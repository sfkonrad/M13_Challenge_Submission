{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### M13_Challenge_KonradK_venture_funding_with_deep_learning.ipynb\n",
    "## Konrad Kozicki\n",
    "### UCB-VIRT-FIN-PT-12-2020-U-B-TTH\n",
    "# Module 13 Challenge Submission - Sandbox_1.21\n",
    "## ( *A20-24.h5* - Optimizer Functions - 1000 Epochs )\n",
    "---\n",
    "\n",
    "# Venture Funding with Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the applicants_data.csv file from the Resources folder into a Pandas DataFrame\n",
    "applicant_data_df = pd.read_csv(\n",
    "    Path(\"./Resources/applicants_data.csv\")\n",
    ")\n",
    "\n",
    "# # Review the DataFrame\n",
    "# applicant_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EIN                        int64\n",
       "NAME                      object\n",
       "APPLICATION_TYPE          object\n",
       "AFFILIATION               object\n",
       "CLASSIFICATION            object\n",
       "USE_CASE                  object\n",
       "ORGANIZATION              object\n",
       "STATUS                     int64\n",
       "INCOME_AMT                object\n",
       "SPECIAL_CONSIDERATIONS    object\n",
       "ASK_AMT                    int64\n",
       "IS_SUCCESSFUL              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the data types associated with the columns\n",
    "applicant_data_df.dtypes"
   ]
  },
  {
   "attachments": {
    "43165e11-dfea-4007-99fa-9bfdbd980c64.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>>> ![image.png](attachment:43165e11-dfea-4007-99fa-9bfdbd980c64.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10M-50M</td>\n",
       "      <td>N</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>N</td>\n",
       "      <td>69656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>165593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2700</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>N</td>\n",
       "      <td>5301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0               T10       Independent          C1000    ProductDev   \n",
       "1                T3       Independent          C2000  Preservation   \n",
       "2                T5  CompanySponsored          C3000    ProductDev   \n",
       "3                T3  CompanySponsored          C2000  Preservation   \n",
       "4                T3       Independent          C1000     Heathcare   \n",
       "5                T3       Independent          C1200  Preservation   \n",
       "6                T3       Independent          C1000  Preservation   \n",
       "7                T3       Independent          C2000  Preservation   \n",
       "8                T7       Independent          C1000    ProductDev   \n",
       "9                T5  CompanySponsored          C3000    ProductDev   \n",
       "10               T3       Independent          C1200  Preservation   \n",
       "11               T3       Independent          C2000  Preservation   \n",
       "12               T3  CompanySponsored          C1200  Preservation   \n",
       "13               T3       Independent          C2700  Preservation   \n",
       "14               T3       Independent          C1000  Preservation   \n",
       "\n",
       "    ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0    Association       1              0                      N     5000   \n",
       "1   Co-operative       1         1-9999                      N   108590   \n",
       "2    Association       1              0                      N     5000   \n",
       "3          Trust       1    10000-24999                      N     6692   \n",
       "4          Trust       1  100000-499999                      N   142590   \n",
       "5          Trust       1              0                      N     5000   \n",
       "6          Trust       1  100000-499999                      N    31452   \n",
       "7          Trust       1        10M-50M                      N  7508025   \n",
       "8          Trust       1         1-9999                      N    94389   \n",
       "9    Association       1              0                      N     5000   \n",
       "10         Trust       1    25000-99999                      N    69656   \n",
       "11         Trust       1  100000-499999                      N   165593   \n",
       "12   Association       1              0                      N     5000   \n",
       "13         Trust       1    25000-99999                      N     5301   \n",
       "14         Trust       1              0                      N     5000   \n",
       "\n",
       "    IS_SUCCESSFUL  \n",
       "0               1  \n",
       "1               1  \n",
       "2               0  \n",
       "3               1  \n",
       "4               1  \n",
       "5               1  \n",
       "6               1  \n",
       "7               1  \n",
       "8               1  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "12              1  \n",
       "13              1  \n",
       "14              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the 'EIN' and 'NAME' columns from the DataFrame\n",
    "applicant_data_df = applicant_data_df.drop(columns = [\"EIN\", \"NAME\"])\n",
    "\n",
    "# Review the DataFrame\n",
    "applicant_data_df[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>31452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10M-50M</td>\n",
       "      <td>7508025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T7</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>94389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>69656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>165593</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C1200</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2700</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>25000-99999</td>\n",
       "      <td>5301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0               T10       Independent          C1000    ProductDev   \n",
       "1                T3       Independent          C2000  Preservation   \n",
       "2                T5  CompanySponsored          C3000    ProductDev   \n",
       "3                T3  CompanySponsored          C2000  Preservation   \n",
       "4                T3       Independent          C1000     Heathcare   \n",
       "5                T3       Independent          C1200  Preservation   \n",
       "6                T3       Independent          C1000  Preservation   \n",
       "7                T3       Independent          C2000  Preservation   \n",
       "8                T7       Independent          C1000    ProductDev   \n",
       "9                T5  CompanySponsored          C3000    ProductDev   \n",
       "10               T3       Independent          C1200  Preservation   \n",
       "11               T3       Independent          C2000  Preservation   \n",
       "12               T3  CompanySponsored          C1200  Preservation   \n",
       "13               T3       Independent          C2700  Preservation   \n",
       "14               T3       Independent          C1000  Preservation   \n",
       "\n",
       "    ORGANIZATION  STATUS     INCOME_AMT  ASK_AMT  IS_SUCCESSFUL  \n",
       "0    Association       1              0     5000              1  \n",
       "1   Co-operative       1         1-9999   108590              1  \n",
       "2    Association       1              0     5000              0  \n",
       "3          Trust       1    10000-24999     6692              1  \n",
       "4          Trust       1  100000-499999   142590              1  \n",
       "5          Trust       1              0     5000              1  \n",
       "6          Trust       1  100000-499999    31452              1  \n",
       "7          Trust       1        10M-50M  7508025              1  \n",
       "8          Trust       1         1-9999    94389              1  \n",
       "9    Association       1              0     5000              0  \n",
       "10         Trust       1    25000-99999    69656              0  \n",
       "11         Trust       1  100000-499999   165593              0  \n",
       "12   Association       1              0     5000              1  \n",
       "13         Trust       1    25000-99999     5301              1  \n",
       "14         Trust       1              0     5000              1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the other columns from the DataFrame as needed\n",
    "applicant_data_df_cropped = applicant_data_df.drop(columns = [\"SPECIAL_CONSIDERATIONS\"])\n",
    "\n",
    "\n",
    "#.drop(columns = [\"AFFILIATION\", \"APPLICATION_TYPE\", \"CLASSIFICATION\", \"ORGANIZATION\", \"INCOME_AMT\", \"ASK_AMT\", \"STATUS\", \"USE_CASE\", \"SPECIAL_CONSIDERATIONS\"])\n",
    "\n",
    "# # Review the DataFrame\n",
    "applicant_data_df_cropped[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of categorical variables \n",
    "categorical_variables_cropped = list(applicant_data_df_cropped.dtypes[applicant_data_df_cropped.dtypes == \"object\"].index)\n",
    "\n",
    "# Display the categorical variables list\n",
    "categorical_variables_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(applicant_data_df_cropped[categorical_variables_cropped])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns = enc.get_feature_names(categorical_variables_cropped)\n",
    ")\n",
    "\n",
    "# # Review the DataFrame\n",
    "# encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_variables_df = applicant_data_df_cropped.drop(columns = categorical_variables_cropped\n",
    "                                                       )\n",
    "\n",
    "# # Review the DataFrame\n",
    "# numerical_variables_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "fully_encoded_df = pd.concat(\n",
    "    [\n",
    "        numerical_variables_df,\n",
    "        encoded_df\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# # Review the Dataframe\n",
    "# fully_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE    object\n",
       "AFFILIATION         object\n",
       "CLASSIFICATION      object\n",
       "USE_CASE            object\n",
       "ORGANIZATION        object\n",
       "STATUS               int64\n",
       "INCOME_AMT          object\n",
       "ASK_AMT              int64\n",
       "IS_SUCCESSFUL        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "applicant_data_df_cropped.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS                      int64\n",
       "ASK_AMT                     int64\n",
       "IS_SUCCESSFUL               int64\n",
       "APPLICATION_TYPE_T10      float64\n",
       "APPLICATION_TYPE_T12      float64\n",
       "                           ...   \n",
       "INCOME_AMT_10M-50M        float64\n",
       "INCOME_AMT_1M-5M          float64\n",
       "INCOME_AMT_25000-99999    float64\n",
       "INCOME_AMT_50M+           float64\n",
       "INCOME_AMT_5M-10M         float64\n",
       "Length: 115, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_encoded_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target set y using the IS_SUCCESSFUL column\n",
    "y = fully_encoded_df[\"IS_SUCCESSFUL\"]\n",
    "\n",
    "# # Display a sample of y\n",
    "# y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features set X by selecting all columns but IS_SUCCESSFUL\n",
    "X = fully_encoded_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
    "\n",
    "\n",
    "# # Review the features DataFrame\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Fit the scaler to the features training dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Optimize the neural network model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define at least three new deep neural network models (resulting in the original plus 3 optimization attempts). With each, try to improve on your first models predictive accuracy.\n",
    "\n",
    "> **Rewind** Recall that perfect accuracy has a value of 1, so accuracy improves as its value moves closer to 1. To optimize your model for a predictive accuracy as close to 1 as possible, you can use any or all of the following techniques:\n",
    ">\n",
    "> * Adjust the input data by dropping different features columns to ensure that no variables or outliers confuse the model.\n",
    ">\n",
    "> * Add more neurons (nodes) to a hidden layer.\n",
    ">\n",
    "> * Add more hidden layers.\n",
    ">\n",
    "> * Use different activation functions for the hidden layers.\n",
    ">\n",
    "> * Add to or reduce the number of epochs in the training regimen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Model 20+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A20 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A20 =  (number_input_features + number_output_neurons_A20) // 2\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A20 =  (hidden_nodes_layer1_A20 + number_output_neurons_A20) // 2\n",
    "# Review the number of hidden nodes in the second layer\n",
    "hidden_nodes_layer2_A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\n",
    "hidden_nodes_layer3_A20 =  (hidden_nodes_layer2_A20 + number_output_neurons_A20) // 2\n",
    "# Review the number of hidden nodes in the third layer\n",
    "hidden_nodes_layer3_A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fourth hidden layer\n",
    "hidden_nodes_layer4_A20 =  (hidden_nodes_layer3_A20 + number_output_neurons_A20) // 2\n",
    "# Review the number of hidden nodes in the fourth layer\n",
    "hidden_nodes_layer4_A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fifth hidden layer\n",
    "hidden_nodes_layer5_A20 =  (hidden_nodes_layer4_A20 + number_output_neurons_A20) // 2\n",
    "# Review the number of hidden nodes in the fifth layer\n",
    "hidden_nodes_layer5_A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the Sixth hidden layer\n",
    "hidden_nodes_layer6_A20 =  (hidden_nodes_layer5_A20 + number_output_neurons_A20) // 2\n",
    "# Review the number of hidden nodes in the sixth layer\n",
    "hidden_nodes_layer6_A20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 57)                6555      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 29)                1682      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 8,864\n",
      "Trainable params: 8,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Display the Sequential Model Instance \n",
    "# for Model A20\n",
    "nn_A20 = Sequential() \n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_A20.add(Dense(units=hidden_nodes_layer1_A20, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the second hidden layer\n",
    "nn_A20.add(Dense(units=hidden_nodes_layer2_A20, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the third hidden layer\n",
    "nn_A20.add(Dense(units=hidden_nodes_layer3_A20, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fourth hidden layer\n",
    "nn_A20.add(Dense(units=hidden_nodes_layer4_A20, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fifth hidden layer\n",
    "nn_A20.add(Dense(units=hidden_nodes_layer5_A20, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the sixth hidden layer\n",
    "nn_A20.add(Dense(units=hidden_nodes_layer6_A20, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_A20.add(Dense(units=number_output_neurons_A20, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_A20.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A20.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "322/322 [==============================] - 1s 3ms/step - loss: 0.2297 - accuracy: 0.6502 - val_loss: 0.2064 - val_accuracy: 0.7294\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2029 - accuracy: 0.7335 - val_loss: 0.1998 - val_accuracy: 0.7298\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1984 - accuracy: 0.7311 - val_loss: 0.1978 - val_accuracy: 0.7276\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.7325 - val_loss: 0.1948 - val_accuracy: 0.7279\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.7334 - val_loss: 0.1938 - val_accuracy: 0.7290\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1933 - accuracy: 0.7277 - val_loss: 0.1922 - val_accuracy: 0.7287\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.7317 - val_loss: 0.1921 - val_accuracy: 0.7305\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.7346 - val_loss: 0.1917 - val_accuracy: 0.7300\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.7286 - val_loss: 0.1921 - val_accuracy: 0.7287\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1875 - accuracy: 0.7380 - val_loss: 0.1935 - val_accuracy: 0.7254\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7352 - val_loss: 0.1923 - val_accuracy: 0.7283\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1895 - accuracy: 0.7301 - val_loss: 0.1919 - val_accuracy: 0.7286\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7316 - val_loss: 0.1920 - val_accuracy: 0.7274\n",
      "Epoch 14/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.7348 - val_loss: 0.1927 - val_accuracy: 0.7265\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.7362 - val_loss: 0.1921 - val_accuracy: 0.7276\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1890 - accuracy: 0.7337 - val_loss: 0.1923 - val_accuracy: 0.7280\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.7308 - val_loss: 0.1923 - val_accuracy: 0.7272\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.7400 - val_loss: 0.1924 - val_accuracy: 0.7275\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7334 - val_loss: 0.1925 - val_accuracy: 0.7272\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1851 - accuracy: 0.7405 - val_loss: 0.1920 - val_accuracy: 0.7289\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.7455 - val_loss: 0.1924 - val_accuracy: 0.7296\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1865 - accuracy: 0.7372 - val_loss: 0.1924 - val_accuracy: 0.7282\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7362 - val_loss: 0.1930 - val_accuracy: 0.7260\n",
      "Epoch 24/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7402 - val_loss: 0.1929 - val_accuracy: 0.7273\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.7350 - val_loss: 0.1926 - val_accuracy: 0.7273\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.7373 - val_loss: 0.1928 - val_accuracy: 0.7269\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7318 - val_loss: 0.1924 - val_accuracy: 0.7285\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1869 - accuracy: 0.7385 - val_loss: 0.1920 - val_accuracy: 0.7274\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.7305 - val_loss: 0.1908 - val_accuracy: 0.7291\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7416 - val_loss: 0.1912 - val_accuracy: 0.7249\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1869 - accuracy: 0.7379 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7392 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.7417 - val_loss: 0.1908 - val_accuracy: 0.7282\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7405 - val_loss: 0.1910 - val_accuracy: 0.7289\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7338 - val_loss: 0.1904 - val_accuracy: 0.7293\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7539 - val_loss: 0.1898 - val_accuracy: 0.7285\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7430 - val_loss: 0.1918 - val_accuracy: 0.7269\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7479 - val_loss: 0.1903 - val_accuracy: 0.7293\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7410 - val_loss: 0.1910 - val_accuracy: 0.7285\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7388 - val_loss: 0.1906 - val_accuracy: 0.7276\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1828 - accuracy: 0.7392 - val_loss: 0.1906 - val_accuracy: 0.7290\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7511 - val_loss: 0.1891 - val_accuracy: 0.7263\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7376 - val_loss: 0.1894 - val_accuracy: 0.7303\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7380 - val_loss: 0.1888 - val_accuracy: 0.7305\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.7403 - val_loss: 0.1891 - val_accuracy: 0.7293\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7449 - val_loss: 0.1895 - val_accuracy: 0.7252\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7448 - val_loss: 0.1893 - val_accuracy: 0.7270\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.7371 - val_loss: 0.1896 - val_accuracy: 0.7295\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7481 - val_loss: 0.1896 - val_accuracy: 0.7305\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7422 - val_loss: 0.1894 - val_accuracy: 0.7308\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7385 - val_loss: 0.1892 - val_accuracy: 0.7298\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.7406 - val_loss: 0.1892 - val_accuracy: 0.7259\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.7393 - val_loss: 0.1891 - val_accuracy: 0.7287\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7397 - val_loss: 0.1895 - val_accuracy: 0.7296\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7439 - val_loss: 0.1894 - val_accuracy: 0.7296\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7452 - val_loss: 0.1894 - val_accuracy: 0.7302\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.7379 - val_loss: 0.1907 - val_accuracy: 0.7291\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7430 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.7432 - val_loss: 0.1899 - val_accuracy: 0.7272\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7437 - val_loss: 0.1894 - val_accuracy: 0.7291\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.7464 - val_loss: 0.1890 - val_accuracy: 0.7296\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.7448 - val_loss: 0.1894 - val_accuracy: 0.7306\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7424 - val_loss: 0.1890 - val_accuracy: 0.7307\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7453 - val_loss: 0.1929 - val_accuracy: 0.7275\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1841 - accuracy: 0.7418 - val_loss: 0.1894 - val_accuracy: 0.7302\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7412 - val_loss: 0.1894 - val_accuracy: 0.7277\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7429 - val_loss: 0.1893 - val_accuracy: 0.7287\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7424 - val_loss: 0.1900 - val_accuracy: 0.7293\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7400 - val_loss: 0.1897 - val_accuracy: 0.7296\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7418 - val_loss: 0.1894 - val_accuracy: 0.7282\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7486 - val_loss: 0.1899 - val_accuracy: 0.7288\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7410 - val_loss: 0.1896 - val_accuracy: 0.7291\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.7360 - val_loss: 0.1896 - val_accuracy: 0.7302\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7519 - val_loss: 0.1906 - val_accuracy: 0.7293\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7483 - val_loss: 0.1898 - val_accuracy: 0.7289\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7465 - val_loss: 0.1902 - val_accuracy: 0.7274\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7387 - val_loss: 0.1904 - val_accuracy: 0.7265\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.7385 - val_loss: 0.1902 - val_accuracy: 0.7294\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7425 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7397 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7418 - val_loss: 0.1900 - val_accuracy: 0.7295\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7464 - val_loss: 0.1901 - val_accuracy: 0.7292\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7412 - val_loss: 0.1900 - val_accuracy: 0.7294\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7453 - val_loss: 0.1908 - val_accuracy: 0.7293\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7438 - val_loss: 0.1899 - val_accuracy: 0.7294\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7473 - val_loss: 0.1899 - val_accuracy: 0.7299\n",
      "Epoch 87/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7406 - val_loss: 0.1902 - val_accuracy: 0.7296\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7441 - val_loss: 0.1901 - val_accuracy: 0.7300\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7480 - val_loss: 0.1902 - val_accuracy: 0.7296\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7461 - val_loss: 0.1922 - val_accuracy: 0.7292\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7420 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7439 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.7441 - val_loss: 0.1908 - val_accuracy: 0.7286\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7443 - val_loss: 0.1900 - val_accuracy: 0.7295\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7417 - val_loss: 0.1899 - val_accuracy: 0.7294\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1829 - accuracy: 0.7363 - val_loss: 0.1900 - val_accuracy: 0.7280\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7472 - val_loss: 0.1898 - val_accuracy: 0.7294\n",
      "Epoch 98/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7415 - val_loss: 0.1907 - val_accuracy: 0.7270\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7451 - val_loss: 0.1903 - val_accuracy: 0.7293\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7439 - val_loss: 0.1901 - val_accuracy: 0.7292\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7501 - val_loss: 0.1902 - val_accuracy: 0.7294\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7424 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7415 - val_loss: 0.1896 - val_accuracy: 0.7300\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7462 - val_loss: 0.1896 - val_accuracy: 0.7288\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7464 - val_loss: 0.1898 - val_accuracy: 0.7298\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7408 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7405 - val_loss: 0.1903 - val_accuracy: 0.7296\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7520 - val_loss: 0.1899 - val_accuracy: 0.7294\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7415 - val_loss: 0.1893 - val_accuracy: 0.7300\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1828 - accuracy: 0.7391 - val_loss: 0.1894 - val_accuracy: 0.7303\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7390 - val_loss: 0.1898 - val_accuracy: 0.7290\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7356 - val_loss: 0.1896 - val_accuracy: 0.7297\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7411 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7473 - val_loss: 0.1898 - val_accuracy: 0.7304\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7447 - val_loss: 0.1899 - val_accuracy: 0.7294\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7425 - val_loss: 0.1901 - val_accuracy: 0.7292\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.7434 - val_loss: 0.1908 - val_accuracy: 0.7292\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7391 - val_loss: 0.1902 - val_accuracy: 0.7290\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7431 - val_loss: 0.1901 - val_accuracy: 0.7294\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7388 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7481 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7410 - val_loss: 0.1891 - val_accuracy: 0.7295\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7439 - val_loss: 0.1895 - val_accuracy: 0.7302\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7430 - val_loss: 0.1899 - val_accuracy: 0.7283\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7408 - val_loss: 0.1897 - val_accuracy: 0.7293\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7443 - val_loss: 0.1898 - val_accuracy: 0.7292\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7413 - val_loss: 0.1897 - val_accuracy: 0.7295\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7454 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7473 - val_loss: 0.1894 - val_accuracy: 0.7299\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7475 - val_loss: 0.1902 - val_accuracy: 0.7298\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7399 - val_loss: 0.1905 - val_accuracy: 0.7296\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7386 - val_loss: 0.1898 - val_accuracy: 0.7300\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7430 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 134/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7461 - val_loss: 0.1898 - val_accuracy: 0.7291\n",
      "Epoch 135/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7482 - val_loss: 0.1899 - val_accuracy: 0.7289\n",
      "Epoch 136/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7384 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 137/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7409 - val_loss: 0.1899 - val_accuracy: 0.7291\n",
      "Epoch 138/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.7402 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 139/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7465 - val_loss: 0.1906 - val_accuracy: 0.7286\n",
      "Epoch 140/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.7389 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 141/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7433 - val_loss: 0.1900 - val_accuracy: 0.7280\n",
      "Epoch 142/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7510 - val_loss: 0.1899 - val_accuracy: 0.7289\n",
      "Epoch 143/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7509 - val_loss: 0.1893 - val_accuracy: 0.7297\n",
      "Epoch 144/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.7439 - val_loss: 0.1895 - val_accuracy: 0.7292\n",
      "Epoch 145/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7433 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 146/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7485 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 147/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7465 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 148/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7498 - val_loss: 0.1910 - val_accuracy: 0.7285\n",
      "Epoch 149/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7482 - val_loss: 0.1901 - val_accuracy: 0.7286\n",
      "Epoch 150/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7479 - val_loss: 0.1907 - val_accuracy: 0.7273\n",
      "Epoch 151/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7433 - val_loss: 0.1900 - val_accuracy: 0.7287\n",
      "Epoch 152/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7433 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 153/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7482 - val_loss: 0.1911 - val_accuracy: 0.7275\n",
      "Epoch 154/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7466 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 155/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7418 - val_loss: 0.1907 - val_accuracy: 0.7281\n",
      "Epoch 156/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.7321 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 157/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.7392 - val_loss: 0.1907 - val_accuracy: 0.7269\n",
      "Epoch 158/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7343 - val_loss: 0.1913 - val_accuracy: 0.7276\n",
      "Epoch 159/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7372 - val_loss: 0.1919 - val_accuracy: 0.7267\n",
      "Epoch 160/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.7346 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 161/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7437 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 162/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7471 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 163/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7472 - val_loss: 0.1913 - val_accuracy: 0.7272\n",
      "Epoch 164/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7410 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 165/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.7339 - val_loss: 0.1909 - val_accuracy: 0.7281\n",
      "Epoch 166/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7342 - val_loss: 0.1905 - val_accuracy: 0.7276\n",
      "Epoch 167/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7451 - val_loss: 0.1897 - val_accuracy: 0.7282\n",
      "Epoch 168/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7430 - val_loss: 0.1897 - val_accuracy: 0.7283\n",
      "Epoch 169/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7478 - val_loss: 0.1900 - val_accuracy: 0.7270\n",
      "Epoch 170/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7432 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 171/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7490 - val_loss: 0.1901 - val_accuracy: 0.7286\n",
      "Epoch 172/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7487 - val_loss: 0.1892 - val_accuracy: 0.7283\n",
      "Epoch 173/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7447 - val_loss: 0.1897 - val_accuracy: 0.7280\n",
      "Epoch 174/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7461 - val_loss: 0.1887 - val_accuracy: 0.7302\n",
      "Epoch 175/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7466 - val_loss: 0.1893 - val_accuracy: 0.7280\n",
      "Epoch 176/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7478 - val_loss: 0.1888 - val_accuracy: 0.7285\n",
      "Epoch 177/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7470 - val_loss: 0.1893 - val_accuracy: 0.7287\n",
      "Epoch 178/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.7497 - val_loss: 0.1887 - val_accuracy: 0.7290\n",
      "Epoch 179/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1730 - accuracy: 0.7526 - val_loss: 0.1888 - val_accuracy: 0.7291\n",
      "Epoch 180/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7419 - val_loss: 0.1891 - val_accuracy: 0.7290\n",
      "Epoch 181/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7471 - val_loss: 0.1888 - val_accuracy: 0.7293\n",
      "Epoch 182/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7492 - val_loss: 0.1891 - val_accuracy: 0.7284\n",
      "Epoch 183/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.7432 - val_loss: 0.1886 - val_accuracy: 0.7259\n",
      "Epoch 184/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7469 - val_loss: 0.1889 - val_accuracy: 0.7286\n",
      "Epoch 185/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7434 - val_loss: 0.1898 - val_accuracy: 0.7285\n",
      "Epoch 186/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7442 - val_loss: 0.1895 - val_accuracy: 0.7278\n",
      "Epoch 187/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7474 - val_loss: 0.1904 - val_accuracy: 0.7255\n",
      "Epoch 188/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.7520 - val_loss: 0.1900 - val_accuracy: 0.7268\n",
      "Epoch 189/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7494 - val_loss: 0.1895 - val_accuracy: 0.7275\n",
      "Epoch 190/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7412 - val_loss: 0.1897 - val_accuracy: 0.7283\n",
      "Epoch 191/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7338 - val_loss: 0.1899 - val_accuracy: 0.7283\n",
      "Epoch 192/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1746 - accuracy: 0.7522 - val_loss: 0.1891 - val_accuracy: 0.7283\n",
      "Epoch 193/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7459 - val_loss: 0.1896 - val_accuracy: 0.7277\n",
      "Epoch 194/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7481 - val_loss: 0.1894 - val_accuracy: 0.7287\n",
      "Epoch 195/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7464 - val_loss: 0.1899 - val_accuracy: 0.7280\n",
      "Epoch 196/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7465 - val_loss: 0.1902 - val_accuracy: 0.7274\n",
      "Epoch 197/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7418 - val_loss: 0.1897 - val_accuracy: 0.7274\n",
      "Epoch 198/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7412 - val_loss: 0.1901 - val_accuracy: 0.7280\n",
      "Epoch 199/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7453 - val_loss: 0.1903 - val_accuracy: 0.7272\n",
      "Epoch 200/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7429 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 201/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7408 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 202/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.7504 - val_loss: 0.1899 - val_accuracy: 0.7287\n",
      "Epoch 203/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7372 - val_loss: 0.1900 - val_accuracy: 0.7274\n",
      "Epoch 204/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7387 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 205/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7443 - val_loss: 0.1901 - val_accuracy: 0.7273\n",
      "Epoch 206/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7367 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 207/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7463 - val_loss: 0.1897 - val_accuracy: 0.7282\n",
      "Epoch 208/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7513 - val_loss: 0.1904 - val_accuracy: 0.7293\n",
      "Epoch 209/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7426 - val_loss: 0.1897 - val_accuracy: 0.7282\n",
      "Epoch 210/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7364 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 211/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7463 - val_loss: 0.1900 - val_accuracy: 0.7278\n",
      "Epoch 212/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.7477 - val_loss: 0.1895 - val_accuracy: 0.7270\n",
      "Epoch 213/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.7341 - val_loss: 0.1904 - val_accuracy: 0.7275\n",
      "Epoch 214/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7449 - val_loss: 0.1897 - val_accuracy: 0.7288\n",
      "Epoch 215/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7511 - val_loss: 0.1900 - val_accuracy: 0.7286\n",
      "Epoch 216/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7471 - val_loss: 0.1901 - val_accuracy: 0.7278\n",
      "Epoch 217/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7496 - val_loss: 0.1898 - val_accuracy: 0.7283\n",
      "Epoch 218/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7489 - val_loss: 0.1895 - val_accuracy: 0.7289\n",
      "Epoch 219/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7453 - val_loss: 0.1898 - val_accuracy: 0.7286\n",
      "Epoch 220/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1730 - accuracy: 0.7565 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 221/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7362 - val_loss: 0.1897 - val_accuracy: 0.7281\n",
      "Epoch 222/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.7518 - val_loss: 0.1896 - val_accuracy: 0.7285\n",
      "Epoch 223/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7460 - val_loss: 0.1897 - val_accuracy: 0.7278\n",
      "Epoch 224/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7456 - val_loss: 0.1894 - val_accuracy: 0.7285\n",
      "Epoch 225/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7451 - val_loss: 0.1902 - val_accuracy: 0.7276\n",
      "Epoch 226/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7408 - val_loss: 0.1900 - val_accuracy: 0.7281\n",
      "Epoch 227/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7364 - val_loss: 0.1898 - val_accuracy: 0.7280\n",
      "Epoch 228/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7488 - val_loss: 0.1899 - val_accuracy: 0.7283\n",
      "Epoch 229/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7425 - val_loss: 0.1892 - val_accuracy: 0.7288\n",
      "Epoch 230/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7453 - val_loss: 0.1898 - val_accuracy: 0.7287\n",
      "Epoch 231/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7487 - val_loss: 0.1896 - val_accuracy: 0.7288\n",
      "Epoch 232/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7489 - val_loss: 0.1907 - val_accuracy: 0.7272\n",
      "Epoch 233/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7416 - val_loss: 0.1904 - val_accuracy: 0.7279\n",
      "Epoch 234/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.7455 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 235/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7433 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 236/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7504 - val_loss: 0.1911 - val_accuracy: 0.7265\n",
      "Epoch 237/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7444 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 238/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7519 - val_loss: 0.1895 - val_accuracy: 0.7283\n",
      "Epoch 239/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7457 - val_loss: 0.1896 - val_accuracy: 0.7278\n",
      "Epoch 240/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7501 - val_loss: 0.1896 - val_accuracy: 0.7285\n",
      "Epoch 241/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7434 - val_loss: 0.1898 - val_accuracy: 0.7290\n",
      "Epoch 242/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7410 - val_loss: 0.1898 - val_accuracy: 0.7289\n",
      "Epoch 243/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7441 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 244/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7474 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 245/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7498 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 246/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7452 - val_loss: 0.1905 - val_accuracy: 0.7272\n",
      "Epoch 247/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7426 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 248/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7485 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 249/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7490 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 250/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7431 - val_loss: 0.1895 - val_accuracy: 0.7293\n",
      "Epoch 251/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7465 - val_loss: 0.1894 - val_accuracy: 0.7291\n",
      "Epoch 252/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.7517 - val_loss: 0.1899 - val_accuracy: 0.7291\n",
      "Epoch 253/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7385 - val_loss: 0.1896 - val_accuracy: 0.7289\n",
      "Epoch 254/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7472 - val_loss: 0.1903 - val_accuracy: 0.7294\n",
      "Epoch 255/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7415 - val_loss: 0.1894 - val_accuracy: 0.7296\n",
      "Epoch 256/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7476 - val_loss: 0.1902 - val_accuracy: 0.7281\n",
      "Epoch 257/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7430 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 258/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7473 - val_loss: 0.1896 - val_accuracy: 0.7290\n",
      "Epoch 259/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.7531 - val_loss: 0.1898 - val_accuracy: 0.7293\n",
      "Epoch 260/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7465 - val_loss: 0.1898 - val_accuracy: 0.7287\n",
      "Epoch 261/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7451 - val_loss: 0.1901 - val_accuracy: 0.7297\n",
      "Epoch 262/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7396 - val_loss: 0.1900 - val_accuracy: 0.7299\n",
      "Epoch 263/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7419 - val_loss: 0.1900 - val_accuracy: 0.7294\n",
      "Epoch 264/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7463 - val_loss: 0.1900 - val_accuracy: 0.7286\n",
      "Epoch 265/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7447 - val_loss: 0.1901 - val_accuracy: 0.7286\n",
      "Epoch 266/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7460 - val_loss: 0.1895 - val_accuracy: 0.7296\n",
      "Epoch 267/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.7444 - val_loss: 0.1900 - val_accuracy: 0.7288\n",
      "Epoch 268/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.7418 - val_loss: 0.1897 - val_accuracy: 0.7294\n",
      "Epoch 269/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7417 - val_loss: 0.1900 - val_accuracy: 0.7276\n",
      "Epoch 270/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7449 - val_loss: 0.1900 - val_accuracy: 0.7287\n",
      "Epoch 271/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7467 - val_loss: 0.1895 - val_accuracy: 0.7295\n",
      "Epoch 272/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7454 - val_loss: 0.1900 - val_accuracy: 0.7293\n",
      "Epoch 273/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.7478 - val_loss: 0.1899 - val_accuracy: 0.7292\n",
      "Epoch 274/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7370 - val_loss: 0.1897 - val_accuracy: 0.7288\n",
      "Epoch 275/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.7546 - val_loss: 0.1898 - val_accuracy: 0.7282\n",
      "Epoch 276/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7458 - val_loss: 0.1898 - val_accuracy: 0.7287\n",
      "Epoch 277/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7418 - val_loss: 0.1897 - val_accuracy: 0.7291\n",
      "Epoch 278/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7485 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 279/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7377 - val_loss: 0.1899 - val_accuracy: 0.7278\n",
      "Epoch 280/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7414 - val_loss: 0.1898 - val_accuracy: 0.7292\n",
      "Epoch 281/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7452 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 282/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7461 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 283/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7418 - val_loss: 0.1905 - val_accuracy: 0.7273\n",
      "Epoch 284/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1742 - accuracy: 0.7522 - val_loss: 0.1902 - val_accuracy: 0.7276\n",
      "Epoch 285/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7431 - val_loss: 0.1898 - val_accuracy: 0.7285\n",
      "Epoch 286/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7486 - val_loss: 0.1897 - val_accuracy: 0.7282\n",
      "Epoch 287/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7419 - val_loss: 0.1898 - val_accuracy: 0.7291\n",
      "Epoch 288/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7442 - val_loss: 0.1902 - val_accuracy: 0.7269\n",
      "Epoch 289/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7480 - val_loss: 0.1897 - val_accuracy: 0.7289\n",
      "Epoch 290/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7450 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 291/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.7333 - val_loss: 0.1900 - val_accuracy: 0.7281\n",
      "Epoch 292/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7476 - val_loss: 0.1900 - val_accuracy: 0.7282\n",
      "Epoch 293/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7457 - val_loss: 0.1898 - val_accuracy: 0.7290\n",
      "Epoch 294/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1726 - accuracy: 0.7538 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 295/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1724 - accuracy: 0.7547 - val_loss: 0.1899 - val_accuracy: 0.7291\n",
      "Epoch 296/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7414 - val_loss: 0.1899 - val_accuracy: 0.7290\n",
      "Epoch 297/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7453 - val_loss: 0.1897 - val_accuracy: 0.7293\n",
      "Epoch 298/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1729 - accuracy: 0.7507 - val_loss: 0.1898 - val_accuracy: 0.7293\n",
      "Epoch 299/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7485 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 300/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7460 - val_loss: 0.1895 - val_accuracy: 0.7293\n",
      "Epoch 301/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.7385 - val_loss: 0.1904 - val_accuracy: 0.7272\n",
      "Epoch 302/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7378 - val_loss: 0.1906 - val_accuracy: 0.7261\n",
      "Epoch 303/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7403 - val_loss: 0.1901 - val_accuracy: 0.7260\n",
      "Epoch 304/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7462 - val_loss: 0.1904 - val_accuracy: 0.7261\n",
      "Epoch 305/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.7451 - val_loss: 0.1904 - val_accuracy: 0.7247\n",
      "Epoch 306/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7479 - val_loss: 0.1921 - val_accuracy: 0.7184\n",
      "Epoch 307/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7419 - val_loss: 0.1909 - val_accuracy: 0.7283\n",
      "Epoch 308/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7427 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 309/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7445 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 310/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7456 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 311/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7444 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 312/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7524 - val_loss: 0.1895 - val_accuracy: 0.7298\n",
      "Epoch 313/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7392 - val_loss: 0.1899 - val_accuracy: 0.7264\n",
      "Epoch 314/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7415 - val_loss: 0.1896 - val_accuracy: 0.7285\n",
      "Epoch 315/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7404 - val_loss: 0.1897 - val_accuracy: 0.7289\n",
      "Epoch 316/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7489 - val_loss: 0.1888 - val_accuracy: 0.7294\n",
      "Epoch 317/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7450 - val_loss: 0.1893 - val_accuracy: 0.7297\n",
      "Epoch 318/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7420 - val_loss: 0.1893 - val_accuracy: 0.7301\n",
      "Epoch 319/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7472 - val_loss: 0.1894 - val_accuracy: 0.7294\n",
      "Epoch 320/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.7423 - val_loss: 0.1893 - val_accuracy: 0.7296\n",
      "Epoch 321/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.7450 - val_loss: 0.1892 - val_accuracy: 0.7301\n",
      "Epoch 322/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7434 - val_loss: 0.1895 - val_accuracy: 0.7296\n",
      "Epoch 323/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7445 - val_loss: 0.1894 - val_accuracy: 0.7290\n",
      "Epoch 324/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.7388 - val_loss: 0.1893 - val_accuracy: 0.7289\n",
      "Epoch 325/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7459 - val_loss: 0.1894 - val_accuracy: 0.7294\n",
      "Epoch 326/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1741 - accuracy: 0.7509 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 327/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7433 - val_loss: 0.1894 - val_accuracy: 0.7289\n",
      "Epoch 328/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7388 - val_loss: 0.1893 - val_accuracy: 0.7294\n",
      "Epoch 329/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7420 - val_loss: 0.1893 - val_accuracy: 0.7294\n",
      "Epoch 330/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.7520 - val_loss: 0.1892 - val_accuracy: 0.7294\n",
      "Epoch 331/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7393 - val_loss: 0.1894 - val_accuracy: 0.7291\n",
      "Epoch 332/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7431 - val_loss: 0.1903 - val_accuracy: 0.7270\n",
      "Epoch 333/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7436 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 334/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7470 - val_loss: 0.1904 - val_accuracy: 0.7258\n",
      "Epoch 335/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7492 - val_loss: 0.1929 - val_accuracy: 0.7215\n",
      "Epoch 336/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7436 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 337/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7455 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 338/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7403 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 339/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7424 - val_loss: 0.1904 - val_accuracy: 0.7279\n",
      "Epoch 340/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7465 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 341/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7391 - val_loss: 0.1908 - val_accuracy: 0.7279\n",
      "Epoch 342/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7452 - val_loss: 0.1897 - val_accuracy: 0.7287\n",
      "Epoch 343/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7470 - val_loss: 0.1908 - val_accuracy: 0.7282\n",
      "Epoch 344/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7451 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 345/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7467 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 346/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7426 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 347/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7417 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 348/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7438 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 349/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7483 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 350/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7476 - val_loss: 0.1911 - val_accuracy: 0.7274\n",
      "Epoch 351/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7462 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 352/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7499 - val_loss: 0.1908 - val_accuracy: 0.7286\n",
      "Epoch 353/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7448 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 354/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7408 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 355/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7463 - val_loss: 0.1908 - val_accuracy: 0.7289\n",
      "Epoch 356/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.7441 - val_loss: 0.1897 - val_accuracy: 0.7283\n",
      "Epoch 357/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7417 - val_loss: 0.1896 - val_accuracy: 0.7287\n",
      "Epoch 358/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.7525 - val_loss: 0.1900 - val_accuracy: 0.7283\n",
      "Epoch 359/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7458 - val_loss: 0.1899 - val_accuracy: 0.7284\n",
      "Epoch 360/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.7506 - val_loss: 0.1900 - val_accuracy: 0.7283\n",
      "Epoch 361/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7450 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 362/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7490 - val_loss: 0.1906 - val_accuracy: 0.7289\n",
      "Epoch 363/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1742 - accuracy: 0.7505 - val_loss: 0.1908 - val_accuracy: 0.7277\n",
      "Epoch 364/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7500 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 365/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7489 - val_loss: 0.1895 - val_accuracy: 0.7286\n",
      "Epoch 366/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7421 - val_loss: 0.1896 - val_accuracy: 0.7294\n",
      "Epoch 367/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7408 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 368/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7452 - val_loss: 0.1897 - val_accuracy: 0.7292\n",
      "Epoch 369/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7420 - val_loss: 0.1898 - val_accuracy: 0.7290\n",
      "Epoch 370/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7417 - val_loss: 0.1897 - val_accuracy: 0.7296\n",
      "Epoch 371/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7464 - val_loss: 0.1899 - val_accuracy: 0.7293\n",
      "Epoch 372/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7467 - val_loss: 0.1897 - val_accuracy: 0.7288\n",
      "Epoch 373/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7446 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 374/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.7506 - val_loss: 0.1899 - val_accuracy: 0.7287\n",
      "Epoch 375/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.7485 - val_loss: 0.1895 - val_accuracy: 0.7287\n",
      "Epoch 376/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7431 - val_loss: 0.1897 - val_accuracy: 0.7294\n",
      "Epoch 377/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7427 - val_loss: 0.1901 - val_accuracy: 0.7295\n",
      "Epoch 378/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7447 - val_loss: 0.1894 - val_accuracy: 0.7298\n",
      "Epoch 379/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7446 - val_loss: 0.1909 - val_accuracy: 0.7292\n",
      "Epoch 380/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7464 - val_loss: 0.1915 - val_accuracy: 0.7279\n",
      "Epoch 381/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7472 - val_loss: 0.1908 - val_accuracy: 0.7288\n",
      "Epoch 382/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7474 - val_loss: 0.1912 - val_accuracy: 0.7289\n",
      "Epoch 383/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.7551 - val_loss: 0.1913 - val_accuracy: 0.7286\n",
      "Epoch 384/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7486 - val_loss: 0.1914 - val_accuracy: 0.7290\n",
      "Epoch 385/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7428 - val_loss: 0.1912 - val_accuracy: 0.7286\n",
      "Epoch 386/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7502 - val_loss: 0.1910 - val_accuracy: 0.7290\n",
      "Epoch 387/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7396 - val_loss: 0.1910 - val_accuracy: 0.7293\n",
      "Epoch 388/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7462 - val_loss: 0.1910 - val_accuracy: 0.7289\n",
      "Epoch 389/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1813 - accuracy: 0.7388 - val_loss: 0.1910 - val_accuracy: 0.7285\n",
      "Epoch 390/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.7574 - val_loss: 0.1911 - val_accuracy: 0.7285\n",
      "Epoch 391/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7395 - val_loss: 0.1910 - val_accuracy: 0.7287\n",
      "Epoch 392/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7457 - val_loss: 0.1910 - val_accuracy: 0.7289\n",
      "Epoch 393/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7479 - val_loss: 0.1911 - val_accuracy: 0.7288\n",
      "Epoch 394/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7458 - val_loss: 0.1912 - val_accuracy: 0.7283\n",
      "Epoch 395/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7499 - val_loss: 0.1905 - val_accuracy: 0.7293\n",
      "Epoch 396/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7432 - val_loss: 0.1910 - val_accuracy: 0.7267\n",
      "Epoch 397/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7426 - val_loss: 0.1910 - val_accuracy: 0.7283\n",
      "Epoch 398/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.7516 - val_loss: 0.1911 - val_accuracy: 0.7287\n",
      "Epoch 399/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7412 - val_loss: 0.1911 - val_accuracy: 0.7281\n",
      "Epoch 400/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.7467 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 401/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7442 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 402/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7445 - val_loss: 0.1915 - val_accuracy: 0.7283\n",
      "Epoch 403/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7453 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 404/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7440 - val_loss: 0.1911 - val_accuracy: 0.7287\n",
      "Epoch 405/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7437 - val_loss: 0.1913 - val_accuracy: 0.7292\n",
      "Epoch 406/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7454 - val_loss: 0.1916 - val_accuracy: 0.7285\n",
      "Epoch 407/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7495 - val_loss: 0.1915 - val_accuracy: 0.7289\n",
      "Epoch 408/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.7501 - val_loss: 0.1910 - val_accuracy: 0.7291\n",
      "Epoch 409/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7423 - val_loss: 0.1902 - val_accuracy: 0.7302\n",
      "Epoch 410/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7461 - val_loss: 0.1904 - val_accuracy: 0.7300\n",
      "Epoch 411/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7460 - val_loss: 0.1908 - val_accuracy: 0.7300\n",
      "Epoch 412/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7445 - val_loss: 0.1902 - val_accuracy: 0.7294\n",
      "Epoch 413/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7468 - val_loss: 0.1901 - val_accuracy: 0.7306\n",
      "Epoch 414/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.7412 - val_loss: 0.1904 - val_accuracy: 0.7302\n",
      "Epoch 415/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7414 - val_loss: 0.1906 - val_accuracy: 0.7304\n",
      "Epoch 416/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7462 - val_loss: 0.1904 - val_accuracy: 0.7307\n",
      "Epoch 417/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7417 - val_loss: 0.1909 - val_accuracy: 0.7301\n",
      "Epoch 418/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7471 - val_loss: 0.1906 - val_accuracy: 0.7299\n",
      "Epoch 419/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7488 - val_loss: 0.1904 - val_accuracy: 0.7299\n",
      "Epoch 420/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7502 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 421/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7430 - val_loss: 0.1906 - val_accuracy: 0.7296\n",
      "Epoch 422/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7451 - val_loss: 0.1905 - val_accuracy: 0.7292\n",
      "Epoch 423/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7484 - val_loss: 0.1908 - val_accuracy: 0.7287\n",
      "Epoch 424/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7437 - val_loss: 0.1903 - val_accuracy: 0.7296\n",
      "Epoch 425/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.7543 - val_loss: 0.1908 - val_accuracy: 0.7297\n",
      "Epoch 426/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7496 - val_loss: 0.1903 - val_accuracy: 0.7274\n",
      "Epoch 427/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7447 - val_loss: 0.1909 - val_accuracy: 0.7292\n",
      "Epoch 428/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7416 - val_loss: 0.1908 - val_accuracy: 0.7293\n",
      "Epoch 429/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7385 - val_loss: 0.1905 - val_accuracy: 0.7294\n",
      "Epoch 430/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7402 - val_loss: 0.1904 - val_accuracy: 0.7296\n",
      "Epoch 431/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7502 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 432/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7511 - val_loss: 0.1903 - val_accuracy: 0.7293\n",
      "Epoch 433/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7477 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 434/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7467 - val_loss: 0.1907 - val_accuracy: 0.7285\n",
      "Epoch 435/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7412 - val_loss: 0.1901 - val_accuracy: 0.7299\n",
      "Epoch 436/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7425 - val_loss: 0.1900 - val_accuracy: 0.7290\n",
      "Epoch 437/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7440 - val_loss: 0.1905 - val_accuracy: 0.7292\n",
      "Epoch 438/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7518 - val_loss: 0.1905 - val_accuracy: 0.7288\n",
      "Epoch 439/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7440 - val_loss: 0.1907 - val_accuracy: 0.7289\n",
      "Epoch 440/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7455 - val_loss: 0.1905 - val_accuracy: 0.7293\n",
      "Epoch 441/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7346 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 442/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7429 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 443/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7443 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 444/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7457 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 445/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7461 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 446/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7399 - val_loss: 0.1910 - val_accuracy: 0.7279\n",
      "Epoch 447/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7429 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 448/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7461 - val_loss: 0.1909 - val_accuracy: 0.7292\n",
      "Epoch 449/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7450 - val_loss: 0.1899 - val_accuracy: 0.7290\n",
      "Epoch 450/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7485 - val_loss: 0.1906 - val_accuracy: 0.7291\n",
      "Epoch 451/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7443 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 452/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.7413 - val_loss: 0.1902 - val_accuracy: 0.7294\n",
      "Epoch 453/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7414 - val_loss: 0.1902 - val_accuracy: 0.7292\n",
      "Epoch 454/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7434 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 455/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7437 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 456/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7465 - val_loss: 0.1906 - val_accuracy: 0.7277\n",
      "Epoch 457/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7478 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 458/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7466 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 459/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.7486 - val_loss: 0.1903 - val_accuracy: 0.7292\n",
      "Epoch 460/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7485 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 461/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1746 - accuracy: 0.7519 - val_loss: 0.1907 - val_accuracy: 0.7287\n",
      "Epoch 462/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7434 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 463/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.7561 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 464/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7374 - val_loss: 0.1900 - val_accuracy: 0.7298\n",
      "Epoch 465/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7462 - val_loss: 0.1901 - val_accuracy: 0.7305\n",
      "Epoch 466/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7471 - val_loss: 0.1898 - val_accuracy: 0.7299\n",
      "Epoch 467/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7468 - val_loss: 0.1903 - val_accuracy: 0.7300\n",
      "Epoch 468/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7490 - val_loss: 0.1904 - val_accuracy: 0.7268\n",
      "Epoch 469/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7486 - val_loss: 0.1908 - val_accuracy: 0.7286\n",
      "Epoch 470/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7488 - val_loss: 0.1908 - val_accuracy: 0.7293\n",
      "Epoch 471/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7470 - val_loss: 0.1900 - val_accuracy: 0.7266\n",
      "Epoch 472/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.7405 - val_loss: 0.1901 - val_accuracy: 0.7282\n",
      "Epoch 473/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1786 - accuracy: 0.7431 - val_loss: 0.1901 - val_accuracy: 0.7296\n",
      "Epoch 474/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7468 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 475/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7454 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 476/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7457 - val_loss: 0.1898 - val_accuracy: 0.7292\n",
      "Epoch 477/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.7493 - val_loss: 0.1898 - val_accuracy: 0.7293\n",
      "Epoch 478/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7417 - val_loss: 0.1903 - val_accuracy: 0.7293\n",
      "Epoch 479/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1750 - accuracy: 0.7471 - val_loss: 0.1903 - val_accuracy: 0.7295\n",
      "Epoch 480/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1783 - accuracy: 0.7443 - val_loss: 0.1903 - val_accuracy: 0.7296\n",
      "Epoch 481/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7456 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 482/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7443 - val_loss: 0.1907 - val_accuracy: 0.7287\n",
      "Epoch 483/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7521 - val_loss: 0.1910 - val_accuracy: 0.7260\n",
      "Epoch 484/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.7414 - val_loss: 0.1906 - val_accuracy: 0.7278\n",
      "Epoch 485/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.7485 - val_loss: 0.1909 - val_accuracy: 0.7269\n",
      "Epoch 486/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7511 - val_loss: 0.1910 - val_accuracy: 0.7285\n",
      "Epoch 487/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7404 - val_loss: 0.1913 - val_accuracy: 0.7259\n",
      "Epoch 488/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.7440 - val_loss: 0.1907 - val_accuracy: 0.7285\n",
      "Epoch 489/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7492 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 490/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1720 - accuracy: 0.7572 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 491/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.7513 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 492/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1726 - accuracy: 0.7528 - val_loss: 0.1907 - val_accuracy: 0.7285\n",
      "Epoch 493/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7426 - val_loss: 0.1908 - val_accuracy: 0.7280\n",
      "Epoch 494/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1733 - accuracy: 0.7519 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 495/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7367 - val_loss: 0.1906 - val_accuracy: 0.7286\n",
      "Epoch 496/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7448 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 497/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.7447 - val_loss: 0.1911 - val_accuracy: 0.7277\n",
      "Epoch 498/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7431 - val_loss: 0.1910 - val_accuracy: 0.7253\n",
      "Epoch 499/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7463 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 500/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7464 - val_loss: 0.1907 - val_accuracy: 0.7282\n",
      "Epoch 501/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7405 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 502/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7490 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 503/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.7504 - val_loss: 0.1909 - val_accuracy: 0.7289\n",
      "Epoch 504/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7455 - val_loss: 0.1906 - val_accuracy: 0.7289\n",
      "Epoch 505/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7387 - val_loss: 0.1907 - val_accuracy: 0.7292\n",
      "Epoch 506/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7487 - val_loss: 0.1901 - val_accuracy: 0.7280\n",
      "Epoch 507/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7411 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 508/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.7520 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 509/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.7506 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 510/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7450 - val_loss: 0.1905 - val_accuracy: 0.7289\n",
      "Epoch 511/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.7488 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 512/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7448 - val_loss: 0.1899 - val_accuracy: 0.7292\n",
      "Epoch 513/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7453 - val_loss: 0.1906 - val_accuracy: 0.7292\n",
      "Epoch 514/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7460 - val_loss: 0.1904 - val_accuracy: 0.7298\n",
      "Epoch 515/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7473 - val_loss: 0.1901 - val_accuracy: 0.7280\n",
      "Epoch 516/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.7499 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 517/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1799 - accuracy: 0.7410 - val_loss: 0.1907 - val_accuracy: 0.7272\n",
      "Epoch 518/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7393 - val_loss: 0.1903 - val_accuracy: 0.7277\n",
      "Epoch 519/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.7488 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 520/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.7516 - val_loss: 0.1913 - val_accuracy: 0.7250\n",
      "Epoch 521/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1739 - accuracy: 0.7566 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 522/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7487 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 523/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7452 - val_loss: 0.1907 - val_accuracy: 0.7281\n",
      "Epoch 524/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7438 - val_loss: 0.1906 - val_accuracy: 0.7285\n",
      "Epoch 525/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.7475 - val_loss: 0.1908 - val_accuracy: 0.7281\n",
      "Epoch 526/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7447 - val_loss: 0.1907 - val_accuracy: 0.7281\n",
      "Epoch 527/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7440 - val_loss: 0.1908 - val_accuracy: 0.7278\n",
      "Epoch 528/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.7389 - val_loss: 0.1911 - val_accuracy: 0.7283\n",
      "Epoch 529/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7369 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 530/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7437 - val_loss: 0.1907 - val_accuracy: 0.7291\n",
      "Epoch 531/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7516 - val_loss: 0.1903 - val_accuracy: 0.7294\n",
      "Epoch 532/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.7515 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 533/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7373 - val_loss: 0.1910 - val_accuracy: 0.7278\n",
      "Epoch 534/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7454 - val_loss: 0.1909 - val_accuracy: 0.7275\n",
      "Epoch 535/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7455 - val_loss: 0.1908 - val_accuracy: 0.7277\n",
      "Epoch 536/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7368 - val_loss: 0.1908 - val_accuracy: 0.7284\n",
      "Epoch 537/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.7524 - val_loss: 0.1914 - val_accuracy: 0.7286\n",
      "Epoch 538/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7452 - val_loss: 0.1907 - val_accuracy: 0.7292\n",
      "Epoch 539/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7510 - val_loss: 0.1910 - val_accuracy: 0.7279\n",
      "Epoch 540/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7479 - val_loss: 0.1915 - val_accuracy: 0.7274\n",
      "Epoch 541/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7423 - val_loss: 0.1909 - val_accuracy: 0.7280\n",
      "Epoch 542/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7465 - val_loss: 0.1909 - val_accuracy: 0.7285\n",
      "Epoch 543/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.7431 - val_loss: 0.1909 - val_accuracy: 0.7288\n",
      "Epoch 544/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7403 - val_loss: 0.1908 - val_accuracy: 0.7284\n",
      "Epoch 545/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7401 - val_loss: 0.1910 - val_accuracy: 0.7286\n",
      "Epoch 546/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7417 - val_loss: 0.1913 - val_accuracy: 0.7282\n",
      "Epoch 547/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7486 - val_loss: 0.1911 - val_accuracy: 0.7283\n",
      "Epoch 548/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.7435 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 549/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7405 - val_loss: 0.1915 - val_accuracy: 0.7276\n",
      "Epoch 550/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7476 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 551/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7483 - val_loss: 0.1909 - val_accuracy: 0.7284\n",
      "Epoch 552/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.7521 - val_loss: 0.1910 - val_accuracy: 0.7281\n",
      "Epoch 553/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7483 - val_loss: 0.1912 - val_accuracy: 0.7277\n",
      "Epoch 554/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7448 - val_loss: 0.1913 - val_accuracy: 0.7275\n",
      "Epoch 555/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7425 - val_loss: 0.1911 - val_accuracy: 0.7278\n",
      "Epoch 556/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7476 - val_loss: 0.1908 - val_accuracy: 0.7286\n",
      "Epoch 557/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.7484 - val_loss: 0.1907 - val_accuracy: 0.7287\n",
      "Epoch 558/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7427 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 559/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7456 - val_loss: 0.1910 - val_accuracy: 0.7287\n",
      "Epoch 560/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1768 - accuracy: 0.7513 - val_loss: 0.1911 - val_accuracy: 0.7280\n",
      "Epoch 561/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7445 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 562/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7389 - val_loss: 0.1908 - val_accuracy: 0.7285\n",
      "Epoch 563/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.7392 - val_loss: 0.1917 - val_accuracy: 0.7283\n",
      "Epoch 564/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7472 - val_loss: 0.1911 - val_accuracy: 0.7287\n",
      "Epoch 565/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7456 - val_loss: 0.1911 - val_accuracy: 0.7280\n",
      "Epoch 566/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1777 - accuracy: 0.7453 - val_loss: 0.1910 - val_accuracy: 0.7287\n",
      "Epoch 567/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7389 - val_loss: 0.1911 - val_accuracy: 0.7279\n",
      "Epoch 568/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7411 - val_loss: 0.1911 - val_accuracy: 0.7287\n",
      "Epoch 569/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7530 - val_loss: 0.1942 - val_accuracy: 0.7251\n",
      "Epoch 570/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.7464 - val_loss: 0.1935 - val_accuracy: 0.7247\n",
      "Epoch 571/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.7356 - val_loss: 0.1938 - val_accuracy: 0.7248\n",
      "Epoch 572/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7465 - val_loss: 0.1936 - val_accuracy: 0.7250\n",
      "Epoch 573/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7415 - val_loss: 0.1933 - val_accuracy: 0.7251\n",
      "Epoch 574/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.7462 - val_loss: 0.1929 - val_accuracy: 0.7254\n",
      "Epoch 575/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.7445 - val_loss: 0.1933 - val_accuracy: 0.7250\n",
      "Epoch 576/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7467 - val_loss: 0.1936 - val_accuracy: 0.7222\n",
      "Epoch 577/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1823 - accuracy: 0.7386 - val_loss: 0.1929 - val_accuracy: 0.7252\n",
      "Epoch 578/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7465 - val_loss: 0.1923 - val_accuracy: 0.7259\n",
      "Epoch 579/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7447 - val_loss: 0.1924 - val_accuracy: 0.7244\n",
      "Epoch 580/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.7420 - val_loss: 0.1926 - val_accuracy: 0.7261\n",
      "Epoch 581/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7488 - val_loss: 0.1923 - val_accuracy: 0.7257\n",
      "Epoch 582/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7406 - val_loss: 0.1925 - val_accuracy: 0.7259\n",
      "Epoch 583/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.7374 - val_loss: 0.1924 - val_accuracy: 0.7259\n",
      "Epoch 584/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.7558 - val_loss: 0.1924 - val_accuracy: 0.7255\n",
      "Epoch 585/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7473 - val_loss: 0.1927 - val_accuracy: 0.7248\n",
      "Epoch 586/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1796 - accuracy: 0.7436 - val_loss: 0.1930 - val_accuracy: 0.7246\n",
      "Epoch 587/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7426 - val_loss: 0.1926 - val_accuracy: 0.7250\n",
      "Epoch 588/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7447 - val_loss: 0.1926 - val_accuracy: 0.7255\n",
      "Epoch 589/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7406 - val_loss: 0.1924 - val_accuracy: 0.7257\n",
      "Epoch 590/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.7394 - val_loss: 0.1903 - val_accuracy: 0.7274\n",
      "Epoch 591/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.7502 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 592/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7485 - val_loss: 0.1905 - val_accuracy: 0.7270\n",
      "Epoch 593/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7466 - val_loss: 0.1906 - val_accuracy: 0.7269\n",
      "Epoch 594/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.7491 - val_loss: 0.1907 - val_accuracy: 0.7270\n",
      "Epoch 595/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.7477 - val_loss: 0.1908 - val_accuracy: 0.7272\n",
      "Epoch 596/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.7492 - val_loss: 0.1907 - val_accuracy: 0.7279\n",
      "Epoch 597/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7436 - val_loss: 0.1917 - val_accuracy: 0.7278\n",
      "Epoch 598/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.7431 - val_loss: 0.1909 - val_accuracy: 0.7272\n",
      "Epoch 599/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1776 - accuracy: 0.7472 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 600/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7462 - val_loss: 0.1906 - val_accuracy: 0.7279\n",
      "Epoch 601/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7424 - val_loss: 0.1907 - val_accuracy: 0.7279\n",
      "Epoch 602/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7540 - val_loss: 0.1910 - val_accuracy: 0.7277\n",
      "Epoch 603/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.7488 - val_loss: 0.1910 - val_accuracy: 0.7269\n",
      "Epoch 604/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7505 - val_loss: 0.1911 - val_accuracy: 0.7277\n",
      "Epoch 605/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.7449 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 606/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1797 - accuracy: 0.7402 - val_loss: 0.1909 - val_accuracy: 0.7281\n",
      "Epoch 607/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1742 - accuracy: 0.7489 - val_loss: 0.1908 - val_accuracy: 0.7280\n",
      "Epoch 608/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7373 - val_loss: 0.1913 - val_accuracy: 0.7274\n",
      "Epoch 609/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.7429 - val_loss: 0.1910 - val_accuracy: 0.7280\n",
      "Epoch 610/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.7468 - val_loss: 0.1913 - val_accuracy: 0.7274\n",
      "Epoch 611/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.7391 - val_loss: 0.1913 - val_accuracy: 0.7266\n",
      "Epoch 612/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7448 - val_loss: 0.1908 - val_accuracy: 0.7282\n",
      "Epoch 613/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.7370 - val_loss: 0.1906 - val_accuracy: 0.7285\n",
      "Epoch 614/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.7453 - val_loss: 0.1905 - val_accuracy: 0.7288\n",
      "Epoch 615/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7479 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 616/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7417 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 617/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.7432 - val_loss: 0.1904 - val_accuracy: 0.7296\n",
      "Epoch 618/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.7439 - val_loss: 0.1908 - val_accuracy: 0.7290\n",
      "Epoch 619/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7471 - val_loss: 0.1910 - val_accuracy: 0.7284\n",
      "Epoch 620/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7480 - val_loss: 0.1908 - val_accuracy: 0.7276\n",
      "Epoch 621/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.7439 - val_loss: 0.1910 - val_accuracy: 0.7278\n",
      "Epoch 622/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7486 - val_loss: 0.1910 - val_accuracy: 0.7281\n",
      "Epoch 623/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.7423 - val_loss: 0.1910 - val_accuracy: 0.7285\n",
      "Epoch 624/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7436 - val_loss: 0.1911 - val_accuracy: 0.7282\n",
      "Epoch 625/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7444 - val_loss: 0.1911 - val_accuracy: 0.7283\n",
      "Epoch 626/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1765 - accuracy: 0.7442 - val_loss: 0.1909 - val_accuracy: 0.7283\n",
      "Epoch 627/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7475 - val_loss: 0.1915 - val_accuracy: 0.7278\n",
      "Epoch 628/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7524 - val_loss: 0.1911 - val_accuracy: 0.7288\n",
      "Epoch 629/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7458 - val_loss: 0.1913 - val_accuracy: 0.7284\n",
      "Epoch 630/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1783 - accuracy: 0.7420 - val_loss: 0.1910 - val_accuracy: 0.7267\n",
      "Epoch 631/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.7379 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 632/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7426 - val_loss: 0.1909 - val_accuracy: 0.7278\n",
      "Epoch 633/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7428 - val_loss: 0.1910 - val_accuracy: 0.7276\n",
      "Epoch 634/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.7459 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 635/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.7542 - val_loss: 0.1907 - val_accuracy: 0.7287\n",
      "Epoch 636/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7469 - val_loss: 0.1909 - val_accuracy: 0.7283\n",
      "Epoch 637/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1756 - accuracy: 0.7485 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 638/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1755 - accuracy: 0.7493 - val_loss: 0.1909 - val_accuracy: 0.7281\n",
      "Epoch 639/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.7472 - val_loss: 0.1907 - val_accuracy: 0.7293\n",
      "Epoch 640/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7483 - val_loss: 0.1908 - val_accuracy: 0.7277\n",
      "Epoch 641/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.7507 - val_loss: 0.1911 - val_accuracy: 0.7285\n",
      "Epoch 642/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7479 - val_loss: 0.1907 - val_accuracy: 0.7293\n",
      "Epoch 643/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7385 - val_loss: 0.1908 - val_accuracy: 0.7291\n",
      "Epoch 644/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7458 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 645/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7487 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 646/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7500 - val_loss: 0.1907 - val_accuracy: 0.7291\n",
      "Epoch 647/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1729 - accuracy: 0.7564 - val_loss: 0.1913 - val_accuracy: 0.7292\n",
      "Epoch 648/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.7485 - val_loss: 0.1908 - val_accuracy: 0.7293\n",
      "Epoch 649/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7374 - val_loss: 0.1906 - val_accuracy: 0.7296\n",
      "Epoch 650/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1730 - accuracy: 0.7524 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 651/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7396 - val_loss: 0.1907 - val_accuracy: 0.7294\n",
      "Epoch 652/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7442 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 653/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7447 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 654/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.7462 - val_loss: 0.1914 - val_accuracy: 0.7287\n",
      "Epoch 655/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7459 - val_loss: 0.1906 - val_accuracy: 0.7286\n",
      "Epoch 656/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7440 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 657/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.7459 - val_loss: 0.1915 - val_accuracy: 0.7272\n",
      "Epoch 658/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.7475 - val_loss: 0.1914 - val_accuracy: 0.7277\n",
      "Epoch 659/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1746 - accuracy: 0.7496 - val_loss: 0.1913 - val_accuracy: 0.7276\n",
      "Epoch 660/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7440 - val_loss: 0.1911 - val_accuracy: 0.7265\n",
      "Epoch 661/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.7447 - val_loss: 0.1913 - val_accuracy: 0.7272\n",
      "Epoch 662/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.7468 - val_loss: 0.1917 - val_accuracy: 0.7274\n",
      "Epoch 663/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.7354 - val_loss: 0.1908 - val_accuracy: 0.7278\n",
      "Epoch 664/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1735 - accuracy: 0.7508 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 665/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.7414 - val_loss: 0.1914 - val_accuracy: 0.7274\n",
      "Epoch 666/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.7431 - val_loss: 0.1912 - val_accuracy: 0.7280\n",
      "Epoch 667/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7493 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 668/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7419 - val_loss: 0.1910 - val_accuracy: 0.7281\n",
      "Epoch 669/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7417 - val_loss: 0.1910 - val_accuracy: 0.7294\n",
      "Epoch 670/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7375 - val_loss: 0.1910 - val_accuracy: 0.7280\n",
      "Epoch 671/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.7500 - val_loss: 0.1912 - val_accuracy: 0.7280\n",
      "Epoch 672/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7426 - val_loss: 0.1911 - val_accuracy: 0.7280\n",
      "Epoch 673/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.7422 - val_loss: 0.1909 - val_accuracy: 0.7274\n",
      "Epoch 674/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7458 - val_loss: 0.1910 - val_accuracy: 0.7281\n",
      "Epoch 675/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7431 - val_loss: 0.1914 - val_accuracy: 0.7275\n",
      "Epoch 676/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.7504 - val_loss: 0.1915 - val_accuracy: 0.7280\n",
      "Epoch 677/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7425 - val_loss: 0.1919 - val_accuracy: 0.7280\n",
      "Epoch 678/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7430 - val_loss: 0.1917 - val_accuracy: 0.7276\n",
      "Epoch 679/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7470 - val_loss: 0.1920 - val_accuracy: 0.7269\n",
      "Epoch 680/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1766 - accuracy: 0.7461 - val_loss: 0.1917 - val_accuracy: 0.7280\n",
      "Epoch 681/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7431 - val_loss: 0.1916 - val_accuracy: 0.7278\n",
      "Epoch 682/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7417 - val_loss: 0.1916 - val_accuracy: 0.7270\n",
      "Epoch 683/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7437 - val_loss: 0.1912 - val_accuracy: 0.7280\n",
      "Epoch 684/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7438 - val_loss: 0.1912 - val_accuracy: 0.7281\n",
      "Epoch 685/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7427 - val_loss: 0.1914 - val_accuracy: 0.7287\n",
      "Epoch 686/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7431 - val_loss: 0.1915 - val_accuracy: 0.7278\n",
      "Epoch 687/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7474 - val_loss: 0.1915 - val_accuracy: 0.7279\n",
      "Epoch 688/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7452 - val_loss: 0.1914 - val_accuracy: 0.7278\n",
      "Epoch 689/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.7496 - val_loss: 0.1915 - val_accuracy: 0.7287\n",
      "Epoch 690/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1747 - accuracy: 0.7482 - val_loss: 0.1917 - val_accuracy: 0.7275\n",
      "Epoch 691/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1782 - accuracy: 0.7439 - val_loss: 0.1915 - val_accuracy: 0.7280\n",
      "Epoch 692/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7489 - val_loss: 0.1918 - val_accuracy: 0.7273\n",
      "Epoch 693/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7494 - val_loss: 0.1916 - val_accuracy: 0.7284\n",
      "Epoch 694/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7402 - val_loss: 0.1916 - val_accuracy: 0.7280\n",
      "Epoch 695/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1754 - accuracy: 0.7479 - val_loss: 0.1912 - val_accuracy: 0.7287\n",
      "Epoch 696/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.7468 - val_loss: 0.1918 - val_accuracy: 0.7285\n",
      "Epoch 697/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.7480 - val_loss: 0.1915 - val_accuracy: 0.7279\n",
      "Epoch 698/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7467 - val_loss: 0.1913 - val_accuracy: 0.7289\n",
      "Epoch 699/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7452 - val_loss: 0.1916 - val_accuracy: 0.7289\n",
      "Epoch 700/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7463 - val_loss: 0.1917 - val_accuracy: 0.7278\n",
      "Epoch 701/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.7426 - val_loss: 0.1913 - val_accuracy: 0.7291\n",
      "Epoch 702/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1740 - accuracy: 0.7503 - val_loss: 0.1912 - val_accuracy: 0.7276\n",
      "Epoch 703/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7462 - val_loss: 0.1910 - val_accuracy: 0.7291\n",
      "Epoch 704/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7409 - val_loss: 0.1906 - val_accuracy: 0.7291\n",
      "Epoch 705/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7437 - val_loss: 0.1909 - val_accuracy: 0.7289\n",
      "Epoch 706/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7503 - val_loss: 0.1910 - val_accuracy: 0.7295\n",
      "Epoch 707/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1781 - accuracy: 0.7425 - val_loss: 0.1908 - val_accuracy: 0.7291\n",
      "Epoch 708/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1741 - accuracy: 0.7531 - val_loss: 0.1909 - val_accuracy: 0.7291\n",
      "Epoch 709/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7462 - val_loss: 0.1908 - val_accuracy: 0.7291\n",
      "Epoch 710/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1742 - accuracy: 0.7520 - val_loss: 0.1909 - val_accuracy: 0.7291\n",
      "Epoch 711/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7492 - val_loss: 0.1909 - val_accuracy: 0.7292\n",
      "Epoch 712/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7494 - val_loss: 0.1911 - val_accuracy: 0.7289\n",
      "Epoch 713/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7446 - val_loss: 0.1909 - val_accuracy: 0.7293\n",
      "Epoch 714/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7412 - val_loss: 0.1911 - val_accuracy: 0.7293\n",
      "Epoch 715/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7432 - val_loss: 0.1910 - val_accuracy: 0.7288\n",
      "Epoch 716/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7402 - val_loss: 0.1910 - val_accuracy: 0.7293\n",
      "Epoch 717/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.7496 - val_loss: 0.1909 - val_accuracy: 0.7291\n",
      "Epoch 718/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7426 - val_loss: 0.1907 - val_accuracy: 0.7300\n",
      "Epoch 719/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7463 - val_loss: 0.1917 - val_accuracy: 0.7290\n",
      "Epoch 720/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7486 - val_loss: 0.1907 - val_accuracy: 0.7293\n",
      "Epoch 721/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7403 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 722/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7452 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 723/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7472 - val_loss: 0.1907 - val_accuracy: 0.7284\n",
      "Epoch 724/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7458 - val_loss: 0.1912 - val_accuracy: 0.7284\n",
      "Epoch 725/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7390 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 726/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7395 - val_loss: 0.1904 - val_accuracy: 0.7304\n",
      "Epoch 727/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7454 - val_loss: 0.1904 - val_accuracy: 0.7299\n",
      "Epoch 728/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.7538 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 729/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7395 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 730/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7435 - val_loss: 0.1910 - val_accuracy: 0.7298\n",
      "Epoch 731/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7417 - val_loss: 0.1906 - val_accuracy: 0.7294\n",
      "Epoch 732/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7418 - val_loss: 0.1903 - val_accuracy: 0.7288\n",
      "Epoch 733/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7412 - val_loss: 0.1907 - val_accuracy: 0.7299\n",
      "Epoch 734/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1809 - accuracy: 0.7346 - val_loss: 0.1907 - val_accuracy: 0.7287\n",
      "Epoch 735/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7437 - val_loss: 0.1903 - val_accuracy: 0.7288\n",
      "Epoch 736/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1728 - accuracy: 0.7506 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 737/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7413 - val_loss: 0.1903 - val_accuracy: 0.7292\n",
      "Epoch 738/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1803 - accuracy: 0.7383 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 739/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7406 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 740/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7472 - val_loss: 0.1905 - val_accuracy: 0.7296\n",
      "Epoch 741/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7401 - val_loss: 0.1902 - val_accuracy: 0.7298\n",
      "Epoch 742/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.7498 - val_loss: 0.1903 - val_accuracy: 0.7297\n",
      "Epoch 743/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7443 - val_loss: 0.1902 - val_accuracy: 0.7300\n",
      "Epoch 744/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.7490 - val_loss: 0.1900 - val_accuracy: 0.7300\n",
      "Epoch 745/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7428 - val_loss: 0.1901 - val_accuracy: 0.7299\n",
      "Epoch 746/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7447 - val_loss: 0.1904 - val_accuracy: 0.7297\n",
      "Epoch 747/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7518 - val_loss: 0.1902 - val_accuracy: 0.7296\n",
      "Epoch 748/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7397 - val_loss: 0.1906 - val_accuracy: 0.7300\n",
      "Epoch 749/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1796 - accuracy: 0.7402 - val_loss: 0.1903 - val_accuracy: 0.7299\n",
      "Epoch 750/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.7498 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 751/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.7462 - val_loss: 0.1900 - val_accuracy: 0.7302\n",
      "Epoch 752/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1751 - accuracy: 0.7503 - val_loss: 0.1902 - val_accuracy: 0.7302\n",
      "Epoch 753/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7371 - val_loss: 0.1903 - val_accuracy: 0.7300\n",
      "Epoch 754/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1715 - accuracy: 0.7563 - val_loss: 0.1913 - val_accuracy: 0.7283\n",
      "Epoch 755/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7468 - val_loss: 0.1918 - val_accuracy: 0.7289\n",
      "Epoch 756/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7489 - val_loss: 0.1903 - val_accuracy: 0.7296\n",
      "Epoch 757/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7458 - val_loss: 0.1906 - val_accuracy: 0.7293\n",
      "Epoch 758/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1793 - accuracy: 0.7382 - val_loss: 0.1901 - val_accuracy: 0.7300\n",
      "Epoch 759/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1741 - accuracy: 0.7507 - val_loss: 0.1902 - val_accuracy: 0.7299\n",
      "Epoch 760/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7448 - val_loss: 0.1901 - val_accuracy: 0.7304\n",
      "Epoch 761/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1785 - accuracy: 0.7412 - val_loss: 0.1901 - val_accuracy: 0.7299\n",
      "Epoch 762/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7476 - val_loss: 0.1906 - val_accuracy: 0.7306\n",
      "Epoch 763/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.7438 - val_loss: 0.1903 - val_accuracy: 0.7304\n",
      "Epoch 764/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7457 - val_loss: 0.1906 - val_accuracy: 0.7303\n",
      "Epoch 765/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7488 - val_loss: 0.1901 - val_accuracy: 0.7299\n",
      "Epoch 766/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7389 - val_loss: 0.1900 - val_accuracy: 0.7302\n",
      "Epoch 767/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.7403 - val_loss: 0.1902 - val_accuracy: 0.7304\n",
      "Epoch 768/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7389 - val_loss: 0.1904 - val_accuracy: 0.7305\n",
      "Epoch 769/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.7464 - val_loss: 0.1904 - val_accuracy: 0.7303\n",
      "Epoch 770/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7369 - val_loss: 0.1904 - val_accuracy: 0.7304\n",
      "Epoch 771/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.7413 - val_loss: 0.1902 - val_accuracy: 0.7296\n",
      "Epoch 772/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7466 - val_loss: 0.1908 - val_accuracy: 0.7302\n",
      "Epoch 773/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7416 - val_loss: 0.1906 - val_accuracy: 0.7295\n",
      "Epoch 774/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7449 - val_loss: 0.1907 - val_accuracy: 0.7297\n",
      "Epoch 775/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7448 - val_loss: 0.1900 - val_accuracy: 0.7305\n",
      "Epoch 776/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7463 - val_loss: 0.1900 - val_accuracy: 0.7300\n",
      "Epoch 777/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7458 - val_loss: 0.1902 - val_accuracy: 0.7306\n",
      "Epoch 778/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7461 - val_loss: 0.1904 - val_accuracy: 0.7303\n",
      "Epoch 779/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1807 - accuracy: 0.7399 - val_loss: 0.1904 - val_accuracy: 0.7299\n",
      "Epoch 780/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1734 - accuracy: 0.7531 - val_loss: 0.1905 - val_accuracy: 0.7296\n",
      "Epoch 781/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1766 - accuracy: 0.7452 - val_loss: 0.1904 - val_accuracy: 0.7294\n",
      "Epoch 782/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.7443 - val_loss: 0.1903 - val_accuracy: 0.7294\n",
      "Epoch 783/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7442 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 784/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7387 - val_loss: 0.1907 - val_accuracy: 0.7294\n",
      "Epoch 785/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1785 - accuracy: 0.7421 - val_loss: 0.1909 - val_accuracy: 0.7300\n",
      "Epoch 786/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7452 - val_loss: 0.1913 - val_accuracy: 0.7301\n",
      "Epoch 787/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7441 - val_loss: 0.1913 - val_accuracy: 0.7291\n",
      "Epoch 788/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1767 - accuracy: 0.7463 - val_loss: 0.1902 - val_accuracy: 0.7305\n",
      "Epoch 789/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.7509 - val_loss: 0.1904 - val_accuracy: 0.7303\n",
      "Epoch 790/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.7481 - val_loss: 0.1902 - val_accuracy: 0.7303\n",
      "Epoch 791/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1744 - accuracy: 0.7514 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 792/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7449 - val_loss: 0.1898 - val_accuracy: 0.7300\n",
      "Epoch 793/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7448 - val_loss: 0.1901 - val_accuracy: 0.7267\n",
      "Epoch 794/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7470 - val_loss: 0.1908 - val_accuracy: 0.7286\n",
      "Epoch 795/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1740 - accuracy: 0.7494 - val_loss: 0.1913 - val_accuracy: 0.7274\n",
      "Epoch 796/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7489 - val_loss: 0.1908 - val_accuracy: 0.7283\n",
      "Epoch 797/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.7408 - val_loss: 0.1968 - val_accuracy: 0.7086\n",
      "Epoch 798/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.7440 - val_loss: 0.1940 - val_accuracy: 0.7251\n",
      "Epoch 799/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.7340 - val_loss: 0.1936 - val_accuracy: 0.7251\n",
      "Epoch 800/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1789 - accuracy: 0.7411 - val_loss: 0.1922 - val_accuracy: 0.7278\n",
      "Epoch 801/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1764 - accuracy: 0.7427 - val_loss: 0.1918 - val_accuracy: 0.7279\n",
      "Epoch 802/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7459 - val_loss: 0.1916 - val_accuracy: 0.7279\n",
      "Epoch 803/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.7510 - val_loss: 0.1913 - val_accuracy: 0.7281\n",
      "Epoch 804/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7473 - val_loss: 0.1918 - val_accuracy: 0.7277\n",
      "Epoch 805/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1786 - accuracy: 0.7424 - val_loss: 0.1916 - val_accuracy: 0.7277\n",
      "Epoch 806/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7360 - val_loss: 0.1916 - val_accuracy: 0.7277\n",
      "Epoch 807/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1756 - accuracy: 0.7494 - val_loss: 0.1917 - val_accuracy: 0.7283\n",
      "Epoch 808/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7472 - val_loss: 0.1916 - val_accuracy: 0.7285\n",
      "Epoch 809/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.7443 - val_loss: 0.1915 - val_accuracy: 0.7276\n",
      "Epoch 810/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1766 - accuracy: 0.7455 - val_loss: 0.1914 - val_accuracy: 0.7262\n",
      "Epoch 811/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.7409 - val_loss: 0.1917 - val_accuracy: 0.7289\n",
      "Epoch 812/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.7437 - val_loss: 0.1915 - val_accuracy: 0.7280\n",
      "Epoch 813/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.7476 - val_loss: 0.1913 - val_accuracy: 0.7283\n",
      "Epoch 814/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1761 - accuracy: 0.7455 - val_loss: 0.1912 - val_accuracy: 0.7289\n",
      "Epoch 815/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.7394 - val_loss: 0.1918 - val_accuracy: 0.7279\n",
      "Epoch 816/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.7427 - val_loss: 0.1910 - val_accuracy: 0.7291\n",
      "Epoch 817/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.7486 - val_loss: 0.1916 - val_accuracy: 0.7292\n",
      "Epoch 818/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1757 - accuracy: 0.7435 - val_loss: 0.1916 - val_accuracy: 0.7277\n",
      "Epoch 819/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.7397 - val_loss: 0.1916 - val_accuracy: 0.7287\n",
      "Epoch 820/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1791 - accuracy: 0.7398 - val_loss: 0.1914 - val_accuracy: 0.7289\n",
      "Epoch 821/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7349 - val_loss: 0.1916 - val_accuracy: 0.7289\n",
      "Epoch 822/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.7507 - val_loss: 0.1917 - val_accuracy: 0.7286\n",
      "Epoch 823/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1745 - accuracy: 0.7516 - val_loss: 0.1916 - val_accuracy: 0.7279\n",
      "Epoch 824/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.7417 - val_loss: 0.1912 - val_accuracy: 0.7277\n",
      "Epoch 825/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.7380 - val_loss: 0.1913 - val_accuracy: 0.7280\n",
      "Epoch 826/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.7382 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 827/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.7431 - val_loss: 0.1912 - val_accuracy: 0.7281\n",
      "Epoch 828/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1763 - accuracy: 0.7457 - val_loss: 0.1910 - val_accuracy: 0.7279\n",
      "Epoch 829/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.7486 - val_loss: 0.1911 - val_accuracy: 0.7278\n",
      "Epoch 830/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7397 - val_loss: 0.1909 - val_accuracy: 0.7288\n",
      "Epoch 831/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1756 - accuracy: 0.7475 - val_loss: 0.1913 - val_accuracy: 0.7273\n",
      "Epoch 832/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.7444 - val_loss: 0.1913 - val_accuracy: 0.7282\n",
      "Epoch 833/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1746 - accuracy: 0.7492 - val_loss: 0.1914 - val_accuracy: 0.7272\n",
      "Epoch 834/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.7500 - val_loss: 0.1918 - val_accuracy: 0.7271\n",
      "Epoch 835/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.7415 - val_loss: 0.1915 - val_accuracy: 0.7272\n",
      "Epoch 836/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7361 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 837/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1781 - accuracy: 0.7455 - val_loss: 0.1913 - val_accuracy: 0.7284\n",
      "Epoch 838/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.7443 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 839/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1745 - accuracy: 0.7482 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 840/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1737 - accuracy: 0.7511 - val_loss: 0.1910 - val_accuracy: 0.7278\n",
      "Epoch 841/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1742 - accuracy: 0.7497 - val_loss: 0.1912 - val_accuracy: 0.7277\n",
      "Epoch 842/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.7413 - val_loss: 0.1916 - val_accuracy: 0.7272\n",
      "Epoch 843/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.7417 - val_loss: 0.1920 - val_accuracy: 0.7270\n",
      "Epoch 844/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.7418 - val_loss: 0.1918 - val_accuracy: 0.7274\n",
      "Epoch 845/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1758 - accuracy: 0.7451 - val_loss: 0.1913 - val_accuracy: 0.7285\n",
      "Epoch 846/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1759 - accuracy: 0.7430 - val_loss: 0.1906 - val_accuracy: 0.7290\n",
      "Epoch 847/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.7344 - val_loss: 0.1908 - val_accuracy: 0.7291\n",
      "Epoch 848/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.7459 - val_loss: 0.1913 - val_accuracy: 0.7282\n",
      "Epoch 849/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.7403 - val_loss: 0.1910 - val_accuracy: 0.7277\n",
      "Epoch 850/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1771 - accuracy: 0.7467 - val_loss: 0.1910 - val_accuracy: 0.7286\n",
      "Epoch 851/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.7438 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 852/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.7429 - val_loss: 0.1907 - val_accuracy: 0.7282\n",
      "Epoch 853/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1772 - accuracy: 0.7429 - val_loss: 0.1910 - val_accuracy: 0.7287\n",
      "Epoch 854/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7379 - val_loss: 0.1909 - val_accuracy: 0.7281\n",
      "Epoch 855/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7397 - val_loss: 0.1911 - val_accuracy: 0.7278\n",
      "Epoch 856/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.7457 - val_loss: 0.1914 - val_accuracy: 0.7279\n",
      "Epoch 857/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7472 - val_loss: 0.1909 - val_accuracy: 0.7289\n",
      "Epoch 858/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.7510 - val_loss: 0.1911 - val_accuracy: 0.7285\n",
      "Epoch 859/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7399 - val_loss: 0.1913 - val_accuracy: 0.7283\n",
      "Epoch 860/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7388 - val_loss: 0.1914 - val_accuracy: 0.7282\n",
      "Epoch 861/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7435 - val_loss: 0.1911 - val_accuracy: 0.7278\n",
      "Epoch 862/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7417 - val_loss: 0.1914 - val_accuracy: 0.7274\n",
      "Epoch 863/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1751 - accuracy: 0.7488 - val_loss: 0.1915 - val_accuracy: 0.7271\n",
      "Epoch 864/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.7488 - val_loss: 0.1917 - val_accuracy: 0.7270\n",
      "Epoch 865/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.7518 - val_loss: 0.1921 - val_accuracy: 0.7265\n",
      "Epoch 866/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1771 - accuracy: 0.7430 - val_loss: 0.1913 - val_accuracy: 0.7273\n",
      "Epoch 867/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1760 - accuracy: 0.7465 - val_loss: 0.1912 - val_accuracy: 0.7275\n",
      "Epoch 868/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1770 - accuracy: 0.7438 - val_loss: 0.1928 - val_accuracy: 0.7284\n",
      "Epoch 869/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7450 - val_loss: 0.1907 - val_accuracy: 0.7297\n",
      "Epoch 870/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.7442 - val_loss: 0.1907 - val_accuracy: 0.7286\n",
      "Epoch 871/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.7424 - val_loss: 0.1907 - val_accuracy: 0.7291\n",
      "Epoch 872/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1754 - accuracy: 0.7497 - val_loss: 0.1907 - val_accuracy: 0.7291\n",
      "Epoch 873/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1757 - accuracy: 0.7484 - val_loss: 0.1906 - val_accuracy: 0.7291\n",
      "Epoch 874/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1724 - accuracy: 0.7510 - val_loss: 0.1907 - val_accuracy: 0.7294\n",
      "Epoch 875/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.7433 - val_loss: 0.1913 - val_accuracy: 0.7288\n",
      "Epoch 876/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1735 - accuracy: 0.7532 - val_loss: 0.1911 - val_accuracy: 0.7287\n",
      "Epoch 877/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7476 - val_loss: 0.1908 - val_accuracy: 0.7293\n",
      "Epoch 878/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1743 - accuracy: 0.7506 - val_loss: 0.1906 - val_accuracy: 0.7289\n",
      "Epoch 879/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.7375 - val_loss: 0.1910 - val_accuracy: 0.7283\n",
      "Epoch 880/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1779 - accuracy: 0.7410 - val_loss: 0.1910 - val_accuracy: 0.7284\n",
      "Epoch 881/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1734 - accuracy: 0.7482 - val_loss: 0.1911 - val_accuracy: 0.7280\n",
      "Epoch 882/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1712 - accuracy: 0.7526 - val_loss: 0.1912 - val_accuracy: 0.7278\n",
      "Epoch 883/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.7449 - val_loss: 0.1914 - val_accuracy: 0.7282\n",
      "Epoch 884/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7423 - val_loss: 0.1908 - val_accuracy: 0.7283\n",
      "Epoch 885/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1736 - accuracy: 0.7507 - val_loss: 0.1908 - val_accuracy: 0.7283\n",
      "Epoch 886/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.7382 - val_loss: 0.1912 - val_accuracy: 0.7278\n",
      "Epoch 887/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7440 - val_loss: 0.1916 - val_accuracy: 0.7274\n",
      "Epoch 888/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.7453 - val_loss: 0.1915 - val_accuracy: 0.7274\n",
      "Epoch 889/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.7486 - val_loss: 0.1920 - val_accuracy: 0.7274\n",
      "Epoch 890/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7484 - val_loss: 0.1919 - val_accuracy: 0.7274\n",
      "Epoch 891/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.7409 - val_loss: 0.1920 - val_accuracy: 0.7274\n",
      "Epoch 892/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1740 - accuracy: 0.7504 - val_loss: 0.1921 - val_accuracy: 0.7270\n",
      "Epoch 893/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7457 - val_loss: 0.1913 - val_accuracy: 0.7277\n",
      "Epoch 894/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.7455 - val_loss: 0.1917 - val_accuracy: 0.7277\n",
      "Epoch 895/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7408 - val_loss: 0.1916 - val_accuracy: 0.7274\n",
      "Epoch 896/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7397 - val_loss: 0.1915 - val_accuracy: 0.7274\n",
      "Epoch 897/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.7485 - val_loss: 0.1914 - val_accuracy: 0.7269\n",
      "Epoch 898/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.7491 - val_loss: 0.1911 - val_accuracy: 0.7274\n",
      "Epoch 899/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.7464 - val_loss: 0.1912 - val_accuracy: 0.7277\n",
      "Epoch 900/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1792 - accuracy: 0.7404 - val_loss: 0.1915 - val_accuracy: 0.7294\n",
      "Epoch 901/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1777 - accuracy: 0.7449 - val_loss: 0.1907 - val_accuracy: 0.7286\n",
      "Epoch 902/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.7453 - val_loss: 0.1909 - val_accuracy: 0.7287\n",
      "Epoch 903/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1764 - accuracy: 0.7456 - val_loss: 0.1906 - val_accuracy: 0.7285\n",
      "Epoch 904/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.7397 - val_loss: 0.1908 - val_accuracy: 0.7284\n",
      "Epoch 905/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.7460 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 906/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.7453 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 907/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1765 - accuracy: 0.7400 - val_loss: 0.1911 - val_accuracy: 0.7275\n",
      "Epoch 908/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7459 - val_loss: 0.1911 - val_accuracy: 0.7276\n",
      "Epoch 909/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.7470 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 910/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1770 - accuracy: 0.7459 - val_loss: 0.1911 - val_accuracy: 0.7275\n",
      "Epoch 911/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1758 - accuracy: 0.7477 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 912/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1722 - accuracy: 0.7545 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 913/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7424 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 914/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7375 - val_loss: 0.1911 - val_accuracy: 0.7272\n",
      "Epoch 915/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1773 - accuracy: 0.7429 - val_loss: 0.1909 - val_accuracy: 0.7273\n",
      "Epoch 916/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7383 - val_loss: 0.1910 - val_accuracy: 0.7274\n",
      "Epoch 917/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1755 - accuracy: 0.7459 - val_loss: 0.1913 - val_accuracy: 0.7271\n",
      "Epoch 918/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1735 - accuracy: 0.7515 - val_loss: 0.1911 - val_accuracy: 0.7269\n",
      "Epoch 919/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1763 - accuracy: 0.7475 - val_loss: 0.1913 - val_accuracy: 0.7265\n",
      "Epoch 920/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1758 - accuracy: 0.7491 - val_loss: 0.1909 - val_accuracy: 0.7275\n",
      "Epoch 921/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7423 - val_loss: 0.1909 - val_accuracy: 0.7269\n",
      "Epoch 922/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1745 - accuracy: 0.7496 - val_loss: 0.1909 - val_accuracy: 0.7272\n",
      "Epoch 923/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.7453 - val_loss: 0.1911 - val_accuracy: 0.7269\n",
      "Epoch 924/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1762 - accuracy: 0.7478 - val_loss: 0.1914 - val_accuracy: 0.7266\n",
      "Epoch 925/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1759 - accuracy: 0.7439 - val_loss: 0.1915 - val_accuracy: 0.7269\n",
      "Epoch 926/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1769 - accuracy: 0.7416 - val_loss: 0.1915 - val_accuracy: 0.7269\n",
      "Epoch 927/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.7375 - val_loss: 0.1923 - val_accuracy: 0.7273\n",
      "Epoch 928/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1751 - accuracy: 0.7445 - val_loss: 0.1914 - val_accuracy: 0.7272\n",
      "Epoch 929/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1735 - accuracy: 0.7524 - val_loss: 0.1914 - val_accuracy: 0.7272\n",
      "Epoch 930/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.7493 - val_loss: 0.1919 - val_accuracy: 0.7276\n",
      "Epoch 931/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1737 - accuracy: 0.7536 - val_loss: 0.1912 - val_accuracy: 0.7285\n",
      "Epoch 932/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.7496 - val_loss: 0.1913 - val_accuracy: 0.7283\n",
      "Epoch 933/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.7517 - val_loss: 0.1907 - val_accuracy: 0.7269\n",
      "Epoch 934/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7433 - val_loss: 0.1909 - val_accuracy: 0.7274\n",
      "Epoch 935/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1748 - accuracy: 0.7475 - val_loss: 0.1910 - val_accuracy: 0.7274\n",
      "Epoch 936/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7462 - val_loss: 0.1908 - val_accuracy: 0.7276\n",
      "Epoch 937/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7416 - val_loss: 0.1914 - val_accuracy: 0.7272\n",
      "Epoch 938/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7456 - val_loss: 0.1897 - val_accuracy: 0.7279\n",
      "Epoch 939/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1775 - accuracy: 0.7435 - val_loss: 0.1898 - val_accuracy: 0.7287\n",
      "Epoch 940/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1773 - accuracy: 0.7428 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 941/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1761 - accuracy: 0.7502 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 942/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1778 - accuracy: 0.7414 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 943/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1741 - accuracy: 0.7480 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 944/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.7503 - val_loss: 0.1899 - val_accuracy: 0.7292\n",
      "Epoch 945/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1768 - accuracy: 0.7416 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 946/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.7484 - val_loss: 0.1908 - val_accuracy: 0.7280\n",
      "Epoch 947/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7406 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 948/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1779 - accuracy: 0.7414 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 949/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7415 - val_loss: 0.1912 - val_accuracy: 0.7256\n",
      "Epoch 950/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.7421 - val_loss: 0.1908 - val_accuracy: 0.7261\n",
      "Epoch 951/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1727 - accuracy: 0.7535 - val_loss: 0.1910 - val_accuracy: 0.7256\n",
      "Epoch 952/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1736 - accuracy: 0.7479 - val_loss: 0.1919 - val_accuracy: 0.7260\n",
      "Epoch 953/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1734 - accuracy: 0.7504 - val_loss: 0.1907 - val_accuracy: 0.7261\n",
      "Epoch 954/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1747 - accuracy: 0.7503 - val_loss: 0.1919 - val_accuracy: 0.7252\n",
      "Epoch 955/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7378 - val_loss: 0.1917 - val_accuracy: 0.7251\n",
      "Epoch 956/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1784 - accuracy: 0.7382 - val_loss: 0.1913 - val_accuracy: 0.7250\n",
      "Epoch 957/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.7424 - val_loss: 0.1913 - val_accuracy: 0.7246\n",
      "Epoch 958/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1762 - accuracy: 0.7434 - val_loss: 0.1905 - val_accuracy: 0.7260\n",
      "Epoch 959/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7426 - val_loss: 0.1902 - val_accuracy: 0.7263\n",
      "Epoch 960/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1780 - accuracy: 0.7394 - val_loss: 0.1910 - val_accuracy: 0.7263\n",
      "Epoch 961/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1770 - accuracy: 0.7427 - val_loss: 0.1901 - val_accuracy: 0.7263\n",
      "Epoch 962/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.7489 - val_loss: 0.1906 - val_accuracy: 0.7263\n",
      "Epoch 963/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.7478 - val_loss: 0.1909 - val_accuracy: 0.7245\n",
      "Epoch 964/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1748 - accuracy: 0.7487 - val_loss: 0.1910 - val_accuracy: 0.7245\n",
      "Epoch 965/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.7464 - val_loss: 0.1908 - val_accuracy: 0.7249\n",
      "Epoch 966/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.7483 - val_loss: 0.1907 - val_accuracy: 0.7256\n",
      "Epoch 967/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1764 - accuracy: 0.7472 - val_loss: 0.1905 - val_accuracy: 0.7260\n",
      "Epoch 968/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.7498 - val_loss: 0.1909 - val_accuracy: 0.7258\n",
      "Epoch 969/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1753 - accuracy: 0.7501 - val_loss: 0.1906 - val_accuracy: 0.7258\n",
      "Epoch 970/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1750 - accuracy: 0.7474 - val_loss: 0.1906 - val_accuracy: 0.7262\n",
      "Epoch 971/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1752 - accuracy: 0.7472 - val_loss: 0.1904 - val_accuracy: 0.7279\n",
      "Epoch 972/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.7405 - val_loss: 0.1908 - val_accuracy: 0.7274\n",
      "Epoch 973/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1726 - accuracy: 0.7534 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 974/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1760 - accuracy: 0.7455 - val_loss: 0.1904 - val_accuracy: 0.7275\n",
      "Epoch 975/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1741 - accuracy: 0.7500 - val_loss: 0.1905 - val_accuracy: 0.7274\n",
      "Epoch 976/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.7436 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 977/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1727 - accuracy: 0.7503 - val_loss: 0.1911 - val_accuracy: 0.7277\n",
      "Epoch 978/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1769 - accuracy: 0.7453 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 979/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1735 - accuracy: 0.7525 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 980/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.7478 - val_loss: 0.1907 - val_accuracy: 0.7275\n",
      "Epoch 981/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.7460 - val_loss: 0.1908 - val_accuracy: 0.7280\n",
      "Epoch 982/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7359 - val_loss: 0.1914 - val_accuracy: 0.7282\n",
      "Epoch 983/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1788 - accuracy: 0.7424 - val_loss: 0.1912 - val_accuracy: 0.7282\n",
      "Epoch 984/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1784 - accuracy: 0.7429 - val_loss: 0.1908 - val_accuracy: 0.7281\n",
      "Epoch 985/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1800 - accuracy: 0.7393 - val_loss: 0.1898 - val_accuracy: 0.7286\n",
      "Epoch 986/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7426 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 987/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1763 - accuracy: 0.7466 - val_loss: 0.1900 - val_accuracy: 0.7274\n",
      "Epoch 988/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.7402 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 989/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1738 - accuracy: 0.7513 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 990/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7432 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 991/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1749 - accuracy: 0.7494 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 992/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1769 - accuracy: 0.7423 - val_loss: 0.1906 - val_accuracy: 0.7279\n",
      "Epoch 993/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1726 - accuracy: 0.7532 - val_loss: 0.1906 - val_accuracy: 0.7256\n",
      "Epoch 994/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7402 - val_loss: 0.1902 - val_accuracy: 0.7261\n",
      "Epoch 995/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1776 - accuracy: 0.7424 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 996/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1774 - accuracy: 0.7422 - val_loss: 0.1908 - val_accuracy: 0.7279\n",
      "Epoch 997/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1729 - accuracy: 0.7532 - val_loss: 0.1908 - val_accuracy: 0.7284\n",
      "Epoch 998/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.7451 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 999/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1742 - accuracy: 0.7498 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 1000/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.7499 - val_loss: 0.1900 - val_accuracy: 0.7287\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A20 = nn_A20.fit(X_train_scaled, y_train, validation_split=0.6, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 5 Results\n",
      "Loss: 0.19056975841522217, Accuracy: 0.7264139652252197\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 20 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A20.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Model 21+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A21 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A21 =  (number_input_features + number_output_neurons_A21) // 2\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A21 =  (hidden_nodes_layer1_A21 + number_output_neurons_A21) // 2\n",
    "# Review the number of hidden nodes in the second layer\n",
    "hidden_nodes_layer2_A21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\n",
    "hidden_nodes_layer3_A21 =  (hidden_nodes_layer2_A21 + number_output_neurons_A21) // 2\n",
    "# Review the number of hidden nodes in the third layer\n",
    "hidden_nodes_layer3_A21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fourth hidden layer\n",
    "hidden_nodes_layer4_A21 =  (hidden_nodes_layer3_A21 + number_output_neurons_A21) // 2\n",
    "# Review the number of hidden nodes in the fourth layer\n",
    "hidden_nodes_layer4_A21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fifth hidden layer\n",
    "hidden_nodes_layer5_A21 =  (hidden_nodes_layer4_A21 + number_output_neurons_A21) // 2\n",
    "# Review the number of hidden nodes in the fifth layer\n",
    "hidden_nodes_layer5_A21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the Sixth hidden layer\n",
    "hidden_nodes_layer6_A21 =  (hidden_nodes_layer5_A21 + number_output_neurons_A21) // 2\n",
    "# Review the number of hidden nodes in the sixth layer\n",
    "hidden_nodes_layer6_A21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 57)                6555      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 29)                1682      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 8,864\n",
      "Trainable params: 8,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Display the Sequential Model Instance \n",
    "# for Model A21\n",
    "nn_A21 = Sequential() \n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_A21.add(Dense(units=hidden_nodes_layer1_A21, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the second hidden layer\n",
    "nn_A21.add(Dense(units=hidden_nodes_layer2_A21, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the third hidden layer\n",
    "nn_A21.add(Dense(units=hidden_nodes_layer3_A21, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fourth hidden layer\n",
    "nn_A21.add(Dense(units=hidden_nodes_layer4_A21, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fifth hidden layer\n",
    "nn_A21.add(Dense(units=hidden_nodes_layer5_A21, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the sixth hidden layer\n",
    "nn_A21.add(Dense(units=hidden_nodes_layer6_A21, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_A21.add(Dense(units=number_output_neurons_A21, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_A21.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A21.compile(loss=\"mse\", optimizer=\"adadelta\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.5297 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.5346 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5284 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5259 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5300 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5392 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5266 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.5351 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.5359 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.5254 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2493 - accuracy: 0.5346 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5328 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2496 - accuracy: 0.5246 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 14/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5255 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5364 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5352 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5330 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2494 - accuracy: 0.5389 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5334 - val_loss: 0.2493 - val_accuracy: 0.5347\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5329 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5301 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2494 - accuracy: 0.5232 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5297 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 24/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5295 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5304 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5268 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2495 - accuracy: 0.5168 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5322 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5328 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5238 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5322 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5363 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5300 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5329 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5325 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5331 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5326 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5324 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5319 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5336 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5318 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5306 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5249 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5286 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5369 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5315 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5313 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5359 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5343 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5340 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2493 - accuracy: 0.5272 - val_loss: 0.2490 - val_accuracy: 0.5347\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5348 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5371 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5329 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5362 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5367 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5407 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5392 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5319 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5283 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5339 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.5425 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5364 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5335 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5387 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.5362 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.5324 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5273 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5299 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2492 - accuracy: 0.5248 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5339 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5261 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5319 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5216 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5356 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.5271 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.5284 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2490 - accuracy: 0.5238 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2489 - accuracy: 0.5286 - val_loss: 0.2487 - val_accuracy: 0.5347\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2485 - accuracy: 0.5352 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.5330 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5367 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5405 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.5331 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.5222 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5333 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 87/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2489 - accuracy: 0.5286 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5327 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2485 - accuracy: 0.5310 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2483 - accuracy: 0.5350 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5311 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.5240 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5312 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5203 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2486 - accuracy: 0.5229 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2488 - accuracy: 0.5297 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5320 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 98/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5340 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5360 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2488 - accuracy: 0.5275 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2487 - accuracy: 0.5270 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5292 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5244 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5372 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5281 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5281 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5321 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5257 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5290 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5238 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2485 - accuracy: 0.5294 - val_loss: 0.2483 - val_accuracy: 0.5347\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5319 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5360 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5262 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5301 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5264 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.5352 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5313 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.5376 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5398 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5342 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5342 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2483 - accuracy: 0.5317 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5334 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5278 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5294 - val_loss: 0.2480 - val_accuracy: 0.5347\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5382 - val_loss: 0.2480 - val_accuracy: 0.5347\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5334 - val_loss: 0.2480 - val_accuracy: 0.5347\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.5409 - val_loss: 0.2480 - val_accuracy: 0.5347\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5361 - val_loss: 0.2480 - val_accuracy: 0.5347\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5242 - val_loss: 0.2480 - val_accuracy: 0.5347\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5371 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.5361 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 134/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5362 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 135/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5368 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 136/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2480 - accuracy: 0.5324 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 137/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2476 - accuracy: 0.5423 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 138/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2481 - accuracy: 0.5262 - val_loss: 0.2478 - val_accuracy: 0.5347\n",
      "Epoch 139/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2482 - accuracy: 0.5260 - val_loss: 0.2478 - val_accuracy: 0.5347\n",
      "Epoch 140/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.5304 - val_loss: 0.2478 - val_accuracy: 0.5347\n",
      "Epoch 141/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.5286 - val_loss: 0.2478 - val_accuracy: 0.5347\n",
      "Epoch 142/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2477 - accuracy: 0.5316 - val_loss: 0.2478 - val_accuracy: 0.5347\n",
      "Epoch 143/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5335 - val_loss: 0.2478 - val_accuracy: 0.5347\n",
      "Epoch 144/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5274 - val_loss: 0.2477 - val_accuracy: 0.5347\n",
      "Epoch 145/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5266 - val_loss: 0.2477 - val_accuracy: 0.5347\n",
      "Epoch 146/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5213 - val_loss: 0.2477 - val_accuracy: 0.5347\n",
      "Epoch 147/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5264 - val_loss: 0.2477 - val_accuracy: 0.5347\n",
      "Epoch 148/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2477 - accuracy: 0.5395 - val_loss: 0.2477 - val_accuracy: 0.5347\n",
      "Epoch 149/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5281 - val_loss: 0.2476 - val_accuracy: 0.5347\n",
      "Epoch 150/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5271 - val_loss: 0.2476 - val_accuracy: 0.5347\n",
      "Epoch 151/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5325 - val_loss: 0.2476 - val_accuracy: 0.5347\n",
      "Epoch 152/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.5280 - val_loss: 0.2476 - val_accuracy: 0.5347\n",
      "Epoch 153/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.5311 - val_loss: 0.2476 - val_accuracy: 0.5347\n",
      "Epoch 154/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.5286 - val_loss: 0.2475 - val_accuracy: 0.5347\n",
      "Epoch 155/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.5368 - val_loss: 0.2475 - val_accuracy: 0.5347\n",
      "Epoch 156/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.5323 - val_loss: 0.2475 - val_accuracy: 0.5347\n",
      "Epoch 157/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.5435 - val_loss: 0.2475 - val_accuracy: 0.5347\n",
      "Epoch 158/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.5446 - val_loss: 0.2475 - val_accuracy: 0.5347\n",
      "Epoch 159/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5444 - val_loss: 0.2474 - val_accuracy: 0.5347\n",
      "Epoch 160/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.5279 - val_loss: 0.2474 - val_accuracy: 0.5347\n",
      "Epoch 161/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.5327 - val_loss: 0.2474 - val_accuracy: 0.5347\n",
      "Epoch 162/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.5252 - val_loss: 0.2474 - val_accuracy: 0.5347\n",
      "Epoch 163/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2474 - accuracy: 0.5335 - val_loss: 0.2474 - val_accuracy: 0.5347\n",
      "Epoch 164/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2477 - accuracy: 0.5285 - val_loss: 0.2473 - val_accuracy: 0.5347\n",
      "Epoch 165/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.5300 - val_loss: 0.2473 - val_accuracy: 0.5347\n",
      "Epoch 166/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.5306 - val_loss: 0.2473 - val_accuracy: 0.5347\n",
      "Epoch 167/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5230 - val_loss: 0.2473 - val_accuracy: 0.5347\n",
      "Epoch 168/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.5324 - val_loss: 0.2473 - val_accuracy: 0.5347\n",
      "Epoch 169/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.5337 - val_loss: 0.2472 - val_accuracy: 0.5347\n",
      "Epoch 170/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.5365 - val_loss: 0.2472 - val_accuracy: 0.5347\n",
      "Epoch 171/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2473 - accuracy: 0.5301 - val_loss: 0.2472 - val_accuracy: 0.5347\n",
      "Epoch 172/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.5299 - val_loss: 0.2472 - val_accuracy: 0.5347\n",
      "Epoch 173/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2472 - accuracy: 0.5338 - val_loss: 0.2472 - val_accuracy: 0.5347\n",
      "Epoch 174/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.5323 - val_loss: 0.2471 - val_accuracy: 0.5347\n",
      "Epoch 175/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2471 - accuracy: 0.5360 - val_loss: 0.2471 - val_accuracy: 0.5347\n",
      "Epoch 176/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2475 - accuracy: 0.5236 - val_loss: 0.2471 - val_accuracy: 0.5347\n",
      "Epoch 177/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5197 - val_loss: 0.2471 - val_accuracy: 0.5347\n",
      "Epoch 178/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.5362 - val_loss: 0.2470 - val_accuracy: 0.5347\n",
      "Epoch 179/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2475 - accuracy: 0.5369 - val_loss: 0.2470 - val_accuracy: 0.5347\n",
      "Epoch 180/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.5277 - val_loss: 0.2470 - val_accuracy: 0.5347\n",
      "Epoch 181/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.5420 - val_loss: 0.2470 - val_accuracy: 0.5347\n",
      "Epoch 182/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2474 - accuracy: 0.5245 - val_loss: 0.2470 - val_accuracy: 0.5347\n",
      "Epoch 183/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.5349 - val_loss: 0.2469 - val_accuracy: 0.5347\n",
      "Epoch 184/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.5363 - val_loss: 0.2469 - val_accuracy: 0.5347\n",
      "Epoch 185/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.5309 - val_loss: 0.2469 - val_accuracy: 0.5347\n",
      "Epoch 186/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.5362 - val_loss: 0.2469 - val_accuracy: 0.5347\n",
      "Epoch 187/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2468 - accuracy: 0.5308 - val_loss: 0.2468 - val_accuracy: 0.5347\n",
      "Epoch 188/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5305 - val_loss: 0.2468 - val_accuracy: 0.5347\n",
      "Epoch 189/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.5277 - val_loss: 0.2468 - val_accuracy: 0.5347\n",
      "Epoch 190/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2468 - accuracy: 0.5306 - val_loss: 0.2468 - val_accuracy: 0.5347\n",
      "Epoch 191/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.5301 - val_loss: 0.2467 - val_accuracy: 0.5347\n",
      "Epoch 192/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2470 - accuracy: 0.5332 - val_loss: 0.2467 - val_accuracy: 0.5347\n",
      "Epoch 193/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5349 - val_loss: 0.2467 - val_accuracy: 0.5347\n",
      "Epoch 194/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.5302 - val_loss: 0.2467 - val_accuracy: 0.5347\n",
      "Epoch 195/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.5385 - val_loss: 0.2466 - val_accuracy: 0.5347\n",
      "Epoch 196/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.5276 - val_loss: 0.2466 - val_accuracy: 0.5347\n",
      "Epoch 197/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.5351 - val_loss: 0.2466 - val_accuracy: 0.5347\n",
      "Epoch 198/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.5277 - val_loss: 0.2465 - val_accuracy: 0.5347\n",
      "Epoch 199/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5221 - val_loss: 0.2465 - val_accuracy: 0.5347\n",
      "Epoch 200/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5283 - val_loss: 0.2465 - val_accuracy: 0.5347\n",
      "Epoch 201/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5376 - val_loss: 0.2465 - val_accuracy: 0.5347\n",
      "Epoch 202/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5362 - val_loss: 0.2464 - val_accuracy: 0.5347\n",
      "Epoch 203/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.5333 - val_loss: 0.2464 - val_accuracy: 0.5347\n",
      "Epoch 204/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5218 - val_loss: 0.2464 - val_accuracy: 0.5347\n",
      "Epoch 205/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.5365 - val_loss: 0.2464 - val_accuracy: 0.5347\n",
      "Epoch 206/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.5219 - val_loss: 0.2463 - val_accuracy: 0.5347\n",
      "Epoch 207/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5382 - val_loss: 0.2463 - val_accuracy: 0.5347\n",
      "Epoch 208/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2467 - accuracy: 0.5342 - val_loss: 0.2463 - val_accuracy: 0.5347\n",
      "Epoch 209/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2466 - accuracy: 0.5324 - val_loss: 0.2462 - val_accuracy: 0.5347\n",
      "Epoch 210/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.5281 - val_loss: 0.2462 - val_accuracy: 0.5347\n",
      "Epoch 211/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.5354 - val_loss: 0.2462 - val_accuracy: 0.5347\n",
      "Epoch 212/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.5373 - val_loss: 0.2462 - val_accuracy: 0.5347\n",
      "Epoch 213/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.5312 - val_loss: 0.2461 - val_accuracy: 0.5347\n",
      "Epoch 214/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2465 - accuracy: 0.5261 - val_loss: 0.2461 - val_accuracy: 0.5347\n",
      "Epoch 215/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5310 - val_loss: 0.2461 - val_accuracy: 0.5347\n",
      "Epoch 216/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.5270 - val_loss: 0.2460 - val_accuracy: 0.5347\n",
      "Epoch 217/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5322 - val_loss: 0.2460 - val_accuracy: 0.5347\n",
      "Epoch 218/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.5318 - val_loss: 0.2460 - val_accuracy: 0.5347\n",
      "Epoch 219/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5319 - val_loss: 0.2459 - val_accuracy: 0.5347\n",
      "Epoch 220/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.5316 - val_loss: 0.2459 - val_accuracy: 0.5347\n",
      "Epoch 221/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.5320 - val_loss: 0.2459 - val_accuracy: 0.5347\n",
      "Epoch 222/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2460 - accuracy: 0.5327 - val_loss: 0.2458 - val_accuracy: 0.5347\n",
      "Epoch 223/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2464 - accuracy: 0.5301 - val_loss: 0.2458 - val_accuracy: 0.5347\n",
      "Epoch 224/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.5333 - val_loss: 0.2458 - val_accuracy: 0.5347\n",
      "Epoch 225/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2461 - accuracy: 0.5316 - val_loss: 0.2457 - val_accuracy: 0.5347\n",
      "Epoch 226/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.5360 - val_loss: 0.2457 - val_accuracy: 0.5347\n",
      "Epoch 227/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5376 - val_loss: 0.2457 - val_accuracy: 0.5347\n",
      "Epoch 228/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5352 - val_loss: 0.2456 - val_accuracy: 0.5347\n",
      "Epoch 229/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2463 - accuracy: 0.5228 - val_loss: 0.2456 - val_accuracy: 0.5347\n",
      "Epoch 230/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.5271 - val_loss: 0.2456 - val_accuracy: 0.5347\n",
      "Epoch 231/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.5314 - val_loss: 0.2455 - val_accuracy: 0.5347\n",
      "Epoch 232/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.5357 - val_loss: 0.2455 - val_accuracy: 0.5347\n",
      "Epoch 233/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.5333 - val_loss: 0.2455 - val_accuracy: 0.5347\n",
      "Epoch 234/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.5383 - val_loss: 0.2454 - val_accuracy: 0.5347\n",
      "Epoch 235/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.5270 - val_loss: 0.2454 - val_accuracy: 0.5347\n",
      "Epoch 236/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.5290 - val_loss: 0.2454 - val_accuracy: 0.5347\n",
      "Epoch 237/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.5282 - val_loss: 0.2453 - val_accuracy: 0.5347\n",
      "Epoch 238/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2458 - accuracy: 0.5351 - val_loss: 0.2453 - val_accuracy: 0.5347\n",
      "Epoch 239/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2454 - accuracy: 0.5306 - val_loss: 0.2453 - val_accuracy: 0.5347\n",
      "Epoch 240/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.5360 - val_loss: 0.2452 - val_accuracy: 0.5347\n",
      "Epoch 241/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.5380 - val_loss: 0.2452 - val_accuracy: 0.5347\n",
      "Epoch 242/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5344 - val_loss: 0.2451 - val_accuracy: 0.5347\n",
      "Epoch 243/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2452 - accuracy: 0.5331 - val_loss: 0.2451 - val_accuracy: 0.5347\n",
      "Epoch 244/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2453 - accuracy: 0.5332 - val_loss: 0.2451 - val_accuracy: 0.5347\n",
      "Epoch 245/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5323 - val_loss: 0.2450 - val_accuracy: 0.5347\n",
      "Epoch 246/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5235 - val_loss: 0.2450 - val_accuracy: 0.5347\n",
      "Epoch 247/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.5342 - val_loss: 0.2450 - val_accuracy: 0.5347\n",
      "Epoch 248/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2451 - accuracy: 0.5355 - val_loss: 0.2449 - val_accuracy: 0.5347\n",
      "Epoch 249/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2450 - accuracy: 0.5335 - val_loss: 0.2449 - val_accuracy: 0.5347\n",
      "Epoch 250/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.5313 - val_loss: 0.2448 - val_accuracy: 0.5347\n",
      "Epoch 251/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2449 - accuracy: 0.5292 - val_loss: 0.2448 - val_accuracy: 0.5347\n",
      "Epoch 252/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.5282 - val_loss: 0.2448 - val_accuracy: 0.5347\n",
      "Epoch 253/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2455 - accuracy: 0.5362 - val_loss: 0.2447 - val_accuracy: 0.5347\n",
      "Epoch 254/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2451 - accuracy: 0.5320 - val_loss: 0.2447 - val_accuracy: 0.5347\n",
      "Epoch 255/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2453 - accuracy: 0.5344 - val_loss: 0.2446 - val_accuracy: 0.5347\n",
      "Epoch 256/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.5323 - val_loss: 0.2446 - val_accuracy: 0.5347\n",
      "Epoch 257/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.5395 - val_loss: 0.2445 - val_accuracy: 0.5347\n",
      "Epoch 258/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.5326 - val_loss: 0.2445 - val_accuracy: 0.5347\n",
      "Epoch 259/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2448 - accuracy: 0.5290 - val_loss: 0.2445 - val_accuracy: 0.5347\n",
      "Epoch 260/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.5334 - val_loss: 0.2444 - val_accuracy: 0.5347\n",
      "Epoch 261/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2448 - accuracy: 0.5296 - val_loss: 0.2444 - val_accuracy: 0.5347\n",
      "Epoch 262/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2450 - accuracy: 0.5257 - val_loss: 0.2443 - val_accuracy: 0.5347\n",
      "Epoch 263/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2451 - accuracy: 0.5272 - val_loss: 0.2443 - val_accuracy: 0.5347\n",
      "Epoch 264/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2445 - accuracy: 0.5288 - val_loss: 0.2442 - val_accuracy: 0.5347\n",
      "Epoch 265/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5360 - val_loss: 0.2442 - val_accuracy: 0.5347\n",
      "Epoch 266/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.5344 - val_loss: 0.2442 - val_accuracy: 0.5347\n",
      "Epoch 267/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.5262 - val_loss: 0.2441 - val_accuracy: 0.5347\n",
      "Epoch 268/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.5364 - val_loss: 0.2441 - val_accuracy: 0.5347\n",
      "Epoch 269/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.5363 - val_loss: 0.2440 - val_accuracy: 0.5347\n",
      "Epoch 270/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2446 - accuracy: 0.5334 - val_loss: 0.2440 - val_accuracy: 0.5347\n",
      "Epoch 271/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2440 - accuracy: 0.5326 - val_loss: 0.2439 - val_accuracy: 0.5347\n",
      "Epoch 272/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2438 - accuracy: 0.5358 - val_loss: 0.2439 - val_accuracy: 0.5347\n",
      "Epoch 273/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2447 - accuracy: 0.5210 - val_loss: 0.2438 - val_accuracy: 0.5347\n",
      "Epoch 274/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2438 - accuracy: 0.5356 - val_loss: 0.2438 - val_accuracy: 0.5347\n",
      "Epoch 275/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.5253 - val_loss: 0.2437 - val_accuracy: 0.5347\n",
      "Epoch 276/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.5297 - val_loss: 0.2437 - val_accuracy: 0.5347\n",
      "Epoch 277/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.5372 - val_loss: 0.2436 - val_accuracy: 0.5347\n",
      "Epoch 278/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.5345 - val_loss: 0.2436 - val_accuracy: 0.5347\n",
      "Epoch 279/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2444 - accuracy: 0.5286 - val_loss: 0.2435 - val_accuracy: 0.5347\n",
      "Epoch 280/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2443 - accuracy: 0.5344 - val_loss: 0.2435 - val_accuracy: 0.5347\n",
      "Epoch 281/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.5296 - val_loss: 0.2434 - val_accuracy: 0.5347\n",
      "Epoch 282/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.5316 - val_loss: 0.2434 - val_accuracy: 0.5347\n",
      "Epoch 283/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2436 - accuracy: 0.5333 - val_loss: 0.2433 - val_accuracy: 0.5347\n",
      "Epoch 284/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2432 - accuracy: 0.5314 - val_loss: 0.2433 - val_accuracy: 0.5347\n",
      "Epoch 285/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.5363 - val_loss: 0.2432 - val_accuracy: 0.5347\n",
      "Epoch 286/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2428 - accuracy: 0.5422 - val_loss: 0.2432 - val_accuracy: 0.5347\n",
      "Epoch 287/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.5310 - val_loss: 0.2431 - val_accuracy: 0.5347\n",
      "Epoch 288/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2435 - accuracy: 0.5319 - val_loss: 0.2431 - val_accuracy: 0.5347\n",
      "Epoch 289/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.5320 - val_loss: 0.2430 - val_accuracy: 0.5347\n",
      "Epoch 290/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2432 - accuracy: 0.5288 - val_loss: 0.2430 - val_accuracy: 0.5347\n",
      "Epoch 291/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2434 - accuracy: 0.5327 - val_loss: 0.2429 - val_accuracy: 0.5347\n",
      "Epoch 292/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2432 - accuracy: 0.5271 - val_loss: 0.2429 - val_accuracy: 0.5347\n",
      "Epoch 293/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2437 - accuracy: 0.5248 - val_loss: 0.2428 - val_accuracy: 0.5347\n",
      "Epoch 294/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2440 - accuracy: 0.5252 - val_loss: 0.2428 - val_accuracy: 0.5347\n",
      "Epoch 295/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.5260 - val_loss: 0.2427 - val_accuracy: 0.5347\n",
      "Epoch 296/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.5228 - val_loss: 0.2427 - val_accuracy: 0.5347\n",
      "Epoch 297/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.5397 - val_loss: 0.2426 - val_accuracy: 0.5347\n",
      "Epoch 298/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.5253 - val_loss: 0.2425 - val_accuracy: 0.5347\n",
      "Epoch 299/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2435 - accuracy: 0.5362 - val_loss: 0.2425 - val_accuracy: 0.5347\n",
      "Epoch 300/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.5348 - val_loss: 0.2424 - val_accuracy: 0.5347\n",
      "Epoch 301/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2427 - accuracy: 0.5293 - val_loss: 0.2424 - val_accuracy: 0.5347\n",
      "Epoch 302/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2417 - accuracy: 0.5430 - val_loss: 0.2423 - val_accuracy: 0.5347\n",
      "Epoch 303/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2426 - accuracy: 0.5284 - val_loss: 0.2423 - val_accuracy: 0.5347\n",
      "Epoch 304/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2424 - accuracy: 0.5386 - val_loss: 0.2422 - val_accuracy: 0.5347\n",
      "Epoch 305/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2430 - accuracy: 0.5328 - val_loss: 0.2422 - val_accuracy: 0.5347\n",
      "Epoch 306/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.5363 - val_loss: 0.2421 - val_accuracy: 0.5347\n",
      "Epoch 307/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.5286 - val_loss: 0.2420 - val_accuracy: 0.5347\n",
      "Epoch 308/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2424 - accuracy: 0.5359 - val_loss: 0.2420 - val_accuracy: 0.5347\n",
      "Epoch 309/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.5278 - val_loss: 0.2419 - val_accuracy: 0.5347\n",
      "Epoch 310/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2422 - accuracy: 0.5297 - val_loss: 0.2419 - val_accuracy: 0.5347\n",
      "Epoch 311/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.5328 - val_loss: 0.2418 - val_accuracy: 0.5347\n",
      "Epoch 312/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.5254 - val_loss: 0.2417 - val_accuracy: 0.5347\n",
      "Epoch 313/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2417 - accuracy: 0.5334 - val_loss: 0.2417 - val_accuracy: 0.5347\n",
      "Epoch 314/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2423 - accuracy: 0.5309 - val_loss: 0.2416 - val_accuracy: 0.5347\n",
      "Epoch 315/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.5252 - val_loss: 0.2416 - val_accuracy: 0.5347\n",
      "Epoch 316/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2431 - accuracy: 0.5238 - val_loss: 0.2415 - val_accuracy: 0.5347\n",
      "Epoch 317/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2419 - accuracy: 0.5316 - val_loss: 0.2414 - val_accuracy: 0.5347\n",
      "Epoch 318/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2420 - accuracy: 0.5337 - val_loss: 0.2414 - val_accuracy: 0.5347\n",
      "Epoch 319/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.5220 - val_loss: 0.2413 - val_accuracy: 0.5347\n",
      "Epoch 320/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2425 - accuracy: 0.5318 - val_loss: 0.2413 - val_accuracy: 0.5347\n",
      "Epoch 321/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.5366 - val_loss: 0.2412 - val_accuracy: 0.5347\n",
      "Epoch 322/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.5325 - val_loss: 0.2411 - val_accuracy: 0.5347\n",
      "Epoch 323/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.5272 - val_loss: 0.2411 - val_accuracy: 0.5347\n",
      "Epoch 324/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.5303 - val_loss: 0.2410 - val_accuracy: 0.5347\n",
      "Epoch 325/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2415 - accuracy: 0.5296 - val_loss: 0.2409 - val_accuracy: 0.5347\n",
      "Epoch 326/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.5320 - val_loss: 0.2409 - val_accuracy: 0.5347\n",
      "Epoch 327/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.5300 - val_loss: 0.2408 - val_accuracy: 0.5347\n",
      "Epoch 328/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.5311 - val_loss: 0.2407 - val_accuracy: 0.5347\n",
      "Epoch 329/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2412 - accuracy: 0.5283 - val_loss: 0.2407 - val_accuracy: 0.5347\n",
      "Epoch 330/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.5336 - val_loss: 0.2406 - val_accuracy: 0.5347\n",
      "Epoch 331/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.5292 - val_loss: 0.2406 - val_accuracy: 0.5347\n",
      "Epoch 332/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.5333 - val_loss: 0.2405 - val_accuracy: 0.5347\n",
      "Epoch 333/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2410 - accuracy: 0.5305 - val_loss: 0.2404 - val_accuracy: 0.5347\n",
      "Epoch 334/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2404 - accuracy: 0.5394 - val_loss: 0.2404 - val_accuracy: 0.5347\n",
      "Epoch 335/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.5299 - val_loss: 0.2403 - val_accuracy: 0.5347\n",
      "Epoch 336/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.5291 - val_loss: 0.2402 - val_accuracy: 0.5347\n",
      "Epoch 337/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.5333 - val_loss: 0.2402 - val_accuracy: 0.5347\n",
      "Epoch 338/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.5323 - val_loss: 0.2401 - val_accuracy: 0.5347\n",
      "Epoch 339/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2399 - accuracy: 0.5364 - val_loss: 0.2400 - val_accuracy: 0.5347\n",
      "Epoch 340/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.5316 - val_loss: 0.2400 - val_accuracy: 0.5347\n",
      "Epoch 341/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.5345 - val_loss: 0.2399 - val_accuracy: 0.5347\n",
      "Epoch 342/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2408 - accuracy: 0.5267 - val_loss: 0.2398 - val_accuracy: 0.5347\n",
      "Epoch 343/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2402 - accuracy: 0.5306 - val_loss: 0.2398 - val_accuracy: 0.5347\n",
      "Epoch 344/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.5322 - val_loss: 0.2397 - val_accuracy: 0.5347\n",
      "Epoch 345/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2406 - accuracy: 0.5303 - val_loss: 0.2396 - val_accuracy: 0.5347\n",
      "Epoch 346/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2405 - accuracy: 0.5304 - val_loss: 0.2395 - val_accuracy: 0.5347\n",
      "Epoch 347/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.5303 - val_loss: 0.2395 - val_accuracy: 0.5347\n",
      "Epoch 348/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.5310 - val_loss: 0.2394 - val_accuracy: 0.5347\n",
      "Epoch 349/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2398 - accuracy: 0.5327 - val_loss: 0.2393 - val_accuracy: 0.5347\n",
      "Epoch 350/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2400 - accuracy: 0.5283 - val_loss: 0.2393 - val_accuracy: 0.5347\n",
      "Epoch 351/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.5355 - val_loss: 0.2392 - val_accuracy: 0.5347\n",
      "Epoch 352/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2404 - accuracy: 0.5250 - val_loss: 0.2391 - val_accuracy: 0.5347\n",
      "Epoch 353/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2386 - accuracy: 0.5343 - val_loss: 0.2390 - val_accuracy: 0.5347\n",
      "Epoch 354/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2396 - accuracy: 0.5283 - val_loss: 0.2390 - val_accuracy: 0.5347\n",
      "Epoch 355/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2389 - accuracy: 0.5368 - val_loss: 0.2389 - val_accuracy: 0.5347\n",
      "Epoch 356/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2396 - accuracy: 0.5305 - val_loss: 0.2388 - val_accuracy: 0.5347\n",
      "Epoch 357/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2406 - accuracy: 0.5228 - val_loss: 0.2387 - val_accuracy: 0.5347\n",
      "Epoch 358/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2381 - accuracy: 0.5393 - val_loss: 0.2387 - val_accuracy: 0.5347\n",
      "Epoch 359/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2394 - accuracy: 0.5353 - val_loss: 0.2386 - val_accuracy: 0.5347\n",
      "Epoch 360/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.5179 - val_loss: 0.2385 - val_accuracy: 0.5347\n",
      "Epoch 361/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2392 - accuracy: 0.5274 - val_loss: 0.2384 - val_accuracy: 0.5347\n",
      "Epoch 362/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2389 - accuracy: 0.5315 - val_loss: 0.2384 - val_accuracy: 0.5347\n",
      "Epoch 363/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2402 - accuracy: 0.5244 - val_loss: 0.2383 - val_accuracy: 0.5347\n",
      "Epoch 364/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2395 - accuracy: 0.5246 - val_loss: 0.2382 - val_accuracy: 0.5347\n",
      "Epoch 365/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2384 - accuracy: 0.5361 - val_loss: 0.2381 - val_accuracy: 0.5347\n",
      "Epoch 366/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.5332 - val_loss: 0.2381 - val_accuracy: 0.5347\n",
      "Epoch 367/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2391 - accuracy: 0.5301 - val_loss: 0.2380 - val_accuracy: 0.5347\n",
      "Epoch 368/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.5408 - val_loss: 0.2379 - val_accuracy: 0.5347\n",
      "Epoch 369/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2386 - accuracy: 0.5276 - val_loss: 0.2378 - val_accuracy: 0.5347\n",
      "Epoch 370/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2382 - accuracy: 0.5391 - val_loss: 0.2378 - val_accuracy: 0.5347\n",
      "Epoch 371/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2384 - accuracy: 0.5289 - val_loss: 0.2377 - val_accuracy: 0.5347\n",
      "Epoch 372/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2383 - accuracy: 0.5300 - val_loss: 0.2376 - val_accuracy: 0.5347\n",
      "Epoch 373/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2385 - accuracy: 0.5289 - val_loss: 0.2375 - val_accuracy: 0.5347\n",
      "Epoch 374/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.5192 - val_loss: 0.2374 - val_accuracy: 0.5347\n",
      "Epoch 375/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2372 - accuracy: 0.5348 - val_loss: 0.2374 - val_accuracy: 0.5347\n",
      "Epoch 376/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2388 - accuracy: 0.5285 - val_loss: 0.2373 - val_accuracy: 0.5347\n",
      "Epoch 377/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.5368 - val_loss: 0.2372 - val_accuracy: 0.5347\n",
      "Epoch 378/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2374 - accuracy: 0.5300 - val_loss: 0.2371 - val_accuracy: 0.5347\n",
      "Epoch 379/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2375 - accuracy: 0.5349 - val_loss: 0.2371 - val_accuracy: 0.5347\n",
      "Epoch 380/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.5335 - val_loss: 0.2370 - val_accuracy: 0.5347\n",
      "Epoch 381/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2376 - accuracy: 0.5278 - val_loss: 0.2369 - val_accuracy: 0.5347\n",
      "Epoch 382/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2374 - accuracy: 0.5233 - val_loss: 0.2368 - val_accuracy: 0.5347\n",
      "Epoch 383/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2373 - accuracy: 0.5304 - val_loss: 0.2367 - val_accuracy: 0.5347\n",
      "Epoch 384/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2374 - accuracy: 0.5316 - val_loss: 0.2367 - val_accuracy: 0.5347\n",
      "Epoch 385/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.5320 - val_loss: 0.2366 - val_accuracy: 0.5347\n",
      "Epoch 386/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2370 - accuracy: 0.5397 - val_loss: 0.2365 - val_accuracy: 0.5347\n",
      "Epoch 387/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.5289 - val_loss: 0.2364 - val_accuracy: 0.5347\n",
      "Epoch 388/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2359 - accuracy: 0.5337 - val_loss: 0.2363 - val_accuracy: 0.5347\n",
      "Epoch 389/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2359 - accuracy: 0.5373 - val_loss: 0.2362 - val_accuracy: 0.5347\n",
      "Epoch 390/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2367 - accuracy: 0.5274 - val_loss: 0.2362 - val_accuracy: 0.5347\n",
      "Epoch 391/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.5334 - val_loss: 0.2361 - val_accuracy: 0.5347\n",
      "Epoch 392/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2376 - accuracy: 0.5270 - val_loss: 0.2360 - val_accuracy: 0.5347\n",
      "Epoch 393/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2369 - accuracy: 0.5248 - val_loss: 0.2359 - val_accuracy: 0.5347\n",
      "Epoch 394/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2365 - accuracy: 0.5310 - val_loss: 0.2358 - val_accuracy: 0.5347\n",
      "Epoch 395/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2375 - accuracy: 0.5206 - val_loss: 0.2358 - val_accuracy: 0.5347\n",
      "Epoch 396/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.5350 - val_loss: 0.2357 - val_accuracy: 0.5347\n",
      "Epoch 397/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2345 - accuracy: 0.5410 - val_loss: 0.2356 - val_accuracy: 0.5347\n",
      "Epoch 398/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2368 - accuracy: 0.5285 - val_loss: 0.2355 - val_accuracy: 0.5347\n",
      "Epoch 399/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2351 - accuracy: 0.5366 - val_loss: 0.2354 - val_accuracy: 0.5347\n",
      "Epoch 400/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2373 - accuracy: 0.5198 - val_loss: 0.2354 - val_accuracy: 0.5347\n",
      "Epoch 401/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2361 - accuracy: 0.5319 - val_loss: 0.2353 - val_accuracy: 0.5347\n",
      "Epoch 402/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2353 - accuracy: 0.5370 - val_loss: 0.2352 - val_accuracy: 0.5347\n",
      "Epoch 403/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2363 - accuracy: 0.5290 - val_loss: 0.2351 - val_accuracy: 0.5347\n",
      "Epoch 404/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.5389 - val_loss: 0.2350 - val_accuracy: 0.5347\n",
      "Epoch 405/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2352 - accuracy: 0.5286 - val_loss: 0.2349 - val_accuracy: 0.5347\n",
      "Epoch 406/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.5428 - val_loss: 0.2349 - val_accuracy: 0.5347\n",
      "Epoch 407/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2350 - accuracy: 0.5364 - val_loss: 0.2348 - val_accuracy: 0.5347\n",
      "Epoch 408/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2353 - accuracy: 0.5362 - val_loss: 0.2347 - val_accuracy: 0.5347\n",
      "Epoch 409/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2363 - accuracy: 0.5278 - val_loss: 0.2346 - val_accuracy: 0.5347\n",
      "Epoch 410/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2346 - accuracy: 0.5360 - val_loss: 0.2345 - val_accuracy: 0.5347\n",
      "Epoch 411/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2358 - accuracy: 0.5289 - val_loss: 0.2344 - val_accuracy: 0.5347\n",
      "Epoch 412/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.5343 - val_loss: 0.2344 - val_accuracy: 0.5347\n",
      "Epoch 413/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2356 - accuracy: 0.5252 - val_loss: 0.2343 - val_accuracy: 0.5347\n",
      "Epoch 414/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2337 - accuracy: 0.5372 - val_loss: 0.2342 - val_accuracy: 0.5347\n",
      "Epoch 415/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2355 - accuracy: 0.5260 - val_loss: 0.2341 - val_accuracy: 0.5347\n",
      "Epoch 416/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.5348 - val_loss: 0.2340 - val_accuracy: 0.5347\n",
      "Epoch 417/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.5290 - val_loss: 0.2340 - val_accuracy: 0.5347\n",
      "Epoch 418/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2345 - accuracy: 0.5351 - val_loss: 0.2339 - val_accuracy: 0.5347\n",
      "Epoch 419/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.5354 - val_loss: 0.2338 - val_accuracy: 0.5347\n",
      "Epoch 420/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.5288 - val_loss: 0.2337 - val_accuracy: 0.5347\n",
      "Epoch 421/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.5325 - val_loss: 0.2336 - val_accuracy: 0.5347\n",
      "Epoch 422/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2349 - accuracy: 0.5288 - val_loss: 0.2336 - val_accuracy: 0.5347\n",
      "Epoch 423/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2330 - accuracy: 0.5399 - val_loss: 0.2335 - val_accuracy: 0.5347\n",
      "Epoch 424/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2337 - accuracy: 0.5300 - val_loss: 0.2334 - val_accuracy: 0.5347\n",
      "Epoch 425/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2347 - accuracy: 0.5273 - val_loss: 0.2333 - val_accuracy: 0.5347\n",
      "Epoch 426/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2342 - accuracy: 0.5323 - val_loss: 0.2332 - val_accuracy: 0.5347\n",
      "Epoch 427/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2332 - accuracy: 0.5332 - val_loss: 0.2331 - val_accuracy: 0.5347\n",
      "Epoch 428/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2339 - accuracy: 0.5337 - val_loss: 0.2331 - val_accuracy: 0.5347\n",
      "Epoch 429/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2333 - accuracy: 0.5334 - val_loss: 0.2330 - val_accuracy: 0.5347\n",
      "Epoch 430/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.5355 - val_loss: 0.2329 - val_accuracy: 0.5347\n",
      "Epoch 431/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.5301 - val_loss: 0.2328 - val_accuracy: 0.5347\n",
      "Epoch 432/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2329 - accuracy: 0.5329 - val_loss: 0.2327 - val_accuracy: 0.5347\n",
      "Epoch 433/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2320 - accuracy: 0.5445 - val_loss: 0.2327 - val_accuracy: 0.5347\n",
      "Epoch 434/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2334 - accuracy: 0.5284 - val_loss: 0.2326 - val_accuracy: 0.5347\n",
      "Epoch 435/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.5362 - val_loss: 0.2325 - val_accuracy: 0.5347\n",
      "Epoch 436/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2334 - accuracy: 0.5341 - val_loss: 0.2324 - val_accuracy: 0.5347\n",
      "Epoch 437/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.5392 - val_loss: 0.2323 - val_accuracy: 0.5347\n",
      "Epoch 438/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2329 - accuracy: 0.5296 - val_loss: 0.2323 - val_accuracy: 0.5347\n",
      "Epoch 439/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2335 - accuracy: 0.5280 - val_loss: 0.2322 - val_accuracy: 0.5347\n",
      "Epoch 440/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2320 - accuracy: 0.5374 - val_loss: 0.2321 - val_accuracy: 0.5347\n",
      "Epoch 441/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.5331 - val_loss: 0.2320 - val_accuracy: 0.5347\n",
      "Epoch 442/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.5384 - val_loss: 0.2319 - val_accuracy: 0.5347\n",
      "Epoch 443/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2337 - accuracy: 0.5294 - val_loss: 0.2318 - val_accuracy: 0.5347\n",
      "Epoch 444/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2328 - accuracy: 0.5346 - val_loss: 0.2318 - val_accuracy: 0.5347\n",
      "Epoch 445/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2309 - accuracy: 0.5406 - val_loss: 0.2317 - val_accuracy: 0.5347\n",
      "Epoch 446/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.5372 - val_loss: 0.2316 - val_accuracy: 0.5347\n",
      "Epoch 447/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2327 - accuracy: 0.5298 - val_loss: 0.2315 - val_accuracy: 0.5347\n",
      "Epoch 448/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.5303 - val_loss: 0.2314 - val_accuracy: 0.5347\n",
      "Epoch 449/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.5396 - val_loss: 0.2314 - val_accuracy: 0.5347\n",
      "Epoch 450/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2322 - accuracy: 0.5296 - val_loss: 0.2313 - val_accuracy: 0.5347\n",
      "Epoch 451/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2317 - accuracy: 0.5341 - val_loss: 0.2312 - val_accuracy: 0.5347\n",
      "Epoch 452/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2315 - accuracy: 0.5343 - val_loss: 0.2311 - val_accuracy: 0.5347\n",
      "Epoch 453/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2307 - accuracy: 0.5339 - val_loss: 0.2310 - val_accuracy: 0.5347\n",
      "Epoch 454/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.5345 - val_loss: 0.2310 - val_accuracy: 0.5347\n",
      "Epoch 455/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.5412 - val_loss: 0.2309 - val_accuracy: 0.5347\n",
      "Epoch 456/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.5383 - val_loss: 0.2308 - val_accuracy: 0.5347\n",
      "Epoch 457/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.5228 - val_loss: 0.2307 - val_accuracy: 0.5347\n",
      "Epoch 458/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.5364 - val_loss: 0.2306 - val_accuracy: 0.5347\n",
      "Epoch 459/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2312 - accuracy: 0.5344 - val_loss: 0.2306 - val_accuracy: 0.5347\n",
      "Epoch 460/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2314 - accuracy: 0.5296 - val_loss: 0.2305 - val_accuracy: 0.5347\n",
      "Epoch 461/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2312 - accuracy: 0.5266 - val_loss: 0.2304 - val_accuracy: 0.5347\n",
      "Epoch 462/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.5315 - val_loss: 0.2303 - val_accuracy: 0.5347\n",
      "Epoch 463/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.5294 - val_loss: 0.2303 - val_accuracy: 0.5347\n",
      "Epoch 464/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2324 - accuracy: 0.5270 - val_loss: 0.2302 - val_accuracy: 0.5347\n",
      "Epoch 465/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2308 - accuracy: 0.5321 - val_loss: 0.2301 - val_accuracy: 0.5347\n",
      "Epoch 466/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2305 - accuracy: 0.5352 - val_loss: 0.2300 - val_accuracy: 0.5347\n",
      "Epoch 467/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.5347 - val_loss: 0.2300 - val_accuracy: 0.5347\n",
      "Epoch 468/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2285 - accuracy: 0.5338 - val_loss: 0.2299 - val_accuracy: 0.5347\n",
      "Epoch 469/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2313 - accuracy: 0.5288 - val_loss: 0.2298 - val_accuracy: 0.5347\n",
      "Epoch 470/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2306 - accuracy: 0.5280 - val_loss: 0.2297 - val_accuracy: 0.5786\n",
      "Epoch 471/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2300 - accuracy: 0.5800 - val_loss: 0.2296 - val_accuracy: 0.5786\n",
      "Epoch 472/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2287 - accuracy: 0.5901 - val_loss: 0.2296 - val_accuracy: 0.5786\n",
      "Epoch 473/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.5686 - val_loss: 0.2295 - val_accuracy: 0.5786\n",
      "Epoch 474/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2303 - accuracy: 0.5779 - val_loss: 0.2294 - val_accuracy: 0.5782\n",
      "Epoch 475/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2299 - accuracy: 0.5706 - val_loss: 0.2293 - val_accuracy: 0.5782\n",
      "Epoch 476/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2296 - accuracy: 0.5816 - val_loss: 0.2293 - val_accuracy: 0.5782\n",
      "Epoch 477/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2310 - accuracy: 0.5738 - val_loss: 0.2292 - val_accuracy: 0.5782\n",
      "Epoch 478/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2287 - accuracy: 0.5827 - val_loss: 0.2291 - val_accuracy: 0.5782\n",
      "Epoch 479/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2311 - accuracy: 0.5772 - val_loss: 0.2290 - val_accuracy: 0.5797\n",
      "Epoch 480/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2305 - accuracy: 0.5785 - val_loss: 0.2290 - val_accuracy: 0.5842\n",
      "Epoch 481/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2304 - accuracy: 0.5818 - val_loss: 0.2289 - val_accuracy: 0.5842\n",
      "Epoch 482/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.5839 - val_loss: 0.2288 - val_accuracy: 0.5842\n",
      "Epoch 483/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2309 - accuracy: 0.5766 - val_loss: 0.2287 - val_accuracy: 0.5842\n",
      "Epoch 484/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2297 - accuracy: 0.5872 - val_loss: 0.2287 - val_accuracy: 0.5842\n",
      "Epoch 485/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2298 - accuracy: 0.5792 - val_loss: 0.2286 - val_accuracy: 0.5842\n",
      "Epoch 486/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.5878 - val_loss: 0.2285 - val_accuracy: 0.5842\n",
      "Epoch 487/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2287 - accuracy: 0.5887 - val_loss: 0.2284 - val_accuracy: 0.5842\n",
      "Epoch 488/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.5906 - val_loss: 0.2284 - val_accuracy: 0.5842\n",
      "Epoch 489/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2299 - accuracy: 0.5807 - val_loss: 0.2283 - val_accuracy: 0.5842\n",
      "Epoch 490/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2280 - accuracy: 0.5932 - val_loss: 0.2282 - val_accuracy: 0.5842\n",
      "Epoch 491/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.5912 - val_loss: 0.2281 - val_accuracy: 0.5842\n",
      "Epoch 492/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2283 - accuracy: 0.5872 - val_loss: 0.2281 - val_accuracy: 0.6045\n",
      "Epoch 493/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2278 - accuracy: 0.6151 - val_loss: 0.2280 - val_accuracy: 0.6045\n",
      "Epoch 494/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2293 - accuracy: 0.6014 - val_loss: 0.2279 - val_accuracy: 0.6045\n",
      "Epoch 495/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2273 - accuracy: 0.6114 - val_loss: 0.2278 - val_accuracy: 0.6045\n",
      "Epoch 496/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2283 - accuracy: 0.6084 - val_loss: 0.2278 - val_accuracy: 0.6045\n",
      "Epoch 497/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2287 - accuracy: 0.6066 - val_loss: 0.2277 - val_accuracy: 0.6045\n",
      "Epoch 498/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2255 - accuracy: 0.6185 - val_loss: 0.2276 - val_accuracy: 0.6046\n",
      "Epoch 499/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2286 - accuracy: 0.6023 - val_loss: 0.2276 - val_accuracy: 0.6046\n",
      "Epoch 500/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.6094 - val_loss: 0.2275 - val_accuracy: 0.6045\n",
      "Epoch 501/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2286 - accuracy: 0.6081 - val_loss: 0.2274 - val_accuracy: 0.6045\n",
      "Epoch 502/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.6134 - val_loss: 0.2274 - val_accuracy: 0.6045\n",
      "Epoch 503/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.6007 - val_loss: 0.2273 - val_accuracy: 0.6045\n",
      "Epoch 504/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.6095 - val_loss: 0.2272 - val_accuracy: 0.6175\n",
      "Epoch 505/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.6236 - val_loss: 0.2272 - val_accuracy: 0.6175\n",
      "Epoch 506/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2277 - accuracy: 0.6254 - val_loss: 0.2271 - val_accuracy: 0.6175\n",
      "Epoch 507/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.6280 - val_loss: 0.2270 - val_accuracy: 0.6186\n",
      "Epoch 508/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.6083 - val_loss: 0.2269 - val_accuracy: 0.6186\n",
      "Epoch 509/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2278 - accuracy: 0.6246 - val_loss: 0.2269 - val_accuracy: 0.6186\n",
      "Epoch 510/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2292 - accuracy: 0.6202 - val_loss: 0.2268 - val_accuracy: 0.6186\n",
      "Epoch 511/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.6285 - val_loss: 0.2267 - val_accuracy: 0.6186\n",
      "Epoch 512/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2273 - accuracy: 0.6245 - val_loss: 0.2267 - val_accuracy: 0.6186\n",
      "Epoch 513/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.6250 - val_loss: 0.2266 - val_accuracy: 0.6186\n",
      "Epoch 514/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2304 - accuracy: 0.6118 - val_loss: 0.2266 - val_accuracy: 0.6186\n",
      "Epoch 515/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.6349 - val_loss: 0.2265 - val_accuracy: 0.6184\n",
      "Epoch 516/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2262 - accuracy: 0.6240 - val_loss: 0.2264 - val_accuracy: 0.6184\n",
      "Epoch 517/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2290 - accuracy: 0.6160 - val_loss: 0.2264 - val_accuracy: 0.6472\n",
      "Epoch 518/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.6503 - val_loss: 0.2263 - val_accuracy: 0.6472\n",
      "Epoch 519/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2289 - accuracy: 0.6459 - val_loss: 0.2262 - val_accuracy: 0.6472\n",
      "Epoch 520/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2259 - accuracy: 0.6497 - val_loss: 0.2262 - val_accuracy: 0.6499\n",
      "Epoch 521/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.6470 - val_loss: 0.2261 - val_accuracy: 0.6499\n",
      "Epoch 522/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.6541 - val_loss: 0.2260 - val_accuracy: 0.6499\n",
      "Epoch 523/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.6510 - val_loss: 0.2260 - val_accuracy: 0.6499\n",
      "Epoch 524/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2279 - accuracy: 0.6451 - val_loss: 0.2259 - val_accuracy: 0.6503\n",
      "Epoch 525/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2265 - accuracy: 0.6501 - val_loss: 0.2259 - val_accuracy: 0.6507\n",
      "Epoch 526/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2269 - accuracy: 0.6459 - val_loss: 0.2258 - val_accuracy: 0.6523\n",
      "Epoch 527/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2277 - accuracy: 0.6498 - val_loss: 0.2257 - val_accuracy: 0.6523\n",
      "Epoch 528/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2256 - accuracy: 0.6555 - val_loss: 0.2257 - val_accuracy: 0.6536\n",
      "Epoch 529/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2274 - accuracy: 0.6483 - val_loss: 0.2256 - val_accuracy: 0.6555\n",
      "Epoch 530/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2264 - accuracy: 0.6531 - val_loss: 0.2255 - val_accuracy: 0.6557\n",
      "Epoch 531/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2261 - accuracy: 0.6560 - val_loss: 0.2255 - val_accuracy: 0.6557\n",
      "Epoch 532/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2243 - accuracy: 0.6648 - val_loss: 0.2254 - val_accuracy: 0.6578\n",
      "Epoch 533/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2241 - accuracy: 0.6655 - val_loss: 0.2254 - val_accuracy: 0.6597\n",
      "Epoch 534/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2271 - accuracy: 0.6594 - val_loss: 0.2253 - val_accuracy: 0.6597\n",
      "Epoch 535/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.6580 - val_loss: 0.2252 - val_accuracy: 0.6597\n",
      "Epoch 536/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2273 - accuracy: 0.6593 - val_loss: 0.2252 - val_accuracy: 0.6597\n",
      "Epoch 537/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.6591 - val_loss: 0.2251 - val_accuracy: 0.6597\n",
      "Epoch 538/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.6653 - val_loss: 0.2251 - val_accuracy: 0.6597\n",
      "Epoch 539/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2279 - accuracy: 0.6567 - val_loss: 0.2250 - val_accuracy: 0.6597\n",
      "Epoch 540/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2242 - accuracy: 0.6605 - val_loss: 0.2249 - val_accuracy: 0.6597\n",
      "Epoch 541/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.6578 - val_loss: 0.2249 - val_accuracy: 0.6597\n",
      "Epoch 542/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2254 - accuracy: 0.6654 - val_loss: 0.2248 - val_accuracy: 0.6597\n",
      "Epoch 543/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.6592 - val_loss: 0.2248 - val_accuracy: 0.6597\n",
      "Epoch 544/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2256 - accuracy: 0.6606 - val_loss: 0.2247 - val_accuracy: 0.6597\n",
      "Epoch 545/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2260 - accuracy: 0.6571 - val_loss: 0.2247 - val_accuracy: 0.6734\n",
      "Epoch 546/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.6798 - val_loss: 0.2246 - val_accuracy: 0.6736\n",
      "Epoch 547/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.6759 - val_loss: 0.2245 - val_accuracy: 0.6737\n",
      "Epoch 548/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.6781 - val_loss: 0.2245 - val_accuracy: 0.6737\n",
      "Epoch 549/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.6730 - val_loss: 0.2244 - val_accuracy: 0.6737\n",
      "Epoch 550/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2255 - accuracy: 0.6734 - val_loss: 0.2244 - val_accuracy: 0.6737\n",
      "Epoch 551/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2235 - accuracy: 0.6775 - val_loss: 0.2243 - val_accuracy: 0.6737\n",
      "Epoch 552/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2244 - accuracy: 0.6786 - val_loss: 0.2243 - val_accuracy: 0.6737\n",
      "Epoch 553/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.6717 - val_loss: 0.2242 - val_accuracy: 0.6737\n",
      "Epoch 554/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2261 - accuracy: 0.6744 - val_loss: 0.2242 - val_accuracy: 0.6741\n",
      "Epoch 555/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2257 - accuracy: 0.6725 - val_loss: 0.2241 - val_accuracy: 0.6741\n",
      "Epoch 556/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2250 - accuracy: 0.6766 - val_loss: 0.2241 - val_accuracy: 0.6741\n",
      "Epoch 557/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.6714 - val_loss: 0.2240 - val_accuracy: 0.6741\n",
      "Epoch 558/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2268 - accuracy: 0.6731 - val_loss: 0.2240 - val_accuracy: 0.6741\n",
      "Epoch 559/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2248 - accuracy: 0.6736 - val_loss: 0.2239 - val_accuracy: 0.6741\n",
      "Epoch 560/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2249 - accuracy: 0.6742 - val_loss: 0.2239 - val_accuracy: 0.6741\n",
      "Epoch 561/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2251 - accuracy: 0.6768 - val_loss: 0.2238 - val_accuracy: 0.6741\n",
      "Epoch 562/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2243 - accuracy: 0.6730 - val_loss: 0.2237 - val_accuracy: 0.6741\n",
      "Epoch 563/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.6672 - val_loss: 0.2237 - val_accuracy: 0.6741\n",
      "Epoch 564/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2240 - accuracy: 0.6805 - val_loss: 0.2237 - val_accuracy: 0.6741\n",
      "Epoch 565/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2270 - accuracy: 0.6702 - val_loss: 0.2236 - val_accuracy: 0.6741\n",
      "Epoch 566/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.6774 - val_loss: 0.2236 - val_accuracy: 0.6741\n",
      "Epoch 567/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2256 - accuracy: 0.6707 - val_loss: 0.2235 - val_accuracy: 0.6743\n",
      "Epoch 568/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2241 - accuracy: 0.6799 - val_loss: 0.2235 - val_accuracy: 0.6743\n",
      "Epoch 569/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2270 - accuracy: 0.6645 - val_loss: 0.2234 - val_accuracy: 0.6743\n",
      "Epoch 570/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.6760 - val_loss: 0.2234 - val_accuracy: 0.6758\n",
      "Epoch 571/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.6818 - val_loss: 0.2233 - val_accuracy: 0.6759\n",
      "Epoch 572/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2247 - accuracy: 0.6784 - val_loss: 0.2233 - val_accuracy: 0.6807\n",
      "Epoch 573/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.6794 - val_loss: 0.2232 - val_accuracy: 0.6807\n",
      "Epoch 574/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6769 - val_loss: 0.2232 - val_accuracy: 0.6807\n",
      "Epoch 575/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.6769 - val_loss: 0.2231 - val_accuracy: 0.6807\n",
      "Epoch 576/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2234 - accuracy: 0.6807 - val_loss: 0.2231 - val_accuracy: 0.6807\n",
      "Epoch 577/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.6882 - val_loss: 0.2230 - val_accuracy: 0.6807\n",
      "Epoch 578/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.6887 - val_loss: 0.2230 - val_accuracy: 0.6807\n",
      "Epoch 579/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.6778 - val_loss: 0.2229 - val_accuracy: 0.6807\n",
      "Epoch 580/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2230 - accuracy: 0.6870 - val_loss: 0.2229 - val_accuracy: 0.6807\n",
      "Epoch 581/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2221 - accuracy: 0.6855 - val_loss: 0.2228 - val_accuracy: 0.6809\n",
      "Epoch 582/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.6814 - val_loss: 0.2228 - val_accuracy: 0.6809\n",
      "Epoch 583/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.6843 - val_loss: 0.2227 - val_accuracy: 0.6829\n",
      "Epoch 584/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2247 - accuracy: 0.6852 - val_loss: 0.2227 - val_accuracy: 0.6831\n",
      "Epoch 585/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6879 - val_loss: 0.2227 - val_accuracy: 0.6831\n",
      "Epoch 586/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.6820 - val_loss: 0.2226 - val_accuracy: 0.6830\n",
      "Epoch 587/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2257 - accuracy: 0.6802 - val_loss: 0.2226 - val_accuracy: 0.6830\n",
      "Epoch 588/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2224 - accuracy: 0.6884 - val_loss: 0.2225 - val_accuracy: 0.6832\n",
      "Epoch 589/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.6867 - val_loss: 0.2225 - val_accuracy: 0.6832\n",
      "Epoch 590/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.6919 - val_loss: 0.2224 - val_accuracy: 0.6832\n",
      "Epoch 591/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.6827 - val_loss: 0.2224 - val_accuracy: 0.6833\n",
      "Epoch 592/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.6766 - val_loss: 0.2223 - val_accuracy: 0.6833\n",
      "Epoch 593/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.6789 - val_loss: 0.2223 - val_accuracy: 0.6833\n",
      "Epoch 594/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.6889 - val_loss: 0.2223 - val_accuracy: 0.6833\n",
      "Epoch 595/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.6875 - val_loss: 0.2222 - val_accuracy: 0.6833\n",
      "Epoch 596/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.6883 - val_loss: 0.2222 - val_accuracy: 0.6833\n",
      "Epoch 597/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.6802 - val_loss: 0.2221 - val_accuracy: 0.6833\n",
      "Epoch 598/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2211 - accuracy: 0.6898 - val_loss: 0.2221 - val_accuracy: 0.6886\n",
      "Epoch 599/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.6881 - val_loss: 0.2220 - val_accuracy: 0.7028\n",
      "Epoch 600/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.6977 - val_loss: 0.2220 - val_accuracy: 0.7028\n",
      "Epoch 601/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2243 - accuracy: 0.6966 - val_loss: 0.2220 - val_accuracy: 0.7028\n",
      "Epoch 602/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2225 - accuracy: 0.6989 - val_loss: 0.2219 - val_accuracy: 0.7028\n",
      "Epoch 603/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2237 - accuracy: 0.7026 - val_loss: 0.2219 - val_accuracy: 0.7028\n",
      "Epoch 604/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.6961 - val_loss: 0.2218 - val_accuracy: 0.7028\n",
      "Epoch 605/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2228 - accuracy: 0.7033 - val_loss: 0.2218 - val_accuracy: 0.7029\n",
      "Epoch 606/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.7078 - val_loss: 0.2217 - val_accuracy: 0.7029\n",
      "Epoch 607/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.7012 - val_loss: 0.2217 - val_accuracy: 0.7029\n",
      "Epoch 608/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.7042 - val_loss: 0.2217 - val_accuracy: 0.7029\n",
      "Epoch 609/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.6957 - val_loss: 0.2216 - val_accuracy: 0.7029\n",
      "Epoch 610/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.7005 - val_loss: 0.2216 - val_accuracy: 0.7029\n",
      "Epoch 611/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.7017 - val_loss: 0.2215 - val_accuracy: 0.7029\n",
      "Epoch 612/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2228 - accuracy: 0.7016 - val_loss: 0.2215 - val_accuracy: 0.7031\n",
      "Epoch 613/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.7045 - val_loss: 0.2214 - val_accuracy: 0.7031\n",
      "Epoch 614/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.7083 - val_loss: 0.2214 - val_accuracy: 0.7031\n",
      "Epoch 615/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.7017 - val_loss: 0.2214 - val_accuracy: 0.7031\n",
      "Epoch 616/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.6992 - val_loss: 0.2213 - val_accuracy: 0.7031\n",
      "Epoch 617/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.7030 - val_loss: 0.2213 - val_accuracy: 0.7031\n",
      "Epoch 618/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2236 - accuracy: 0.7058 - val_loss: 0.2212 - val_accuracy: 0.7031\n",
      "Epoch 619/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.7060 - val_loss: 0.2212 - val_accuracy: 0.7031\n",
      "Epoch 620/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.6990 - val_loss: 0.2212 - val_accuracy: 0.7031\n",
      "Epoch 621/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.7047 - val_loss: 0.2211 - val_accuracy: 0.7031\n",
      "Epoch 622/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2228 - accuracy: 0.6933 - val_loss: 0.2211 - val_accuracy: 0.7031\n",
      "Epoch 623/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2216 - accuracy: 0.7036 - val_loss: 0.2210 - val_accuracy: 0.7031\n",
      "Epoch 624/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2244 - accuracy: 0.6941 - val_loss: 0.2210 - val_accuracy: 0.7031\n",
      "Epoch 625/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.6950 - val_loss: 0.2210 - val_accuracy: 0.7031\n",
      "Epoch 626/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2239 - accuracy: 0.6985 - val_loss: 0.2209 - val_accuracy: 0.7031\n",
      "Epoch 627/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.6960 - val_loss: 0.2209 - val_accuracy: 0.7031\n",
      "Epoch 628/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2231 - accuracy: 0.7015 - val_loss: 0.2208 - val_accuracy: 0.7031\n",
      "Epoch 629/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.7046 - val_loss: 0.2208 - val_accuracy: 0.7044\n",
      "Epoch 630/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2242 - accuracy: 0.7033 - val_loss: 0.2208 - val_accuracy: 0.7044\n",
      "Epoch 631/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.7114 - val_loss: 0.2207 - val_accuracy: 0.7045\n",
      "Epoch 632/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.7094 - val_loss: 0.2207 - val_accuracy: 0.7045\n",
      "Epoch 633/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2222 - accuracy: 0.7014 - val_loss: 0.2206 - val_accuracy: 0.7045\n",
      "Epoch 634/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2190 - accuracy: 0.7119 - val_loss: 0.2206 - val_accuracy: 0.7045\n",
      "Epoch 635/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2226 - accuracy: 0.7058 - val_loss: 0.2206 - val_accuracy: 0.7045\n",
      "Epoch 636/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.7039 - val_loss: 0.2205 - val_accuracy: 0.7045\n",
      "Epoch 637/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.7017 - val_loss: 0.2205 - val_accuracy: 0.7044\n",
      "Epoch 638/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6999 - val_loss: 0.2204 - val_accuracy: 0.7044\n",
      "Epoch 639/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.7043 - val_loss: 0.2204 - val_accuracy: 0.7043\n",
      "Epoch 640/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2216 - accuracy: 0.7070 - val_loss: 0.2204 - val_accuracy: 0.7042\n",
      "Epoch 641/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2210 - accuracy: 0.7058 - val_loss: 0.2203 - val_accuracy: 0.7045\n",
      "Epoch 642/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.7016 - val_loss: 0.2203 - val_accuracy: 0.7045\n",
      "Epoch 643/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.7066 - val_loss: 0.2202 - val_accuracy: 0.7045\n",
      "Epoch 644/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2221 - accuracy: 0.6985 - val_loss: 0.2202 - val_accuracy: 0.7039\n",
      "Epoch 645/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.7100 - val_loss: 0.2202 - val_accuracy: 0.7039\n",
      "Epoch 646/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.7152 - val_loss: 0.2201 - val_accuracy: 0.7039\n",
      "Epoch 647/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2194 - accuracy: 0.7067 - val_loss: 0.2201 - val_accuracy: 0.7039\n",
      "Epoch 648/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2217 - accuracy: 0.7032 - val_loss: 0.2201 - val_accuracy: 0.7039\n",
      "Epoch 649/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.7055 - val_loss: 0.2200 - val_accuracy: 0.7039\n",
      "Epoch 650/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.7017 - val_loss: 0.2200 - val_accuracy: 0.7039\n",
      "Epoch 651/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.7047 - val_loss: 0.2199 - val_accuracy: 0.7039\n",
      "Epoch 652/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.7093 - val_loss: 0.2199 - val_accuracy: 0.7039\n",
      "Epoch 653/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.7083 - val_loss: 0.2199 - val_accuracy: 0.7039\n",
      "Epoch 654/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.7030 - val_loss: 0.2198 - val_accuracy: 0.7038\n",
      "Epoch 655/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.6960 - val_loss: 0.2198 - val_accuracy: 0.7038\n",
      "Epoch 656/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.7066 - val_loss: 0.2197 - val_accuracy: 0.7038\n",
      "Epoch 657/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.7102 - val_loss: 0.2197 - val_accuracy: 0.7038\n",
      "Epoch 658/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.7074 - val_loss: 0.2197 - val_accuracy: 0.7038\n",
      "Epoch 659/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.7026 - val_loss: 0.2196 - val_accuracy: 0.7037\n",
      "Epoch 660/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.7042 - val_loss: 0.2196 - val_accuracy: 0.7037\n",
      "Epoch 661/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.7019 - val_loss: 0.2196 - val_accuracy: 0.7037\n",
      "Epoch 662/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.7101 - val_loss: 0.2195 - val_accuracy: 0.7037\n",
      "Epoch 663/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.7082 - val_loss: 0.2195 - val_accuracy: 0.7037\n",
      "Epoch 664/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2206 - accuracy: 0.7046 - val_loss: 0.2194 - val_accuracy: 0.7037\n",
      "Epoch 665/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2214 - accuracy: 0.7010 - val_loss: 0.2194 - val_accuracy: 0.7037\n",
      "Epoch 666/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2220 - accuracy: 0.7003 - val_loss: 0.2194 - val_accuracy: 0.7037\n",
      "Epoch 667/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.7078 - val_loss: 0.2193 - val_accuracy: 0.7038\n",
      "Epoch 668/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.7062 - val_loss: 0.2193 - val_accuracy: 0.7048\n",
      "Epoch 669/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.7086 - val_loss: 0.2193 - val_accuracy: 0.7048\n",
      "Epoch 670/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7149 - val_loss: 0.2192 - val_accuracy: 0.7048\n",
      "Epoch 671/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2203 - accuracy: 0.7005 - val_loss: 0.2192 - val_accuracy: 0.7048\n",
      "Epoch 672/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.7089 - val_loss: 0.2192 - val_accuracy: 0.7048\n",
      "Epoch 673/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.6991 - val_loss: 0.2191 - val_accuracy: 0.7048\n",
      "Epoch 674/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2208 - accuracy: 0.7011 - val_loss: 0.2191 - val_accuracy: 0.7049\n",
      "Epoch 675/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.7073 - val_loss: 0.2191 - val_accuracy: 0.7050\n",
      "Epoch 676/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2195 - accuracy: 0.7095 - val_loss: 0.2190 - val_accuracy: 0.7050\n",
      "Epoch 677/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.7061 - val_loss: 0.2190 - val_accuracy: 0.7050\n",
      "Epoch 678/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.7141 - val_loss: 0.2190 - val_accuracy: 0.7050\n",
      "Epoch 679/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.7107 - val_loss: 0.2189 - val_accuracy: 0.7050\n",
      "Epoch 680/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.7080 - val_loss: 0.2189 - val_accuracy: 0.7051\n",
      "Epoch 681/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.7047 - val_loss: 0.2189 - val_accuracy: 0.7084\n",
      "Epoch 682/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.7195 - val_loss: 0.2188 - val_accuracy: 0.7084\n",
      "Epoch 683/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.7038 - val_loss: 0.2188 - val_accuracy: 0.7085\n",
      "Epoch 684/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2206 - accuracy: 0.7006 - val_loss: 0.2188 - val_accuracy: 0.7085\n",
      "Epoch 685/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.7139 - val_loss: 0.2187 - val_accuracy: 0.7085\n",
      "Epoch 686/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.7101 - val_loss: 0.2187 - val_accuracy: 0.7085\n",
      "Epoch 687/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2210 - accuracy: 0.7087 - val_loss: 0.2187 - val_accuracy: 0.7085\n",
      "Epoch 688/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2209 - accuracy: 0.7040 - val_loss: 0.2186 - val_accuracy: 0.7098\n",
      "Epoch 689/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.7087 - val_loss: 0.2186 - val_accuracy: 0.7145\n",
      "Epoch 690/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.7201 - val_loss: 0.2186 - val_accuracy: 0.7146\n",
      "Epoch 691/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2197 - accuracy: 0.7115 - val_loss: 0.2185 - val_accuracy: 0.7146\n",
      "Epoch 692/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.7179 - val_loss: 0.2185 - val_accuracy: 0.7148\n",
      "Epoch 693/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.7161 - val_loss: 0.2185 - val_accuracy: 0.7148\n",
      "Epoch 694/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.7153 - val_loss: 0.2184 - val_accuracy: 0.7148\n",
      "Epoch 695/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.7038 - val_loss: 0.2184 - val_accuracy: 0.7148\n",
      "Epoch 696/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.7174 - val_loss: 0.2184 - val_accuracy: 0.7148\n",
      "Epoch 697/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.7161 - val_loss: 0.2183 - val_accuracy: 0.7148\n",
      "Epoch 698/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2182 - accuracy: 0.7128 - val_loss: 0.2183 - val_accuracy: 0.7148\n",
      "Epoch 699/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.7172 - val_loss: 0.2183 - val_accuracy: 0.7148\n",
      "Epoch 700/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.7142 - val_loss: 0.2182 - val_accuracy: 0.7148\n",
      "Epoch 701/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.7127 - val_loss: 0.2182 - val_accuracy: 0.7149\n",
      "Epoch 702/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2191 - accuracy: 0.7096 - val_loss: 0.2182 - val_accuracy: 0.7149\n",
      "Epoch 703/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.7172 - val_loss: 0.2181 - val_accuracy: 0.7148\n",
      "Epoch 704/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.7090 - val_loss: 0.2181 - val_accuracy: 0.7148\n",
      "Epoch 705/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2167 - accuracy: 0.7188 - val_loss: 0.2181 - val_accuracy: 0.7148\n",
      "Epoch 706/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.7148 - val_loss: 0.2180 - val_accuracy: 0.7148\n",
      "Epoch 707/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.7142 - val_loss: 0.2180 - val_accuracy: 0.7148\n",
      "Epoch 708/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.7168 - val_loss: 0.2180 - val_accuracy: 0.7157\n",
      "Epoch 709/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.7112 - val_loss: 0.2179 - val_accuracy: 0.7157\n",
      "Epoch 710/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2185 - accuracy: 0.7124 - val_loss: 0.2179 - val_accuracy: 0.7157\n",
      "Epoch 711/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.7124 - val_loss: 0.2179 - val_accuracy: 0.7157\n",
      "Epoch 712/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.7242 - val_loss: 0.2179 - val_accuracy: 0.7158\n",
      "Epoch 713/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.7159 - val_loss: 0.2178 - val_accuracy: 0.7162\n",
      "Epoch 714/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.7114 - val_loss: 0.2178 - val_accuracy: 0.7162\n",
      "Epoch 715/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2194 - accuracy: 0.7157 - val_loss: 0.2178 - val_accuracy: 0.7162\n",
      "Epoch 716/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2199 - accuracy: 0.7125 - val_loss: 0.2177 - val_accuracy: 0.7162\n",
      "Epoch 717/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2172 - accuracy: 0.7208 - val_loss: 0.2177 - val_accuracy: 0.7162\n",
      "Epoch 718/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.7199 - val_loss: 0.2177 - val_accuracy: 0.7162\n",
      "Epoch 719/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.7129 - val_loss: 0.2176 - val_accuracy: 0.7162\n",
      "Epoch 720/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.7146 - val_loss: 0.2176 - val_accuracy: 0.7162\n",
      "Epoch 721/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7232 - val_loss: 0.2176 - val_accuracy: 0.7162\n",
      "Epoch 722/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.7115 - val_loss: 0.2175 - val_accuracy: 0.7162\n",
      "Epoch 723/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.7162 - val_loss: 0.2175 - val_accuracy: 0.7162\n",
      "Epoch 724/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.7232 - val_loss: 0.2175 - val_accuracy: 0.7162\n",
      "Epoch 725/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2184 - accuracy: 0.7141 - val_loss: 0.2175 - val_accuracy: 0.7162\n",
      "Epoch 726/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.7193 - val_loss: 0.2174 - val_accuracy: 0.7162\n",
      "Epoch 727/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2154 - accuracy: 0.7185 - val_loss: 0.2174 - val_accuracy: 0.7162\n",
      "Epoch 728/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.7139 - val_loss: 0.2174 - val_accuracy: 0.7162\n",
      "Epoch 729/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.7144 - val_loss: 0.2173 - val_accuracy: 0.7161\n",
      "Epoch 730/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.7072 - val_loss: 0.2173 - val_accuracy: 0.7162\n",
      "Epoch 731/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2203 - accuracy: 0.7077 - val_loss: 0.2173 - val_accuracy: 0.7164\n",
      "Epoch 732/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.7168 - val_loss: 0.2172 - val_accuracy: 0.7164\n",
      "Epoch 733/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.7178 - val_loss: 0.2172 - val_accuracy: 0.7164\n",
      "Epoch 734/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.7123 - val_loss: 0.2172 - val_accuracy: 0.7164\n",
      "Epoch 735/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7196 - val_loss: 0.2172 - val_accuracy: 0.7160\n",
      "Epoch 736/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.7152 - val_loss: 0.2171 - val_accuracy: 0.7160\n",
      "Epoch 737/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2169 - accuracy: 0.7174 - val_loss: 0.2171 - val_accuracy: 0.7160\n",
      "Epoch 738/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.7231 - val_loss: 0.2171 - val_accuracy: 0.7159\n",
      "Epoch 739/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2164 - accuracy: 0.7234 - val_loss: 0.2170 - val_accuracy: 0.7159\n",
      "Epoch 740/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2185 - accuracy: 0.7160 - val_loss: 0.2170 - val_accuracy: 0.7159\n",
      "Epoch 741/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.7122 - val_loss: 0.2170 - val_accuracy: 0.7159\n",
      "Epoch 742/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.7174 - val_loss: 0.2169 - val_accuracy: 0.7160\n",
      "Epoch 743/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.7167 - val_loss: 0.2169 - val_accuracy: 0.7160\n",
      "Epoch 744/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2212 - accuracy: 0.7074 - val_loss: 0.2169 - val_accuracy: 0.7160\n",
      "Epoch 745/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.7118 - val_loss: 0.2169 - val_accuracy: 0.7156\n",
      "Epoch 746/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2187 - accuracy: 0.7105 - val_loss: 0.2168 - val_accuracy: 0.7157\n",
      "Epoch 747/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.7159 - val_loss: 0.2168 - val_accuracy: 0.7156\n",
      "Epoch 748/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.7196 - val_loss: 0.2168 - val_accuracy: 0.7156\n",
      "Epoch 749/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.7163 - val_loss: 0.2167 - val_accuracy: 0.7158\n",
      "Epoch 750/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7197 - val_loss: 0.2167 - val_accuracy: 0.7158\n",
      "Epoch 751/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.7088 - val_loss: 0.2167 - val_accuracy: 0.7158\n",
      "Epoch 752/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2188 - accuracy: 0.7116 - val_loss: 0.2167 - val_accuracy: 0.7158\n",
      "Epoch 753/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.7158 - val_loss: 0.2166 - val_accuracy: 0.7158\n",
      "Epoch 754/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.7146 - val_loss: 0.2166 - val_accuracy: 0.7164\n",
      "Epoch 755/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.7134 - val_loss: 0.2166 - val_accuracy: 0.7165\n",
      "Epoch 756/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2193 - accuracy: 0.7103 - val_loss: 0.2165 - val_accuracy: 0.7166\n",
      "Epoch 757/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.7120 - val_loss: 0.2165 - val_accuracy: 0.7166\n",
      "Epoch 758/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.7140 - val_loss: 0.2165 - val_accuracy: 0.7167\n",
      "Epoch 759/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.7096 - val_loss: 0.2165 - val_accuracy: 0.7175\n",
      "Epoch 760/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7163 - val_loss: 0.2164 - val_accuracy: 0.7175\n",
      "Epoch 761/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.7132 - val_loss: 0.2164 - val_accuracy: 0.7175\n",
      "Epoch 762/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.7138 - val_loss: 0.2164 - val_accuracy: 0.7169\n",
      "Epoch 763/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.7143 - val_loss: 0.2163 - val_accuracy: 0.7169\n",
      "Epoch 764/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.7175 - val_loss: 0.2163 - val_accuracy: 0.7169\n",
      "Epoch 765/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.7119 - val_loss: 0.2163 - val_accuracy: 0.7169\n",
      "Epoch 766/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.7169 - val_loss: 0.2163 - val_accuracy: 0.7169\n",
      "Epoch 767/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2173 - accuracy: 0.7154 - val_loss: 0.2162 - val_accuracy: 0.7169\n",
      "Epoch 768/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.7110 - val_loss: 0.2162 - val_accuracy: 0.7167\n",
      "Epoch 769/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2171 - accuracy: 0.7171 - val_loss: 0.2162 - val_accuracy: 0.7167\n",
      "Epoch 770/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.7148 - val_loss: 0.2162 - val_accuracy: 0.7167\n",
      "Epoch 771/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.7187 - val_loss: 0.2161 - val_accuracy: 0.7167\n",
      "Epoch 772/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.7115 - val_loss: 0.2161 - val_accuracy: 0.7167\n",
      "Epoch 773/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2178 - accuracy: 0.7140 - val_loss: 0.2161 - val_accuracy: 0.7167\n",
      "Epoch 774/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.7203 - val_loss: 0.2160 - val_accuracy: 0.7167\n",
      "Epoch 775/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.7157 - val_loss: 0.2160 - val_accuracy: 0.7167\n",
      "Epoch 776/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.7202 - val_loss: 0.2160 - val_accuracy: 0.7167\n",
      "Epoch 777/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2176 - accuracy: 0.7095 - val_loss: 0.2160 - val_accuracy: 0.7167\n",
      "Epoch 778/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2175 - accuracy: 0.7197 - val_loss: 0.2159 - val_accuracy: 0.7167\n",
      "Epoch 779/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2180 - accuracy: 0.7143 - val_loss: 0.2159 - val_accuracy: 0.7167\n",
      "Epoch 780/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2194 - accuracy: 0.7080 - val_loss: 0.2159 - val_accuracy: 0.7167\n",
      "Epoch 781/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2193 - accuracy: 0.7110 - val_loss: 0.2159 - val_accuracy: 0.7167\n",
      "Epoch 782/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.7150 - val_loss: 0.2158 - val_accuracy: 0.7167\n",
      "Epoch 783/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.7181 - val_loss: 0.2158 - val_accuracy: 0.7167\n",
      "Epoch 784/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.7198 - val_loss: 0.2158 - val_accuracy: 0.7166\n",
      "Epoch 785/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.7062 - val_loss: 0.2158 - val_accuracy: 0.7166\n",
      "Epoch 786/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.7149 - val_loss: 0.2157 - val_accuracy: 0.7166\n",
      "Epoch 787/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2173 - accuracy: 0.7197 - val_loss: 0.2157 - val_accuracy: 0.7166\n",
      "Epoch 788/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.7173 - val_loss: 0.2157 - val_accuracy: 0.7166\n",
      "Epoch 789/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.7042 - val_loss: 0.2157 - val_accuracy: 0.7166\n",
      "Epoch 790/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2160 - accuracy: 0.7175 - val_loss: 0.2156 - val_accuracy: 0.7166\n",
      "Epoch 791/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.7164 - val_loss: 0.2156 - val_accuracy: 0.7168\n",
      "Epoch 792/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2168 - accuracy: 0.7194 - val_loss: 0.2156 - val_accuracy: 0.7168\n",
      "Epoch 793/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.7167 - val_loss: 0.2155 - val_accuracy: 0.7168\n",
      "Epoch 794/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2156 - accuracy: 0.7203 - val_loss: 0.2155 - val_accuracy: 0.7168\n",
      "Epoch 795/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.7184 - val_loss: 0.2155 - val_accuracy: 0.7168\n",
      "Epoch 796/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.7225 - val_loss: 0.2155 - val_accuracy: 0.7168\n",
      "Epoch 797/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.7187 - val_loss: 0.2154 - val_accuracy: 0.7168\n",
      "Epoch 798/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.7142 - val_loss: 0.2154 - val_accuracy: 0.7168\n",
      "Epoch 799/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.7132 - val_loss: 0.2154 - val_accuracy: 0.7168\n",
      "Epoch 800/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7232 - val_loss: 0.2154 - val_accuracy: 0.7168\n",
      "Epoch 801/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.7242 - val_loss: 0.2153 - val_accuracy: 0.7168\n",
      "Epoch 802/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.7129 - val_loss: 0.2153 - val_accuracy: 0.7168\n",
      "Epoch 803/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2162 - accuracy: 0.7146 - val_loss: 0.2153 - val_accuracy: 0.7168\n",
      "Epoch 804/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7116 - val_loss: 0.2153 - val_accuracy: 0.7168\n",
      "Epoch 805/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2191 - accuracy: 0.7097 - val_loss: 0.2152 - val_accuracy: 0.7168\n",
      "Epoch 806/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2149 - accuracy: 0.7161 - val_loss: 0.2152 - val_accuracy: 0.7168\n",
      "Epoch 807/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.7243 - val_loss: 0.2152 - val_accuracy: 0.7168\n",
      "Epoch 808/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2184 - accuracy: 0.7104 - val_loss: 0.2152 - val_accuracy: 0.7168\n",
      "Epoch 809/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2168 - accuracy: 0.7137 - val_loss: 0.2151 - val_accuracy: 0.7168\n",
      "Epoch 810/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7088 - val_loss: 0.2151 - val_accuracy: 0.7168\n",
      "Epoch 811/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2179 - accuracy: 0.7114 - val_loss: 0.2151 - val_accuracy: 0.7168\n",
      "Epoch 812/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.7098 - val_loss: 0.2151 - val_accuracy: 0.7168\n",
      "Epoch 813/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.7147 - val_loss: 0.2150 - val_accuracy: 0.7168\n",
      "Epoch 814/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.7116 - val_loss: 0.2150 - val_accuracy: 0.7173\n",
      "Epoch 815/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.7164 - val_loss: 0.2150 - val_accuracy: 0.7173\n",
      "Epoch 816/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.7089 - val_loss: 0.2150 - val_accuracy: 0.7173\n",
      "Epoch 817/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.7206 - val_loss: 0.2149 - val_accuracy: 0.7173\n",
      "Epoch 818/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2171 - accuracy: 0.7158 - val_loss: 0.2149 - val_accuracy: 0.7173\n",
      "Epoch 819/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2162 - accuracy: 0.7183 - val_loss: 0.2149 - val_accuracy: 0.7173\n",
      "Epoch 820/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.7183 - val_loss: 0.2149 - val_accuracy: 0.7175\n",
      "Epoch 821/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.7049 - val_loss: 0.2148 - val_accuracy: 0.7175\n",
      "Epoch 822/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7147 - val_loss: 0.2148 - val_accuracy: 0.7175\n",
      "Epoch 823/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.7115 - val_loss: 0.2148 - val_accuracy: 0.7175\n",
      "Epoch 824/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.7103 - val_loss: 0.2148 - val_accuracy: 0.7176\n",
      "Epoch 825/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.7167 - val_loss: 0.2147 - val_accuracy: 0.7175\n",
      "Epoch 826/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2165 - accuracy: 0.7171 - val_loss: 0.2147 - val_accuracy: 0.7175\n",
      "Epoch 827/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.7141 - val_loss: 0.2147 - val_accuracy: 0.7175\n",
      "Epoch 828/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.7201 - val_loss: 0.2147 - val_accuracy: 0.7175\n",
      "Epoch 829/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7183 - val_loss: 0.2146 - val_accuracy: 0.7175\n",
      "Epoch 830/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.7189 - val_loss: 0.2146 - val_accuracy: 0.7175\n",
      "Epoch 831/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.7185 - val_loss: 0.2146 - val_accuracy: 0.7175\n",
      "Epoch 832/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.7110 - val_loss: 0.2146 - val_accuracy: 0.7175\n",
      "Epoch 833/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2174 - accuracy: 0.7145 - val_loss: 0.2145 - val_accuracy: 0.7175\n",
      "Epoch 834/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.7129 - val_loss: 0.2145 - val_accuracy: 0.7175\n",
      "Epoch 835/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.7148 - val_loss: 0.2145 - val_accuracy: 0.7175\n",
      "Epoch 836/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2195 - accuracy: 0.7130 - val_loss: 0.2145 - val_accuracy: 0.7175\n",
      "Epoch 837/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.7165 - val_loss: 0.2144 - val_accuracy: 0.7174\n",
      "Epoch 838/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.7160 - val_loss: 0.2144 - val_accuracy: 0.7174\n",
      "Epoch 839/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2148 - accuracy: 0.7206 - val_loss: 0.2144 - val_accuracy: 0.7174\n",
      "Epoch 840/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2157 - accuracy: 0.7102 - val_loss: 0.2144 - val_accuracy: 0.7174\n",
      "Epoch 841/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2139 - accuracy: 0.7184 - val_loss: 0.2143 - val_accuracy: 0.7174\n",
      "Epoch 842/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2161 - accuracy: 0.7142 - val_loss: 0.2143 - val_accuracy: 0.7175\n",
      "Epoch 843/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2163 - accuracy: 0.7152 - val_loss: 0.2143 - val_accuracy: 0.7176\n",
      "Epoch 844/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.7157 - val_loss: 0.2143 - val_accuracy: 0.7177\n",
      "Epoch 845/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7169 - val_loss: 0.2142 - val_accuracy: 0.7178\n",
      "Epoch 846/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.7132 - val_loss: 0.2142 - val_accuracy: 0.7179\n",
      "Epoch 847/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2152 - accuracy: 0.7194 - val_loss: 0.2142 - val_accuracy: 0.7184\n",
      "Epoch 848/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.7104 - val_loss: 0.2142 - val_accuracy: 0.7188\n",
      "Epoch 849/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7161 - val_loss: 0.2141 - val_accuracy: 0.7189\n",
      "Epoch 850/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.7165 - val_loss: 0.2141 - val_accuracy: 0.7189\n",
      "Epoch 851/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.7200 - val_loss: 0.2141 - val_accuracy: 0.7189\n",
      "Epoch 852/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2165 - accuracy: 0.7165 - val_loss: 0.2141 - val_accuracy: 0.7189\n",
      "Epoch 853/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7152 - val_loss: 0.2140 - val_accuracy: 0.7189\n",
      "Epoch 854/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.7151 - val_loss: 0.2140 - val_accuracy: 0.7189\n",
      "Epoch 855/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.7156 - val_loss: 0.2140 - val_accuracy: 0.7189\n",
      "Epoch 856/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.7182 - val_loss: 0.2140 - val_accuracy: 0.7190\n",
      "Epoch 857/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.7153 - val_loss: 0.2139 - val_accuracy: 0.7190\n",
      "Epoch 858/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.7171 - val_loss: 0.2139 - val_accuracy: 0.7190\n",
      "Epoch 859/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.7151 - val_loss: 0.2139 - val_accuracy: 0.7190\n",
      "Epoch 860/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2158 - accuracy: 0.7155 - val_loss: 0.2139 - val_accuracy: 0.7190\n",
      "Epoch 861/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.7138 - val_loss: 0.2139 - val_accuracy: 0.7190\n",
      "Epoch 862/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.7253 - val_loss: 0.2138 - val_accuracy: 0.7190\n",
      "Epoch 863/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2169 - accuracy: 0.7161 - val_loss: 0.2138 - val_accuracy: 0.7190\n",
      "Epoch 864/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2159 - accuracy: 0.7212 - val_loss: 0.2138 - val_accuracy: 0.7190\n",
      "Epoch 865/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.7245 - val_loss: 0.2138 - val_accuracy: 0.7190\n",
      "Epoch 866/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.7239 - val_loss: 0.2137 - val_accuracy: 0.7190\n",
      "Epoch 867/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2143 - accuracy: 0.7152 - val_loss: 0.2137 - val_accuracy: 0.7190\n",
      "Epoch 868/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2146 - accuracy: 0.7199 - val_loss: 0.2137 - val_accuracy: 0.7190\n",
      "Epoch 869/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.7187 - val_loss: 0.2137 - val_accuracy: 0.7190\n",
      "Epoch 870/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.7143 - val_loss: 0.2136 - val_accuracy: 0.7190\n",
      "Epoch 871/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.7160 - val_loss: 0.2136 - val_accuracy: 0.7190\n",
      "Epoch 872/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.7216 - val_loss: 0.2136 - val_accuracy: 0.7190\n",
      "Epoch 873/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.7242 - val_loss: 0.2136 - val_accuracy: 0.7190\n",
      "Epoch 874/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2186 - accuracy: 0.7150 - val_loss: 0.2135 - val_accuracy: 0.7190\n",
      "Epoch 875/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7076 - val_loss: 0.2135 - val_accuracy: 0.7190\n",
      "Epoch 876/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.7164 - val_loss: 0.2135 - val_accuracy: 0.7190\n",
      "Epoch 877/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.7186 - val_loss: 0.2135 - val_accuracy: 0.7190\n",
      "Epoch 878/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2138 - accuracy: 0.7219 - val_loss: 0.2135 - val_accuracy: 0.7190\n",
      "Epoch 879/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2125 - accuracy: 0.7223 - val_loss: 0.2134 - val_accuracy: 0.7190\n",
      "Epoch 880/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.7162 - val_loss: 0.2134 - val_accuracy: 0.7190\n",
      "Epoch 881/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2131 - accuracy: 0.7201 - val_loss: 0.2134 - val_accuracy: 0.7190\n",
      "Epoch 882/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.7178 - val_loss: 0.2134 - val_accuracy: 0.7190\n",
      "Epoch 883/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.7262 - val_loss: 0.2133 - val_accuracy: 0.7190\n",
      "Epoch 884/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2117 - accuracy: 0.7205 - val_loss: 0.2133 - val_accuracy: 0.7190\n",
      "Epoch 885/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.7253 - val_loss: 0.2133 - val_accuracy: 0.7190\n",
      "Epoch 886/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.7159 - val_loss: 0.2133 - val_accuracy: 0.7190\n",
      "Epoch 887/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.7210 - val_loss: 0.2132 - val_accuracy: 0.7190\n",
      "Epoch 888/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2133 - accuracy: 0.7165 - val_loss: 0.2132 - val_accuracy: 0.7191\n",
      "Epoch 889/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.7164 - val_loss: 0.2132 - val_accuracy: 0.7191\n",
      "Epoch 890/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2139 - accuracy: 0.7172 - val_loss: 0.2132 - val_accuracy: 0.7191\n",
      "Epoch 891/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2117 - accuracy: 0.7218 - val_loss: 0.2132 - val_accuracy: 0.7195\n",
      "Epoch 892/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2149 - accuracy: 0.7170 - val_loss: 0.2131 - val_accuracy: 0.7191\n",
      "Epoch 893/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2134 - accuracy: 0.7234 - val_loss: 0.2131 - val_accuracy: 0.7191\n",
      "Epoch 894/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.7223 - val_loss: 0.2131 - val_accuracy: 0.7199\n",
      "Epoch 895/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7140 - val_loss: 0.2131 - val_accuracy: 0.7198\n",
      "Epoch 896/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.7243 - val_loss: 0.2130 - val_accuracy: 0.7198\n",
      "Epoch 897/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2140 - accuracy: 0.7222 - val_loss: 0.2130 - val_accuracy: 0.7198\n",
      "Epoch 898/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2139 - accuracy: 0.7192 - val_loss: 0.2130 - val_accuracy: 0.7198\n",
      "Epoch 899/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2142 - accuracy: 0.7217 - val_loss: 0.2130 - val_accuracy: 0.7198\n",
      "Epoch 900/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2145 - accuracy: 0.7165 - val_loss: 0.2129 - val_accuracy: 0.7198\n",
      "Epoch 901/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.7104 - val_loss: 0.2129 - val_accuracy: 0.7199\n",
      "Epoch 902/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.7165 - val_loss: 0.2129 - val_accuracy: 0.7199\n",
      "Epoch 903/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7231 - val_loss: 0.2129 - val_accuracy: 0.7200\n",
      "Epoch 904/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.7243 - val_loss: 0.2129 - val_accuracy: 0.7202\n",
      "Epoch 905/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2140 - accuracy: 0.7226 - val_loss: 0.2128 - val_accuracy: 0.7202\n",
      "Epoch 906/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2158 - accuracy: 0.7157 - val_loss: 0.2128 - val_accuracy: 0.7202\n",
      "Epoch 907/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2176 - accuracy: 0.7230 - val_loss: 0.2128 - val_accuracy: 0.7202\n",
      "Epoch 908/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7137 - val_loss: 0.2128 - val_accuracy: 0.7202\n",
      "Epoch 909/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.7212 - val_loss: 0.2127 - val_accuracy: 0.7202\n",
      "Epoch 910/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.7231 - val_loss: 0.2127 - val_accuracy: 0.7202\n",
      "Epoch 911/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2118 - accuracy: 0.7285 - val_loss: 0.2127 - val_accuracy: 0.7202\n",
      "Epoch 912/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.7223 - val_loss: 0.2127 - val_accuracy: 0.7202\n",
      "Epoch 913/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.7187 - val_loss: 0.2127 - val_accuracy: 0.7202\n",
      "Epoch 914/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.7219 - val_loss: 0.2126 - val_accuracy: 0.7202\n",
      "Epoch 915/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.7254 - val_loss: 0.2126 - val_accuracy: 0.7202\n",
      "Epoch 916/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.7248 - val_loss: 0.2126 - val_accuracy: 0.7202\n",
      "Epoch 917/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2157 - accuracy: 0.7196 - val_loss: 0.2126 - val_accuracy: 0.7202\n",
      "Epoch 918/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2166 - accuracy: 0.7140 - val_loss: 0.2125 - val_accuracy: 0.7203\n",
      "Epoch 919/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.7194 - val_loss: 0.2125 - val_accuracy: 0.7204\n",
      "Epoch 920/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2155 - accuracy: 0.7166 - val_loss: 0.2125 - val_accuracy: 0.7204\n",
      "Epoch 921/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2144 - accuracy: 0.7164 - val_loss: 0.2125 - val_accuracy: 0.7203\n",
      "Epoch 922/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2135 - accuracy: 0.7198 - val_loss: 0.2125 - val_accuracy: 0.7203\n",
      "Epoch 923/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.7172 - val_loss: 0.2124 - val_accuracy: 0.7198\n",
      "Epoch 924/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.7166 - val_loss: 0.2124 - val_accuracy: 0.7198\n",
      "Epoch 925/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.7225 - val_loss: 0.2124 - val_accuracy: 0.7202\n",
      "Epoch 926/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2139 - accuracy: 0.7201 - val_loss: 0.2124 - val_accuracy: 0.7202\n",
      "Epoch 927/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2110 - accuracy: 0.7277 - val_loss: 0.2123 - val_accuracy: 0.7202\n",
      "Epoch 928/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2149 - accuracy: 0.7196 - val_loss: 0.2123 - val_accuracy: 0.7202\n",
      "Epoch 929/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.7246 - val_loss: 0.2123 - val_accuracy: 0.7202\n",
      "Epoch 930/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2151 - accuracy: 0.7184 - val_loss: 0.2123 - val_accuracy: 0.7202\n",
      "Epoch 931/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.7195 - val_loss: 0.2123 - val_accuracy: 0.7202\n",
      "Epoch 932/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7131 - val_loss: 0.2122 - val_accuracy: 0.7202\n",
      "Epoch 933/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.7205 - val_loss: 0.2122 - val_accuracy: 0.7202\n",
      "Epoch 934/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.7179 - val_loss: 0.2122 - val_accuracy: 0.7202\n",
      "Epoch 935/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.7268 - val_loss: 0.2122 - val_accuracy: 0.7202\n",
      "Epoch 936/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.7286 - val_loss: 0.2121 - val_accuracy: 0.7202\n",
      "Epoch 937/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.7190 - val_loss: 0.2121 - val_accuracy: 0.7203\n",
      "Epoch 938/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2143 - accuracy: 0.7226 - val_loss: 0.2121 - val_accuracy: 0.7202\n",
      "Epoch 939/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.7224 - val_loss: 0.2121 - val_accuracy: 0.7202\n",
      "Epoch 940/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.7115 - val_loss: 0.2121 - val_accuracy: 0.7202\n",
      "Epoch 941/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.7236 - val_loss: 0.2120 - val_accuracy: 0.7202\n",
      "Epoch 942/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.7150 - val_loss: 0.2120 - val_accuracy: 0.7202\n",
      "Epoch 943/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.7267 - val_loss: 0.2120 - val_accuracy: 0.7202\n",
      "Epoch 944/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.7226 - val_loss: 0.2120 - val_accuracy: 0.7202\n",
      "Epoch 945/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.7204 - val_loss: 0.2120 - val_accuracy: 0.7201\n",
      "Epoch 946/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.7207 - val_loss: 0.2119 - val_accuracy: 0.7201\n",
      "Epoch 947/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.7219 - val_loss: 0.2119 - val_accuracy: 0.7201\n",
      "Epoch 948/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.7241 - val_loss: 0.2119 - val_accuracy: 0.7201\n",
      "Epoch 949/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.7224 - val_loss: 0.2119 - val_accuracy: 0.7200\n",
      "Epoch 950/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.7255 - val_loss: 0.2118 - val_accuracy: 0.7200\n",
      "Epoch 951/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.7240 - val_loss: 0.2118 - val_accuracy: 0.7200\n",
      "Epoch 952/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2155 - accuracy: 0.7111 - val_loss: 0.2118 - val_accuracy: 0.7200\n",
      "Epoch 953/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2129 - accuracy: 0.7230 - val_loss: 0.2118 - val_accuracy: 0.7199\n",
      "Epoch 954/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2156 - accuracy: 0.7157 - val_loss: 0.2118 - val_accuracy: 0.7199\n",
      "Epoch 955/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.7158 - val_loss: 0.2117 - val_accuracy: 0.7199\n",
      "Epoch 956/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2147 - accuracy: 0.7179 - val_loss: 0.2117 - val_accuracy: 0.7199\n",
      "Epoch 957/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.7267 - val_loss: 0.2117 - val_accuracy: 0.7199\n",
      "Epoch 958/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2143 - accuracy: 0.7203 - val_loss: 0.2117 - val_accuracy: 0.7210\n",
      "Epoch 959/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2127 - accuracy: 0.7227 - val_loss: 0.2117 - val_accuracy: 0.7210\n",
      "Epoch 960/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.7221 - val_loss: 0.2116 - val_accuracy: 0.7210\n",
      "Epoch 961/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2135 - accuracy: 0.7228 - val_loss: 0.2116 - val_accuracy: 0.7210\n",
      "Epoch 962/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.7194 - val_loss: 0.2116 - val_accuracy: 0.7210\n",
      "Epoch 963/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2139 - accuracy: 0.7156 - val_loss: 0.2116 - val_accuracy: 0.7210\n",
      "Epoch 964/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.7273 - val_loss: 0.2115 - val_accuracy: 0.7210\n",
      "Epoch 965/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.7299 - val_loss: 0.2115 - val_accuracy: 0.7210\n",
      "Epoch 966/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.7271 - val_loss: 0.2115 - val_accuracy: 0.7210\n",
      "Epoch 967/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2122 - accuracy: 0.7244 - val_loss: 0.2115 - val_accuracy: 0.7210\n",
      "Epoch 968/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2128 - accuracy: 0.7295 - val_loss: 0.2115 - val_accuracy: 0.7210\n",
      "Epoch 969/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.7227 - val_loss: 0.2114 - val_accuracy: 0.7212\n",
      "Epoch 970/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2121 - accuracy: 0.7217 - val_loss: 0.2114 - val_accuracy: 0.7212\n",
      "Epoch 971/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2128 - accuracy: 0.7220 - val_loss: 0.2114 - val_accuracy: 0.7212\n",
      "Epoch 972/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.7262 - val_loss: 0.2114 - val_accuracy: 0.7212\n",
      "Epoch 973/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.7186 - val_loss: 0.2114 - val_accuracy: 0.7212\n",
      "Epoch 974/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.7227 - val_loss: 0.2113 - val_accuracy: 0.7212\n",
      "Epoch 975/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.7232 - val_loss: 0.2113 - val_accuracy: 0.7212\n",
      "Epoch 976/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.7195 - val_loss: 0.2113 - val_accuracy: 0.7212\n",
      "Epoch 977/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.7181 - val_loss: 0.2113 - val_accuracy: 0.7212\n",
      "Epoch 978/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.7159 - val_loss: 0.2113 - val_accuracy: 0.7212\n",
      "Epoch 979/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2140 - accuracy: 0.7196 - val_loss: 0.2112 - val_accuracy: 0.7213\n",
      "Epoch 980/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.7250 - val_loss: 0.2112 - val_accuracy: 0.7213\n",
      "Epoch 981/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.7247 - val_loss: 0.2112 - val_accuracy: 0.7213\n",
      "Epoch 982/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.7257 - val_loss: 0.2112 - val_accuracy: 0.7213\n",
      "Epoch 983/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2150 - accuracy: 0.7138 - val_loss: 0.2112 - val_accuracy: 0.7213\n",
      "Epoch 984/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2126 - accuracy: 0.7268 - val_loss: 0.2111 - val_accuracy: 0.7213\n",
      "Epoch 985/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.7196 - val_loss: 0.2111 - val_accuracy: 0.7213\n",
      "Epoch 986/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.7203 - val_loss: 0.2111 - val_accuracy: 0.7213\n",
      "Epoch 987/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.7219 - val_loss: 0.2111 - val_accuracy: 0.7213\n",
      "Epoch 988/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2116 - accuracy: 0.7227 - val_loss: 0.2111 - val_accuracy: 0.7213\n",
      "Epoch 989/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2103 - accuracy: 0.7341 - val_loss: 0.2110 - val_accuracy: 0.7213\n",
      "Epoch 990/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2134 - accuracy: 0.7236 - val_loss: 0.2110 - val_accuracy: 0.7213\n",
      "Epoch 991/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.7203 - val_loss: 0.2110 - val_accuracy: 0.7213\n",
      "Epoch 992/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.7239 - val_loss: 0.2110 - val_accuracy: 0.7213\n",
      "Epoch 993/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.7197 - val_loss: 0.2110 - val_accuracy: 0.7213\n",
      "Epoch 994/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2113 - accuracy: 0.7226 - val_loss: 0.2109 - val_accuracy: 0.7213\n",
      "Epoch 995/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.7244 - val_loss: 0.2109 - val_accuracy: 0.7213\n",
      "Epoch 996/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2110 - accuracy: 0.7302 - val_loss: 0.2109 - val_accuracy: 0.7215\n",
      "Epoch 997/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.7315 - val_loss: 0.2109 - val_accuracy: 0.7216\n",
      "Epoch 998/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.7273 - val_loss: 0.2109 - val_accuracy: 0.7216\n",
      "Epoch 999/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.7188 - val_loss: 0.2108 - val_accuracy: 0.7216\n",
      "Epoch 1000/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.7257 - val_loss: 0.2108 - val_accuracy: 0.7217\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A21 = nn_A21.fit(X_train_scaled, y_train, validation_split=0.6, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 6 Results\n",
      "Loss: 0.21291719377040863, Accuracy: 0.7204664945602417\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 21 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A21.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Model 22+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A22 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A22 =  (number_input_features + number_output_neurons_A22) // 2\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A22 =  (hidden_nodes_layer1_A22 + number_output_neurons_A22) // 2\n",
    "# Review the number of hidden nodes in the second layer\n",
    "hidden_nodes_layer2_A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\n",
    "hidden_nodes_layer3_A22 =  (hidden_nodes_layer2_A22 + number_output_neurons_A22) // 2\n",
    "# Review the number of hidden nodes in the third layer\n",
    "hidden_nodes_layer3_A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fourth hidden layer\n",
    "hidden_nodes_layer4_A22 =  (hidden_nodes_layer3_A22 + number_output_neurons_A22) // 2\n",
    "# Review the number of hidden nodes in the fourth layer\n",
    "hidden_nodes_layer4_A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fifth hidden layer\n",
    "hidden_nodes_layer5_A22 =  (hidden_nodes_layer4_A22 + number_output_neurons_A22) // 2\n",
    "# Review the number of hidden nodes in the fifth layer\n",
    "hidden_nodes_layer5_A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the Sixth hidden layer\n",
    "hidden_nodes_layer6_A22 =  (hidden_nodes_layer5_A22 + number_output_neurons_A22) // 2\n",
    "# Review the number of hidden nodes in the sixth layer\n",
    "hidden_nodes_layer6_A22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 57)                6555      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 29)                1682      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 8,864\n",
      "Trainable params: 8,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Display the Sequential Model Instance \n",
    "# for Model A22\n",
    "nn_A22 = Sequential() \n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_A22.add(Dense(units=hidden_nodes_layer1_A22, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the second hidden layer\n",
    "nn_A22.add(Dense(units=hidden_nodes_layer2_A22, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the third hidden layer\n",
    "nn_A22.add(Dense(units=hidden_nodes_layer3_A22, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fourth hidden layer\n",
    "nn_A22.add(Dense(units=hidden_nodes_layer4_A22, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fifth hidden layer\n",
    "nn_A22.add(Dense(units=hidden_nodes_layer5_A22, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the sixth hidden layer\n",
    "nn_A22.add(Dense(units=hidden_nodes_layer6_A22, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_A22.add(Dense(units=number_output_neurons_A22, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_A22.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A22.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.6277 - val_loss: 0.2090 - val_accuracy: 0.7204\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2085 - accuracy: 0.7178 - val_loss: 0.2016 - val_accuracy: 0.7270\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2011 - accuracy: 0.7301 - val_loss: 0.1992 - val_accuracy: 0.7263\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.7214 - val_loss: 0.1949 - val_accuracy: 0.7277\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1955 - accuracy: 0.7248 - val_loss: 0.1936 - val_accuracy: 0.7282\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.7328 - val_loss: 0.1932 - val_accuracy: 0.7293\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1897 - accuracy: 0.7306 - val_loss: 0.1920 - val_accuracy: 0.7286\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.7341 - val_loss: 0.1909 - val_accuracy: 0.7310\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.7375 - val_loss: 0.1903 - val_accuracy: 0.7302\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.7404 - val_loss: 0.1897 - val_accuracy: 0.7304\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.7402 - val_loss: 0.1900 - val_accuracy: 0.7305\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.7410 - val_loss: 0.1910 - val_accuracy: 0.7296\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.7436 - val_loss: 0.1899 - val_accuracy: 0.7297\n",
      "Epoch 14/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.7285 - val_loss: 0.1915 - val_accuracy: 0.7281\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.7439 - val_loss: 0.1899 - val_accuracy: 0.7294\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.7390 - val_loss: 0.1901 - val_accuracy: 0.7288\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1836 - accuracy: 0.7417 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7359 - val_loss: 0.1896 - val_accuracy: 0.7280\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.7295 - val_loss: 0.1890 - val_accuracy: 0.7297\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7397 - val_loss: 0.1897 - val_accuracy: 0.7245\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7469 - val_loss: 0.1880 - val_accuracy: 0.7304\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.7358 - val_loss: 0.1884 - val_accuracy: 0.7295\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1826 - accuracy: 0.7416 - val_loss: 0.1890 - val_accuracy: 0.7291\n",
      "Epoch 24/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7411 - val_loss: 0.1881 - val_accuracy: 0.7285\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7409 - val_loss: 0.1893 - val_accuracy: 0.7293\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1836 - accuracy: 0.7404 - val_loss: 0.1907 - val_accuracy: 0.7254\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.7430 - val_loss: 0.1889 - val_accuracy: 0.7285\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.7465 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1816 - accuracy: 0.7410 - val_loss: 0.1891 - val_accuracy: 0.7265\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.7409 - val_loss: 0.1892 - val_accuracy: 0.7274\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7395 - val_loss: 0.1888 - val_accuracy: 0.7285\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.7434 - val_loss: 0.1891 - val_accuracy: 0.7274\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7393 - val_loss: 0.1898 - val_accuracy: 0.7286\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7393 - val_loss: 0.1889 - val_accuracy: 0.7278\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.7367 - val_loss: 0.1893 - val_accuracy: 0.7259\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.7397 - val_loss: 0.1890 - val_accuracy: 0.7248\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7341 - val_loss: 0.1889 - val_accuracy: 0.7277\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7405 - val_loss: 0.1892 - val_accuracy: 0.7277\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.7438 - val_loss: 0.1893 - val_accuracy: 0.7276\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7369 - val_loss: 0.1897 - val_accuracy: 0.7280\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.7462 - val_loss: 0.1886 - val_accuracy: 0.7281\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7443 - val_loss: 0.1888 - val_accuracy: 0.7281\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1794 - accuracy: 0.7435 - val_loss: 0.1888 - val_accuracy: 0.7274\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.7411 - val_loss: 0.1899 - val_accuracy: 0.7256\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7443 - val_loss: 0.1894 - val_accuracy: 0.7265\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1814 - accuracy: 0.7423 - val_loss: 0.1894 - val_accuracy: 0.7269\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1806 - accuracy: 0.7439 - val_loss: 0.1892 - val_accuracy: 0.7260\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.7327 - val_loss: 0.1894 - val_accuracy: 0.7270\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.7432 - val_loss: 0.1903 - val_accuracy: 0.7260\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.7386 - val_loss: 0.1893 - val_accuracy: 0.7265\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1789 - accuracy: 0.7468 - val_loss: 0.1893 - val_accuracy: 0.7278\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.7496 - val_loss: 0.1892 - val_accuracy: 0.7273\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.7370 - val_loss: 0.1900 - val_accuracy: 0.7254\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.7440 - val_loss: 0.1895 - val_accuracy: 0.7270\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.7382 - val_loss: 0.1895 - val_accuracy: 0.7272\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7342 - val_loss: 0.1892 - val_accuracy: 0.7282\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.7334 - val_loss: 0.1894 - val_accuracy: 0.7281\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1828 - accuracy: 0.7378 - val_loss: 0.1894 - val_accuracy: 0.7289\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7435 - val_loss: 0.1893 - val_accuracy: 0.7283\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7368 - val_loss: 0.1899 - val_accuracy: 0.7278\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.7465 - val_loss: 0.1893 - val_accuracy: 0.7280\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.7407 - val_loss: 0.1894 - val_accuracy: 0.7288\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7456 - val_loss: 0.1898 - val_accuracy: 0.7281\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7418 - val_loss: 0.1894 - val_accuracy: 0.7261\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7435 - val_loss: 0.1895 - val_accuracy: 0.7274\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.7322 - val_loss: 0.1894 - val_accuracy: 0.7278\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.7375 - val_loss: 0.1895 - val_accuracy: 0.7274\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7381 - val_loss: 0.1891 - val_accuracy: 0.7280\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7414 - val_loss: 0.1907 - val_accuracy: 0.7269\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7430 - val_loss: 0.1893 - val_accuracy: 0.7287\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.7362 - val_loss: 0.1896 - val_accuracy: 0.7272\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7424 - val_loss: 0.1892 - val_accuracy: 0.7274\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.7453 - val_loss: 0.1903 - val_accuracy: 0.7267\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.7455 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1810 - accuracy: 0.7400 - val_loss: 0.1901 - val_accuracy: 0.7270\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7370 - val_loss: 0.1902 - val_accuracy: 0.7263\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7388 - val_loss: 0.1897 - val_accuracy: 0.7270\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.7437 - val_loss: 0.1899 - val_accuracy: 0.7263\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.7379 - val_loss: 0.1899 - val_accuracy: 0.7276\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7403 - val_loss: 0.1895 - val_accuracy: 0.7283\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.7495 - val_loss: 0.1911 - val_accuracy: 0.7257\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.7421 - val_loss: 0.1898 - val_accuracy: 0.7272\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1782 - accuracy: 0.7452 - val_loss: 0.1901 - val_accuracy: 0.7265\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7433 - val_loss: 0.1900 - val_accuracy: 0.7280\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.7465 - val_loss: 0.1897 - val_accuracy: 0.7276\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.7482 - val_loss: 0.1900 - val_accuracy: 0.7276\n",
      "Epoch 87/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1821 - accuracy: 0.7366 - val_loss: 0.1898 - val_accuracy: 0.7272\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7402 - val_loss: 0.1895 - val_accuracy: 0.7267\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7410 - val_loss: 0.1895 - val_accuracy: 0.7270\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.7421 - val_loss: 0.1906 - val_accuracy: 0.7262\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7369 - val_loss: 0.1903 - val_accuracy: 0.7279\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7359 - val_loss: 0.1899 - val_accuracy: 0.7275\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7365 - val_loss: 0.1911 - val_accuracy: 0.7277\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7361 - val_loss: 0.1907 - val_accuracy: 0.7256\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7425 - val_loss: 0.1908 - val_accuracy: 0.7278\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1802 - accuracy: 0.7423 - val_loss: 0.1911 - val_accuracy: 0.7276\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7380 - val_loss: 0.1893 - val_accuracy: 0.7265\n",
      "Epoch 98/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1774 - accuracy: 0.7500 - val_loss: 0.1901 - val_accuracy: 0.7279\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7388 - val_loss: 0.1903 - val_accuracy: 0.7259\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.7345 - val_loss: 0.1908 - val_accuracy: 0.7273\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7414 - val_loss: 0.1899 - val_accuracy: 0.7278\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7374 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.7421 - val_loss: 0.1897 - val_accuracy: 0.7278\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1777 - accuracy: 0.7432 - val_loss: 0.1899 - val_accuracy: 0.7281\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.7447 - val_loss: 0.1901 - val_accuracy: 0.7274\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.7492 - val_loss: 0.1907 - val_accuracy: 0.7270\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7293 - val_loss: 0.1910 - val_accuracy: 0.7263\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7404 - val_loss: 0.1907 - val_accuracy: 0.7265\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1771 - accuracy: 0.7499 - val_loss: 0.1912 - val_accuracy: 0.7271\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7441 - val_loss: 0.1912 - val_accuracy: 0.7263\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1781 - accuracy: 0.7485 - val_loss: 0.1910 - val_accuracy: 0.7264\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1795 - accuracy: 0.7440 - val_loss: 0.1915 - val_accuracy: 0.7257\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.7447 - val_loss: 0.1908 - val_accuracy: 0.7265\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7390 - val_loss: 0.1910 - val_accuracy: 0.7262\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7392 - val_loss: 0.1905 - val_accuracy: 0.7272\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.7330 - val_loss: 0.1909 - val_accuracy: 0.7275\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7391 - val_loss: 0.1906 - val_accuracy: 0.7260\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7441 - val_loss: 0.1921 - val_accuracy: 0.7248\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7391 - val_loss: 0.1908 - val_accuracy: 0.7254\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7424 - val_loss: 0.1917 - val_accuracy: 0.7245\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7406 - val_loss: 0.1906 - val_accuracy: 0.7261\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7490 - val_loss: 0.1900 - val_accuracy: 0.7275\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7401 - val_loss: 0.1914 - val_accuracy: 0.7267\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7395 - val_loss: 0.1909 - val_accuracy: 0.7258\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7416 - val_loss: 0.1919 - val_accuracy: 0.7273\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7368 - val_loss: 0.1909 - val_accuracy: 0.7276\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7409 - val_loss: 0.1929 - val_accuracy: 0.7263\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.7386 - val_loss: 0.1921 - val_accuracy: 0.7263\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7397 - val_loss: 0.1945 - val_accuracy: 0.7291\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.7500 - val_loss: 0.1916 - val_accuracy: 0.7274\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7414 - val_loss: 0.1919 - val_accuracy: 0.7290\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.7517 - val_loss: 0.1913 - val_accuracy: 0.7273\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1795 - accuracy: 0.7486 - val_loss: 0.1910 - val_accuracy: 0.7268\n",
      "Epoch 134/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7399 - val_loss: 0.1917 - val_accuracy: 0.7272\n",
      "Epoch 135/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7374 - val_loss: 0.1936 - val_accuracy: 0.7277\n",
      "Epoch 136/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7431 - val_loss: 0.1918 - val_accuracy: 0.7280\n",
      "Epoch 137/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7449 - val_loss: 0.1915 - val_accuracy: 0.7270\n",
      "Epoch 138/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7417 - val_loss: 0.1919 - val_accuracy: 0.7264\n",
      "Epoch 139/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7382 - val_loss: 0.1913 - val_accuracy: 0.7272\n",
      "Epoch 140/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7418 - val_loss: 0.1925 - val_accuracy: 0.7236\n",
      "Epoch 141/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1801 - accuracy: 0.7481 - val_loss: 0.1920 - val_accuracy: 0.7275\n",
      "Epoch 142/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7382 - val_loss: 0.1943 - val_accuracy: 0.7247\n",
      "Epoch 143/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7438 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 144/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7417 - val_loss: 0.1921 - val_accuracy: 0.7267\n",
      "Epoch 145/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1805 - accuracy: 0.7465 - val_loss: 0.1920 - val_accuracy: 0.7241\n",
      "Epoch 146/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7413 - val_loss: 0.1917 - val_accuracy: 0.7258\n",
      "Epoch 147/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7417 - val_loss: 0.1916 - val_accuracy: 0.7278\n",
      "Epoch 148/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7410 - val_loss: 0.1910 - val_accuracy: 0.7285\n",
      "Epoch 149/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1775 - accuracy: 0.7518 - val_loss: 0.1914 - val_accuracy: 0.7276\n",
      "Epoch 150/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7496 - val_loss: 0.1911 - val_accuracy: 0.7267\n",
      "Epoch 151/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7423 - val_loss: 0.1919 - val_accuracy: 0.7283\n",
      "Epoch 152/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7442 - val_loss: 0.1916 - val_accuracy: 0.7277\n",
      "Epoch 153/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7419 - val_loss: 0.1908 - val_accuracy: 0.7277\n",
      "Epoch 154/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1812 - accuracy: 0.7450 - val_loss: 0.1917 - val_accuracy: 0.7286\n",
      "Epoch 155/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7343 - val_loss: 0.1919 - val_accuracy: 0.7252\n",
      "Epoch 156/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7379 - val_loss: 0.1921 - val_accuracy: 0.7262\n",
      "Epoch 157/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.7454 - val_loss: 0.1919 - val_accuracy: 0.7252\n",
      "Epoch 158/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.7426 - val_loss: 0.1921 - val_accuracy: 0.7255\n",
      "Epoch 159/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.7485 - val_loss: 0.1909 - val_accuracy: 0.7278\n",
      "Epoch 160/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7325 - val_loss: 0.1918 - val_accuracy: 0.7280\n",
      "Epoch 161/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1825 - accuracy: 0.7355 - val_loss: 0.1910 - val_accuracy: 0.7279\n",
      "Epoch 162/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7439 - val_loss: 0.1919 - val_accuracy: 0.7256\n",
      "Epoch 163/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7437 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 164/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.7410 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 165/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7399 - val_loss: 0.1921 - val_accuracy: 0.7250\n",
      "Epoch 166/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7446 - val_loss: 0.1919 - val_accuracy: 0.7291\n",
      "Epoch 167/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7474 - val_loss: 0.1922 - val_accuracy: 0.7265\n",
      "Epoch 168/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7391 - val_loss: 0.1922 - val_accuracy: 0.7265\n",
      "Epoch 169/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7406 - val_loss: 0.1919 - val_accuracy: 0.7275\n",
      "Epoch 170/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7405 - val_loss: 0.1919 - val_accuracy: 0.7272\n",
      "Epoch 171/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7425 - val_loss: 0.1924 - val_accuracy: 0.7272\n",
      "Epoch 172/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7444 - val_loss: 0.1934 - val_accuracy: 0.7270\n",
      "Epoch 173/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7413 - val_loss: 0.1918 - val_accuracy: 0.7270\n",
      "Epoch 174/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.7380 - val_loss: 0.1912 - val_accuracy: 0.7263\n",
      "Epoch 175/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.7490 - val_loss: 0.1915 - val_accuracy: 0.7269\n",
      "Epoch 176/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7388 - val_loss: 0.1916 - val_accuracy: 0.7276\n",
      "Epoch 177/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7455 - val_loss: 0.1917 - val_accuracy: 0.7247\n",
      "Epoch 178/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7405 - val_loss: 0.1924 - val_accuracy: 0.7265\n",
      "Epoch 179/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7413 - val_loss: 0.1923 - val_accuracy: 0.7261\n",
      "Epoch 180/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7470 - val_loss: 0.1912 - val_accuracy: 0.7259\n",
      "Epoch 181/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.7435 - val_loss: 0.1916 - val_accuracy: 0.7263\n",
      "Epoch 182/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7392 - val_loss: 0.1919 - val_accuracy: 0.7266\n",
      "Epoch 183/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.7411 - val_loss: 0.1923 - val_accuracy: 0.7273\n",
      "Epoch 184/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7453 - val_loss: 0.1926 - val_accuracy: 0.7262\n",
      "Epoch 185/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7437 - val_loss: 0.1919 - val_accuracy: 0.7283\n",
      "Epoch 186/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7392 - val_loss: 0.1921 - val_accuracy: 0.7277\n",
      "Epoch 187/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1792 - accuracy: 0.7488 - val_loss: 0.1914 - val_accuracy: 0.7274\n",
      "Epoch 188/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1778 - accuracy: 0.7512 - val_loss: 0.1917 - val_accuracy: 0.7249\n",
      "Epoch 189/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7453 - val_loss: 0.1919 - val_accuracy: 0.7271\n",
      "Epoch 190/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7405 - val_loss: 0.1948 - val_accuracy: 0.7252\n",
      "Epoch 191/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.7395 - val_loss: 0.1921 - val_accuracy: 0.7258\n",
      "Epoch 192/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7382 - val_loss: 0.1917 - val_accuracy: 0.7269\n",
      "Epoch 193/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7404 - val_loss: 0.1908 - val_accuracy: 0.7277\n",
      "Epoch 194/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7392 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 195/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7416 - val_loss: 0.1905 - val_accuracy: 0.7289\n",
      "Epoch 196/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7431 - val_loss: 0.1915 - val_accuracy: 0.7295\n",
      "Epoch 197/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7360 - val_loss: 0.1918 - val_accuracy: 0.7267\n",
      "Epoch 198/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7441 - val_loss: 0.1932 - val_accuracy: 0.7239\n",
      "Epoch 199/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7370 - val_loss: 0.1927 - val_accuracy: 0.7264\n",
      "Epoch 200/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.7439 - val_loss: 0.1909 - val_accuracy: 0.7282\n",
      "Epoch 201/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7381 - val_loss: 0.1909 - val_accuracy: 0.7259\n",
      "Epoch 202/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7432 - val_loss: 0.1911 - val_accuracy: 0.7267\n",
      "Epoch 203/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.7419 - val_loss: 0.1920 - val_accuracy: 0.7272\n",
      "Epoch 204/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7447 - val_loss: 0.1927 - val_accuracy: 0.7267\n",
      "Epoch 205/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7418 - val_loss: 0.1916 - val_accuracy: 0.7276\n",
      "Epoch 206/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7464 - val_loss: 0.1916 - val_accuracy: 0.7268\n",
      "Epoch 207/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.7362 - val_loss: 0.1923 - val_accuracy: 0.7263\n",
      "Epoch 208/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.7373 - val_loss: 0.1918 - val_accuracy: 0.7280\n",
      "Epoch 209/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7439 - val_loss: 0.1934 - val_accuracy: 0.7254\n",
      "Epoch 210/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7451 - val_loss: 0.1916 - val_accuracy: 0.7276\n",
      "Epoch 211/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7371 - val_loss: 0.1925 - val_accuracy: 0.7286\n",
      "Epoch 212/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7364 - val_loss: 0.1911 - val_accuracy: 0.7286\n",
      "Epoch 213/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7383 - val_loss: 0.1918 - val_accuracy: 0.7270\n",
      "Epoch 214/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.7484 - val_loss: 0.1924 - val_accuracy: 0.7267\n",
      "Epoch 215/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7417 - val_loss: 0.1919 - val_accuracy: 0.7277\n",
      "Epoch 216/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7498 - val_loss: 0.1910 - val_accuracy: 0.7266\n",
      "Epoch 217/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7416 - val_loss: 0.1918 - val_accuracy: 0.7277\n",
      "Epoch 218/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7423 - val_loss: 0.1922 - val_accuracy: 0.7272\n",
      "Epoch 219/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7458 - val_loss: 0.1917 - val_accuracy: 0.7278\n",
      "Epoch 220/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7463 - val_loss: 0.1921 - val_accuracy: 0.7267\n",
      "Epoch 221/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.7501 - val_loss: 0.1914 - val_accuracy: 0.7277\n",
      "Epoch 222/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.7459 - val_loss: 0.1923 - val_accuracy: 0.7255\n",
      "Epoch 223/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7413 - val_loss: 0.1920 - val_accuracy: 0.7267\n",
      "Epoch 224/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7384 - val_loss: 0.1920 - val_accuracy: 0.7272\n",
      "Epoch 225/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.7465 - val_loss: 0.1922 - val_accuracy: 0.7258\n",
      "Epoch 226/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7316 - val_loss: 0.1923 - val_accuracy: 0.7265\n",
      "Epoch 227/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7408 - val_loss: 0.1919 - val_accuracy: 0.7261\n",
      "Epoch 228/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.7442 - val_loss: 0.1915 - val_accuracy: 0.7287\n",
      "Epoch 229/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1856 - accuracy: 0.7379 - val_loss: 0.1902 - val_accuracy: 0.7305\n",
      "Epoch 230/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7374 - val_loss: 0.1914 - val_accuracy: 0.7278\n",
      "Epoch 231/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7445 - val_loss: 0.1924 - val_accuracy: 0.7249\n",
      "Epoch 232/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7435 - val_loss: 0.1910 - val_accuracy: 0.7269\n",
      "Epoch 233/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7412 - val_loss: 0.1916 - val_accuracy: 0.7276\n",
      "Epoch 234/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7376 - val_loss: 0.1910 - val_accuracy: 0.7255\n",
      "Epoch 235/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7434 - val_loss: 0.1917 - val_accuracy: 0.7294\n",
      "Epoch 236/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.7383 - val_loss: 0.1906 - val_accuracy: 0.7291\n",
      "Epoch 237/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7409 - val_loss: 0.1936 - val_accuracy: 0.7278\n",
      "Epoch 238/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7406 - val_loss: 0.1907 - val_accuracy: 0.7302\n",
      "Epoch 239/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7414 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 240/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7414 - val_loss: 0.1914 - val_accuracy: 0.7295\n",
      "Epoch 241/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7446 - val_loss: 0.1922 - val_accuracy: 0.7264\n",
      "Epoch 242/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7337 - val_loss: 0.1927 - val_accuracy: 0.7247\n",
      "Epoch 243/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7416 - val_loss: 0.1924 - val_accuracy: 0.7262\n",
      "Epoch 244/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7431 - val_loss: 0.1912 - val_accuracy: 0.7275\n",
      "Epoch 245/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.7392 - val_loss: 0.1917 - val_accuracy: 0.7276\n",
      "Epoch 246/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.7437 - val_loss: 0.1907 - val_accuracy: 0.7296\n",
      "Epoch 247/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7440 - val_loss: 0.1919 - val_accuracy: 0.7270\n",
      "Epoch 248/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7410 - val_loss: 0.1916 - val_accuracy: 0.7267\n",
      "Epoch 249/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7404 - val_loss: 0.1916 - val_accuracy: 0.7269\n",
      "Epoch 250/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.7389 - val_loss: 0.1918 - val_accuracy: 0.7267\n",
      "Epoch 251/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7457 - val_loss: 0.1921 - val_accuracy: 0.7256\n",
      "Epoch 252/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7423 - val_loss: 0.1932 - val_accuracy: 0.7269\n",
      "Epoch 253/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.7431 - val_loss: 0.1928 - val_accuracy: 0.7253\n",
      "Epoch 254/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7493 - val_loss: 0.1908 - val_accuracy: 0.7282\n",
      "Epoch 255/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1767 - accuracy: 0.7542 - val_loss: 0.1923 - val_accuracy: 0.7268\n",
      "Epoch 256/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7362 - val_loss: 0.1919 - val_accuracy: 0.7267\n",
      "Epoch 257/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.7531 - val_loss: 0.1949 - val_accuracy: 0.7239\n",
      "Epoch 258/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7390 - val_loss: 0.1926 - val_accuracy: 0.7243\n",
      "Epoch 259/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7381 - val_loss: 0.1909 - val_accuracy: 0.7291\n",
      "Epoch 260/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7424 - val_loss: 0.1921 - val_accuracy: 0.7259\n",
      "Epoch 261/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.7411 - val_loss: 0.1912 - val_accuracy: 0.7287\n",
      "Epoch 262/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.7447 - val_loss: 0.1929 - val_accuracy: 0.7245\n",
      "Epoch 263/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7366 - val_loss: 0.1918 - val_accuracy: 0.7282\n",
      "Epoch 264/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7345 - val_loss: 0.1916 - val_accuracy: 0.7282\n",
      "Epoch 265/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7430 - val_loss: 0.1913 - val_accuracy: 0.7278\n",
      "Epoch 266/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.7484 - val_loss: 0.1917 - val_accuracy: 0.7279\n",
      "Epoch 267/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7418 - val_loss: 0.1940 - val_accuracy: 0.7254\n",
      "Epoch 268/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7445 - val_loss: 0.1932 - val_accuracy: 0.7278\n",
      "Epoch 269/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7432 - val_loss: 0.1957 - val_accuracy: 0.7240\n",
      "Epoch 270/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1834 - accuracy: 0.7419 - val_loss: 0.1936 - val_accuracy: 0.7258\n",
      "Epoch 271/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7403 - val_loss: 0.1936 - val_accuracy: 0.7278\n",
      "Epoch 272/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7437 - val_loss: 0.1937 - val_accuracy: 0.7272\n",
      "Epoch 273/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7440 - val_loss: 0.1940 - val_accuracy: 0.7265\n",
      "Epoch 274/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.7455 - val_loss: 0.1956 - val_accuracy: 0.7262\n",
      "Epoch 275/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7432 - val_loss: 0.1970 - val_accuracy: 0.7250\n",
      "Epoch 276/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7440 - val_loss: 0.1934 - val_accuracy: 0.7271\n",
      "Epoch 277/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7447 - val_loss: 0.1950 - val_accuracy: 0.7253\n",
      "Epoch 278/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7413 - val_loss: 0.1925 - val_accuracy: 0.7289\n",
      "Epoch 279/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7471 - val_loss: 0.1938 - val_accuracy: 0.7250\n",
      "Epoch 280/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7447 - val_loss: 0.1930 - val_accuracy: 0.7280\n",
      "Epoch 281/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7410 - val_loss: 0.1949 - val_accuracy: 0.7274\n",
      "Epoch 282/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.7436 - val_loss: 0.1933 - val_accuracy: 0.7271\n",
      "Epoch 283/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7472 - val_loss: 0.1947 - val_accuracy: 0.7247\n",
      "Epoch 284/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7457 - val_loss: 0.1932 - val_accuracy: 0.7243\n",
      "Epoch 285/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7460 - val_loss: 0.1937 - val_accuracy: 0.7258\n",
      "Epoch 286/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7369 - val_loss: 0.1969 - val_accuracy: 0.7270\n",
      "Epoch 287/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7377 - val_loss: 0.1949 - val_accuracy: 0.7270\n",
      "Epoch 288/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.7388 - val_loss: 0.1949 - val_accuracy: 0.7228\n",
      "Epoch 289/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7444 - val_loss: 0.1955 - val_accuracy: 0.7238\n",
      "Epoch 290/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7410 - val_loss: 0.1934 - val_accuracy: 0.7279\n",
      "Epoch 291/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.7358 - val_loss: 0.1933 - val_accuracy: 0.7255\n",
      "Epoch 292/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7351 - val_loss: 0.1958 - val_accuracy: 0.7155\n",
      "Epoch 293/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7352 - val_loss: 0.1956 - val_accuracy: 0.7268\n",
      "Epoch 294/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7403 - val_loss: 0.1951 - val_accuracy: 0.7273\n",
      "Epoch 295/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.7391 - val_loss: 0.1954 - val_accuracy: 0.7269\n",
      "Epoch 296/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7403 - val_loss: 0.1956 - val_accuracy: 0.7269\n",
      "Epoch 297/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7434 - val_loss: 0.1952 - val_accuracy: 0.7268\n",
      "Epoch 298/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7441 - val_loss: 0.1969 - val_accuracy: 0.7265\n",
      "Epoch 299/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.7396 - val_loss: 0.1963 - val_accuracy: 0.7274\n",
      "Epoch 300/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7463 - val_loss: 0.1954 - val_accuracy: 0.7261\n",
      "Epoch 301/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7467 - val_loss: 0.1964 - val_accuracy: 0.7247\n",
      "Epoch 302/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7457 - val_loss: 0.1943 - val_accuracy: 0.7276\n",
      "Epoch 303/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7470 - val_loss: 0.1947 - val_accuracy: 0.7272\n",
      "Epoch 304/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.7380 - val_loss: 0.1951 - val_accuracy: 0.7280\n",
      "Epoch 305/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7469 - val_loss: 0.1972 - val_accuracy: 0.7231\n",
      "Epoch 306/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7449 - val_loss: 0.1974 - val_accuracy: 0.7224\n",
      "Epoch 307/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.7396 - val_loss: 0.1968 - val_accuracy: 0.7220\n",
      "Epoch 308/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7343 - val_loss: 0.1973 - val_accuracy: 0.7240\n",
      "Epoch 309/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.7421 - val_loss: 0.1948 - val_accuracy: 0.7263\n",
      "Epoch 310/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7468 - val_loss: 0.1965 - val_accuracy: 0.7260\n",
      "Epoch 311/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.7454 - val_loss: 0.1957 - val_accuracy: 0.7257\n",
      "Epoch 312/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7410 - val_loss: 0.1968 - val_accuracy: 0.7229\n",
      "Epoch 313/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.7324 - val_loss: 0.1955 - val_accuracy: 0.7263\n",
      "Epoch 314/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7382 - val_loss: 0.1956 - val_accuracy: 0.7265\n",
      "Epoch 315/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.7370 - val_loss: 0.1951 - val_accuracy: 0.7262\n",
      "Epoch 316/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1852 - accuracy: 0.7449 - val_loss: 0.1959 - val_accuracy: 0.7248\n",
      "Epoch 317/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7417 - val_loss: 0.1950 - val_accuracy: 0.7256\n",
      "Epoch 318/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7380 - val_loss: 0.1936 - val_accuracy: 0.7267\n",
      "Epoch 319/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7393 - val_loss: 0.1945 - val_accuracy: 0.7261\n",
      "Epoch 320/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7354 - val_loss: 0.1937 - val_accuracy: 0.7261\n",
      "Epoch 321/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7391 - val_loss: 0.1943 - val_accuracy: 0.7261\n",
      "Epoch 322/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7461 - val_loss: 0.1949 - val_accuracy: 0.7270\n",
      "Epoch 323/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7417 - val_loss: 0.1966 - val_accuracy: 0.7241\n",
      "Epoch 324/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.7262 - val_loss: 0.2000 - val_accuracy: 0.7142\n",
      "Epoch 325/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7199 - val_loss: 0.2039 - val_accuracy: 0.7103\n",
      "Epoch 326/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7245 - val_loss: 0.1946 - val_accuracy: 0.7259\n",
      "Epoch 327/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7405 - val_loss: 0.1960 - val_accuracy: 0.7257\n",
      "Epoch 328/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7381 - val_loss: 0.1940 - val_accuracy: 0.7269\n",
      "Epoch 329/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7418 - val_loss: 0.1954 - val_accuracy: 0.7248\n",
      "Epoch 330/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1889 - accuracy: 0.7331 - val_loss: 0.1932 - val_accuracy: 0.7278\n",
      "Epoch 331/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7399 - val_loss: 0.1947 - val_accuracy: 0.7263\n",
      "Epoch 332/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1859 - accuracy: 0.7398 - val_loss: 0.1944 - val_accuracy: 0.7266\n",
      "Epoch 333/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7436 - val_loss: 0.1942 - val_accuracy: 0.7275\n",
      "Epoch 334/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7404 - val_loss: 0.1947 - val_accuracy: 0.7280\n",
      "Epoch 335/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.7361 - val_loss: 0.1944 - val_accuracy: 0.7272\n",
      "Epoch 336/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.7394 - val_loss: 0.1947 - val_accuracy: 0.7266\n",
      "Epoch 337/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7414 - val_loss: 0.1957 - val_accuracy: 0.7269\n",
      "Epoch 338/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7461 - val_loss: 0.1955 - val_accuracy: 0.7264\n",
      "Epoch 339/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7411 - val_loss: 0.1946 - val_accuracy: 0.7264\n",
      "Epoch 340/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.7398 - val_loss: 0.1959 - val_accuracy: 0.7270\n",
      "Epoch 341/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7403 - val_loss: 0.1965 - val_accuracy: 0.7254\n",
      "Epoch 342/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7416 - val_loss: 0.1953 - val_accuracy: 0.7258\n",
      "Epoch 343/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7439 - val_loss: 0.1951 - val_accuracy: 0.7259\n",
      "Epoch 344/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.7403 - val_loss: 0.1950 - val_accuracy: 0.7266\n",
      "Epoch 345/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7391 - val_loss: 0.1940 - val_accuracy: 0.7263\n",
      "Epoch 346/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7372 - val_loss: 0.1943 - val_accuracy: 0.7266\n",
      "Epoch 347/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7416 - val_loss: 0.1944 - val_accuracy: 0.7262\n",
      "Epoch 348/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.7435 - val_loss: 0.1956 - val_accuracy: 0.7266\n",
      "Epoch 349/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7399 - val_loss: 0.1940 - val_accuracy: 0.7253\n",
      "Epoch 350/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7462 - val_loss: 0.1950 - val_accuracy: 0.7239\n",
      "Epoch 351/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.7355 - val_loss: 0.1946 - val_accuracy: 0.7259\n",
      "Epoch 352/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7343 - val_loss: 0.1965 - val_accuracy: 0.7253\n",
      "Epoch 353/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.7447 - val_loss: 0.1951 - val_accuracy: 0.7249\n",
      "Epoch 354/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.7448 - val_loss: 0.1952 - val_accuracy: 0.7258\n",
      "Epoch 355/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.7331 - val_loss: 0.1936 - val_accuracy: 0.7269\n",
      "Epoch 356/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.7369 - val_loss: 0.1946 - val_accuracy: 0.7244\n",
      "Epoch 357/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7388 - val_loss: 0.1941 - val_accuracy: 0.7262\n",
      "Epoch 358/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7397 - val_loss: 0.1949 - val_accuracy: 0.7246\n",
      "Epoch 359/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7428 - val_loss: 0.1948 - val_accuracy: 0.7260\n",
      "Epoch 360/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 0.7323 - val_loss: 0.1937 - val_accuracy: 0.7270\n",
      "Epoch 361/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.7410 - val_loss: 0.1935 - val_accuracy: 0.7272\n",
      "Epoch 362/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.7333 - val_loss: 0.1958 - val_accuracy: 0.7274\n",
      "Epoch 363/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7488 - val_loss: 0.1960 - val_accuracy: 0.7265\n",
      "Epoch 364/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7430 - val_loss: 0.1953 - val_accuracy: 0.7269\n",
      "Epoch 365/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1851 - accuracy: 0.7450 - val_loss: 0.1944 - val_accuracy: 0.7274\n",
      "Epoch 366/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7415 - val_loss: 0.1981 - val_accuracy: 0.7243\n",
      "Epoch 367/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7392 - val_loss: 0.1965 - val_accuracy: 0.7224\n",
      "Epoch 368/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7483 - val_loss: 0.1950 - val_accuracy: 0.7267\n",
      "Epoch 369/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.7449 - val_loss: 0.1965 - val_accuracy: 0.7269\n",
      "Epoch 370/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7477 - val_loss: 0.2016 - val_accuracy: 0.7132\n",
      "Epoch 371/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7335 - val_loss: 0.1964 - val_accuracy: 0.7263\n",
      "Epoch 372/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7490 - val_loss: 0.1961 - val_accuracy: 0.7280\n",
      "Epoch 373/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.7380 - val_loss: 0.1950 - val_accuracy: 0.7272\n",
      "Epoch 374/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7448 - val_loss: 0.1950 - val_accuracy: 0.7259\n",
      "Epoch 375/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1919 - accuracy: 0.7305 - val_loss: 0.1950 - val_accuracy: 0.7268\n",
      "Epoch 376/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7457 - val_loss: 0.1947 - val_accuracy: 0.7265\n",
      "Epoch 377/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1882 - accuracy: 0.7377 - val_loss: 0.1963 - val_accuracy: 0.7269\n",
      "Epoch 378/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7402 - val_loss: 0.1955 - val_accuracy: 0.7267\n",
      "Epoch 379/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7459 - val_loss: 0.1958 - val_accuracy: 0.7265\n",
      "Epoch 380/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.7459 - val_loss: 0.1980 - val_accuracy: 0.7250\n",
      "Epoch 381/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7358 - val_loss: 0.1957 - val_accuracy: 0.7262\n",
      "Epoch 382/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7436 - val_loss: 0.1949 - val_accuracy: 0.7264\n",
      "Epoch 383/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7399 - val_loss: 0.1960 - val_accuracy: 0.7264\n",
      "Epoch 384/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.7477 - val_loss: 0.1950 - val_accuracy: 0.7258\n",
      "Epoch 385/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7471 - val_loss: 0.1948 - val_accuracy: 0.7273\n",
      "Epoch 386/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.7421 - val_loss: 0.1951 - val_accuracy: 0.7274\n",
      "Epoch 387/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.7382 - val_loss: 0.1974 - val_accuracy: 0.7277\n",
      "Epoch 388/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.7412 - val_loss: 0.1957 - val_accuracy: 0.7255\n",
      "Epoch 389/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1877 - accuracy: 0.7413 - val_loss: 0.1961 - val_accuracy: 0.7248\n",
      "Epoch 390/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1890 - accuracy: 0.7372 - val_loss: 0.1954 - val_accuracy: 0.7280\n",
      "Epoch 391/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7440 - val_loss: 0.1952 - val_accuracy: 0.7268\n",
      "Epoch 392/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1891 - accuracy: 0.7337 - val_loss: 0.1950 - val_accuracy: 0.7270\n",
      "Epoch 393/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7406 - val_loss: 0.1958 - val_accuracy: 0.7252\n",
      "Epoch 394/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7449 - val_loss: 0.1969 - val_accuracy: 0.7261\n",
      "Epoch 395/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7461 - val_loss: 0.1959 - val_accuracy: 0.7270\n",
      "Epoch 396/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7408 - val_loss: 0.1965 - val_accuracy: 0.7264\n",
      "Epoch 397/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7432 - val_loss: 0.1954 - val_accuracy: 0.7272\n",
      "Epoch 398/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7410 - val_loss: 0.1971 - val_accuracy: 0.7223\n",
      "Epoch 399/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7490 - val_loss: 0.1958 - val_accuracy: 0.7254\n",
      "Epoch 400/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7450 - val_loss: 0.1957 - val_accuracy: 0.7270\n",
      "Epoch 401/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.7386 - val_loss: 0.1951 - val_accuracy: 0.7271\n",
      "Epoch 402/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7329 - val_loss: 0.2019 - val_accuracy: 0.7132\n",
      "Epoch 403/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.7325 - val_loss: 0.1950 - val_accuracy: 0.7270\n",
      "Epoch 404/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7476 - val_loss: 0.1951 - val_accuracy: 0.7269\n",
      "Epoch 405/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7422 - val_loss: 0.1960 - val_accuracy: 0.7252\n",
      "Epoch 406/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7370 - val_loss: 0.1960 - val_accuracy: 0.7264\n",
      "Epoch 407/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7393 - val_loss: 0.1953 - val_accuracy: 0.7268\n",
      "Epoch 408/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7409 - val_loss: 0.1961 - val_accuracy: 0.7265\n",
      "Epoch 409/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7378 - val_loss: 0.1959 - val_accuracy: 0.7259\n",
      "Epoch 410/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.7441 - val_loss: 0.1958 - val_accuracy: 0.7264\n",
      "Epoch 411/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7377 - val_loss: 0.1955 - val_accuracy: 0.7265\n",
      "Epoch 412/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7426 - val_loss: 0.1956 - val_accuracy: 0.7273\n",
      "Epoch 413/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.7421 - val_loss: 0.1957 - val_accuracy: 0.7256\n",
      "Epoch 414/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.7460 - val_loss: 0.1957 - val_accuracy: 0.7253\n",
      "Epoch 415/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7405 - val_loss: 0.1955 - val_accuracy: 0.7258\n",
      "Epoch 416/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7460 - val_loss: 0.1960 - val_accuracy: 0.7261\n",
      "Epoch 417/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.7388 - val_loss: 0.1955 - val_accuracy: 0.7279\n",
      "Epoch 418/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7460 - val_loss: 0.2018 - val_accuracy: 0.7132\n",
      "Epoch 419/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.7303 - val_loss: 0.1957 - val_accuracy: 0.7261\n",
      "Epoch 420/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7417 - val_loss: 0.1950 - val_accuracy: 0.7259\n",
      "Epoch 421/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7389 - val_loss: 0.1953 - val_accuracy: 0.7270\n",
      "Epoch 422/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7420 - val_loss: 0.1953 - val_accuracy: 0.7271\n",
      "Epoch 423/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.7469 - val_loss: 0.1964 - val_accuracy: 0.7248\n",
      "Epoch 424/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7445 - val_loss: 0.1959 - val_accuracy: 0.7236\n",
      "Epoch 425/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.7410 - val_loss: 0.1958 - val_accuracy: 0.7263\n",
      "Epoch 426/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7450 - val_loss: 0.1949 - val_accuracy: 0.7274\n",
      "Epoch 427/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.7381 - val_loss: 0.1956 - val_accuracy: 0.7270\n",
      "Epoch 428/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.7386 - val_loss: 0.1955 - val_accuracy: 0.7256\n",
      "Epoch 429/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7399 - val_loss: 0.1954 - val_accuracy: 0.7259\n",
      "Epoch 430/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7455 - val_loss: 0.1950 - val_accuracy: 0.7262\n",
      "Epoch 431/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.7419 - val_loss: 0.1956 - val_accuracy: 0.7255\n",
      "Epoch 432/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.7451 - val_loss: 0.1983 - val_accuracy: 0.7266\n",
      "Epoch 433/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7400 - val_loss: 0.1951 - val_accuracy: 0.7268\n",
      "Epoch 434/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.7457 - val_loss: 0.1961 - val_accuracy: 0.7259\n",
      "Epoch 435/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.7455 - val_loss: 0.1963 - val_accuracy: 0.7254\n",
      "Epoch 436/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7424 - val_loss: 0.1978 - val_accuracy: 0.7233\n",
      "Epoch 437/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.7403 - val_loss: 0.1969 - val_accuracy: 0.7239\n",
      "Epoch 438/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7402 - val_loss: 0.1960 - val_accuracy: 0.7250\n",
      "Epoch 439/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7414 - val_loss: 0.1961 - val_accuracy: 0.7251\n",
      "Epoch 440/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7401 - val_loss: 0.1959 - val_accuracy: 0.7237\n",
      "Epoch 441/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7385 - val_loss: 0.1965 - val_accuracy: 0.7260\n",
      "Epoch 442/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7402 - val_loss: 0.1960 - val_accuracy: 0.7266\n",
      "Epoch 443/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.7382 - val_loss: 0.1970 - val_accuracy: 0.7262\n",
      "Epoch 444/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.7446 - val_loss: 0.1962 - val_accuracy: 0.7258\n",
      "Epoch 445/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.7389 - val_loss: 0.1967 - val_accuracy: 0.7255\n",
      "Epoch 446/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7457 - val_loss: 0.1959 - val_accuracy: 0.7261\n",
      "Epoch 447/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7415 - val_loss: 0.1974 - val_accuracy: 0.7257\n",
      "Epoch 448/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7488 - val_loss: 0.1964 - val_accuracy: 0.7254\n",
      "Epoch 449/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7371 - val_loss: 0.1961 - val_accuracy: 0.7256\n",
      "Epoch 450/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7425 - val_loss: 0.1958 - val_accuracy: 0.7259\n",
      "Epoch 451/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.7369 - val_loss: 0.1971 - val_accuracy: 0.7266\n",
      "Epoch 452/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1891 - accuracy: 0.7363 - val_loss: 0.1961 - val_accuracy: 0.7260\n",
      "Epoch 453/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7409 - val_loss: 0.1958 - val_accuracy: 0.7257\n",
      "Epoch 454/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7434 - val_loss: 0.1955 - val_accuracy: 0.7267\n",
      "Epoch 455/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7423 - val_loss: 0.1969 - val_accuracy: 0.7223\n",
      "Epoch 456/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1877 - accuracy: 0.7381 - val_loss: 0.1964 - val_accuracy: 0.7242\n",
      "Epoch 457/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7427 - val_loss: 0.1970 - val_accuracy: 0.7256\n",
      "Epoch 458/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7394 - val_loss: 0.1956 - val_accuracy: 0.7249\n",
      "Epoch 459/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7464 - val_loss: 0.1960 - val_accuracy: 0.7249\n",
      "Epoch 460/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.7434 - val_loss: 0.1980 - val_accuracy: 0.7260\n",
      "Epoch 461/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7398 - val_loss: 0.1960 - val_accuracy: 0.7250\n",
      "Epoch 462/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7397 - val_loss: 0.1997 - val_accuracy: 0.7243\n",
      "Epoch 463/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7365 - val_loss: 0.1959 - val_accuracy: 0.7256\n",
      "Epoch 464/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7461 - val_loss: 0.1965 - val_accuracy: 0.7241\n",
      "Epoch 465/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7383 - val_loss: 0.1971 - val_accuracy: 0.7216\n",
      "Epoch 466/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7408 - val_loss: 0.1984 - val_accuracy: 0.7215\n",
      "Epoch 467/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7316 - val_loss: 0.1951 - val_accuracy: 0.7252\n",
      "Epoch 468/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7425 - val_loss: 0.1982 - val_accuracy: 0.7217\n",
      "Epoch 469/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7402 - val_loss: 0.1973 - val_accuracy: 0.7239\n",
      "Epoch 470/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.7361 - val_loss: 0.1980 - val_accuracy: 0.7204\n",
      "Epoch 471/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7379 - val_loss: 0.1972 - val_accuracy: 0.7247\n",
      "Epoch 472/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.7341 - val_loss: 0.1961 - val_accuracy: 0.7276\n",
      "Epoch 473/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7406 - val_loss: 0.1970 - val_accuracy: 0.7259\n",
      "Epoch 474/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7460 - val_loss: 0.1981 - val_accuracy: 0.7212\n",
      "Epoch 475/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7449 - val_loss: 0.1955 - val_accuracy: 0.7258\n",
      "Epoch 476/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7459 - val_loss: 0.1951 - val_accuracy: 0.7263\n",
      "Epoch 477/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7430 - val_loss: 0.1959 - val_accuracy: 0.7239\n",
      "Epoch 478/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7454 - val_loss: 0.1961 - val_accuracy: 0.7248\n",
      "Epoch 479/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.7435 - val_loss: 0.1954 - val_accuracy: 0.7265\n",
      "Epoch 480/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7358 - val_loss: 0.1960 - val_accuracy: 0.7235\n",
      "Epoch 481/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7442 - val_loss: 0.1976 - val_accuracy: 0.7248\n",
      "Epoch 482/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7350 - val_loss: 0.1956 - val_accuracy: 0.7258\n",
      "Epoch 483/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7379 - val_loss: 0.1956 - val_accuracy: 0.7252\n",
      "Epoch 484/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7466 - val_loss: 0.1967 - val_accuracy: 0.7251\n",
      "Epoch 485/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7417 - val_loss: 0.1955 - val_accuracy: 0.7256\n",
      "Epoch 486/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7324 - val_loss: 0.1972 - val_accuracy: 0.7258\n",
      "Epoch 487/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7464 - val_loss: 0.1956 - val_accuracy: 0.7259\n",
      "Epoch 488/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7449 - val_loss: 0.1956 - val_accuracy: 0.7256\n",
      "Epoch 489/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7395 - val_loss: 0.1979 - val_accuracy: 0.7241\n",
      "Epoch 490/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7367 - val_loss: 0.1962 - val_accuracy: 0.7258\n",
      "Epoch 491/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.7396 - val_loss: 0.1960 - val_accuracy: 0.7272\n",
      "Epoch 492/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1901 - accuracy: 0.7348 - val_loss: 0.1962 - val_accuracy: 0.7260\n",
      "Epoch 493/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7380 - val_loss: 0.1945 - val_accuracy: 0.7262\n",
      "Epoch 494/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7391 - val_loss: 0.1961 - val_accuracy: 0.7246\n",
      "Epoch 495/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.7311 - val_loss: 0.1959 - val_accuracy: 0.7263\n",
      "Epoch 496/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7432 - val_loss: 0.1965 - val_accuracy: 0.7224\n",
      "Epoch 497/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7485 - val_loss: 0.1966 - val_accuracy: 0.7249\n",
      "Epoch 498/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7454 - val_loss: 0.1955 - val_accuracy: 0.7263\n",
      "Epoch 499/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7386 - val_loss: 0.1981 - val_accuracy: 0.7236\n",
      "Epoch 500/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7470 - val_loss: 0.1968 - val_accuracy: 0.7219\n",
      "Epoch 501/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7459 - val_loss: 0.1955 - val_accuracy: 0.7264\n",
      "Epoch 502/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1860 - accuracy: 0.7442 - val_loss: 0.1957 - val_accuracy: 0.7262\n",
      "Epoch 503/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.7332 - val_loss: 0.1967 - val_accuracy: 0.7236\n",
      "Epoch 504/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.7443 - val_loss: 0.1964 - val_accuracy: 0.7233\n",
      "Epoch 505/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7371 - val_loss: 0.1957 - val_accuracy: 0.7264\n",
      "Epoch 506/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7401 - val_loss: 0.1950 - val_accuracy: 0.7248\n",
      "Epoch 507/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7487 - val_loss: 0.1947 - val_accuracy: 0.7251\n",
      "Epoch 508/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.7360 - val_loss: 0.1967 - val_accuracy: 0.7230\n",
      "Epoch 509/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7448 - val_loss: 0.1957 - val_accuracy: 0.7246\n",
      "Epoch 510/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7470 - val_loss: 0.1949 - val_accuracy: 0.7258\n",
      "Epoch 511/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7426 - val_loss: 0.1950 - val_accuracy: 0.7269\n",
      "Epoch 512/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7414 - val_loss: 0.1954 - val_accuracy: 0.7248\n",
      "Epoch 513/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7434 - val_loss: 0.1955 - val_accuracy: 0.7263\n",
      "Epoch 514/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7449 - val_loss: 0.1955 - val_accuracy: 0.7240\n",
      "Epoch 515/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7428 - val_loss: 0.1966 - val_accuracy: 0.7238\n",
      "Epoch 516/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1886 - accuracy: 0.7398 - val_loss: 0.1965 - val_accuracy: 0.7266\n",
      "Epoch 517/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.7394 - val_loss: 0.1951 - val_accuracy: 0.7265\n",
      "Epoch 518/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7471 - val_loss: 0.1952 - val_accuracy: 0.7255\n",
      "Epoch 519/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7507 - val_loss: 0.1951 - val_accuracy: 0.7270\n",
      "Epoch 520/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7414 - val_loss: 0.1967 - val_accuracy: 0.7244\n",
      "Epoch 521/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7311 - val_loss: 0.1966 - val_accuracy: 0.7236\n",
      "Epoch 522/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7419 - val_loss: 0.1945 - val_accuracy: 0.7272\n",
      "Epoch 523/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7380 - val_loss: 0.1943 - val_accuracy: 0.7254\n",
      "Epoch 524/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.7425 - val_loss: 0.1961 - val_accuracy: 0.7247\n",
      "Epoch 525/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7451 - val_loss: 0.1947 - val_accuracy: 0.7252\n",
      "Epoch 526/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7365 - val_loss: 0.1975 - val_accuracy: 0.7232\n",
      "Epoch 527/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7402 - val_loss: 0.1971 - val_accuracy: 0.7231\n",
      "Epoch 528/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7384 - val_loss: 0.1954 - val_accuracy: 0.7258\n",
      "Epoch 529/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7446 - val_loss: 0.1957 - val_accuracy: 0.7251\n",
      "Epoch 530/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7413 - val_loss: 0.1949 - val_accuracy: 0.7258\n",
      "Epoch 531/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7381 - val_loss: 0.1978 - val_accuracy: 0.7218\n",
      "Epoch 532/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7435 - val_loss: 0.1956 - val_accuracy: 0.7255\n",
      "Epoch 533/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.7332 - val_loss: 0.1956 - val_accuracy: 0.7271\n",
      "Epoch 534/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7452 - val_loss: 0.1954 - val_accuracy: 0.7245\n",
      "Epoch 535/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.7338 - val_loss: 0.1962 - val_accuracy: 0.7211\n",
      "Epoch 536/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7476 - val_loss: 0.1951 - val_accuracy: 0.7237\n",
      "Epoch 537/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7433 - val_loss: 0.1947 - val_accuracy: 0.7265\n",
      "Epoch 538/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7427 - val_loss: 0.1954 - val_accuracy: 0.7245\n",
      "Epoch 539/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7433 - val_loss: 0.1968 - val_accuracy: 0.7237\n",
      "Epoch 540/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7375 - val_loss: 0.1958 - val_accuracy: 0.7280\n",
      "Epoch 541/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7506 - val_loss: 0.2021 - val_accuracy: 0.7140\n",
      "Epoch 542/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7348 - val_loss: 0.1962 - val_accuracy: 0.7244\n",
      "Epoch 543/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7380 - val_loss: 0.1958 - val_accuracy: 0.7261\n",
      "Epoch 544/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.7460 - val_loss: 0.1958 - val_accuracy: 0.7263\n",
      "Epoch 545/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7399 - val_loss: 0.2010 - val_accuracy: 0.7139\n",
      "Epoch 546/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1887 - accuracy: 0.7347 - val_loss: 0.1964 - val_accuracy: 0.7248\n",
      "Epoch 547/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.7402 - val_loss: 0.1974 - val_accuracy: 0.7278\n",
      "Epoch 548/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7483 - val_loss: 0.2054 - val_accuracy: 0.7028\n",
      "Epoch 549/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.7366 - val_loss: 0.1968 - val_accuracy: 0.7207\n",
      "Epoch 550/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7369 - val_loss: 0.1949 - val_accuracy: 0.7259\n",
      "Epoch 551/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.7332 - val_loss: 0.1947 - val_accuracy: 0.7265\n",
      "Epoch 552/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.7343 - val_loss: 0.1983 - val_accuracy: 0.7215\n",
      "Epoch 553/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7361 - val_loss: 0.1947 - val_accuracy: 0.7242\n",
      "Epoch 554/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7441 - val_loss: 0.1951 - val_accuracy: 0.7258\n",
      "Epoch 555/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7399 - val_loss: 0.1952 - val_accuracy: 0.7260\n",
      "Epoch 556/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7469 - val_loss: 0.1958 - val_accuracy: 0.7224\n",
      "Epoch 557/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7466 - val_loss: 0.1944 - val_accuracy: 0.7253\n",
      "Epoch 558/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.7300 - val_loss: 0.1954 - val_accuracy: 0.7256\n",
      "Epoch 559/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7437 - val_loss: 0.1955 - val_accuracy: 0.7259\n",
      "Epoch 560/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7402 - val_loss: 0.1961 - val_accuracy: 0.7275\n",
      "Epoch 561/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.7364 - val_loss: 0.1963 - val_accuracy: 0.7214\n",
      "Epoch 562/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7445 - val_loss: 0.1959 - val_accuracy: 0.7264\n",
      "Epoch 563/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7525 - val_loss: 0.1970 - val_accuracy: 0.7258\n",
      "Epoch 564/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7458 - val_loss: 0.1944 - val_accuracy: 0.7241\n",
      "Epoch 565/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.7359 - val_loss: 0.1947 - val_accuracy: 0.7259\n",
      "Epoch 566/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.7408 - val_loss: 0.1948 - val_accuracy: 0.7257\n",
      "Epoch 567/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1857 - accuracy: 0.7427 - val_loss: 0.1954 - val_accuracy: 0.7263\n",
      "Epoch 568/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1841 - accuracy: 0.7457 - val_loss: 0.1949 - val_accuracy: 0.7249\n",
      "Epoch 569/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7457 - val_loss: 0.1946 - val_accuracy: 0.7267\n",
      "Epoch 570/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1902 - accuracy: 0.7371 - val_loss: 0.1958 - val_accuracy: 0.7247\n",
      "Epoch 571/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7423 - val_loss: 0.1947 - val_accuracy: 0.7260\n",
      "Epoch 572/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7481 - val_loss: 0.1961 - val_accuracy: 0.7227\n",
      "Epoch 573/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7416 - val_loss: 0.1942 - val_accuracy: 0.7277\n",
      "Epoch 574/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7455 - val_loss: 0.1970 - val_accuracy: 0.7224\n",
      "Epoch 575/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7329 - val_loss: 0.1967 - val_accuracy: 0.7252\n",
      "Epoch 576/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7425 - val_loss: 0.1966 - val_accuracy: 0.7209\n",
      "Epoch 577/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1846 - accuracy: 0.7450 - val_loss: 0.1955 - val_accuracy: 0.7267\n",
      "Epoch 578/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.7341 - val_loss: 0.1954 - val_accuracy: 0.7253\n",
      "Epoch 579/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.7432 - val_loss: 0.1950 - val_accuracy: 0.7254\n",
      "Epoch 580/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.7449 - val_loss: 0.1959 - val_accuracy: 0.7254\n",
      "Epoch 581/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7483 - val_loss: 0.1958 - val_accuracy: 0.7266\n",
      "Epoch 582/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.7380 - val_loss: 0.1943 - val_accuracy: 0.7273\n",
      "Epoch 583/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7410 - val_loss: 0.1958 - val_accuracy: 0.7239\n",
      "Epoch 584/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.7320 - val_loss: 0.1951 - val_accuracy: 0.7268\n",
      "Epoch 585/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7470 - val_loss: 0.1951 - val_accuracy: 0.7249\n",
      "Epoch 586/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.7411 - val_loss: 0.1952 - val_accuracy: 0.7252\n",
      "Epoch 587/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1852 - accuracy: 0.7403 - val_loss: 0.1957 - val_accuracy: 0.7263\n",
      "Epoch 588/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7482 - val_loss: 0.1965 - val_accuracy: 0.7259\n",
      "Epoch 589/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.7517 - val_loss: 0.1957 - val_accuracy: 0.7260\n",
      "Epoch 590/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7484 - val_loss: 0.1970 - val_accuracy: 0.7241\n",
      "Epoch 591/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7437 - val_loss: 0.1950 - val_accuracy: 0.7228\n",
      "Epoch 592/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7305 - val_loss: 0.1944 - val_accuracy: 0.7250\n",
      "Epoch 593/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.7359 - val_loss: 0.1950 - val_accuracy: 0.7263\n",
      "Epoch 594/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7430 - val_loss: 0.1948 - val_accuracy: 0.7243\n",
      "Epoch 595/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7362 - val_loss: 0.1964 - val_accuracy: 0.7243\n",
      "Epoch 596/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1916 - accuracy: 0.7300 - val_loss: 0.1957 - val_accuracy: 0.7263\n",
      "Epoch 597/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7402 - val_loss: 0.1953 - val_accuracy: 0.7241\n",
      "Epoch 598/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7466 - val_loss: 0.1955 - val_accuracy: 0.7261\n",
      "Epoch 599/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.7426 - val_loss: 0.1977 - val_accuracy: 0.7207\n",
      "Epoch 600/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.7434 - val_loss: 0.1963 - val_accuracy: 0.7248\n",
      "Epoch 601/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1886 - accuracy: 0.7327 - val_loss: 0.1952 - val_accuracy: 0.7269\n",
      "Epoch 602/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7437 - val_loss: 0.1975 - val_accuracy: 0.7274\n",
      "Epoch 603/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1872 - accuracy: 0.7398 - val_loss: 0.1951 - val_accuracy: 0.7261\n",
      "Epoch 604/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1828 - accuracy: 0.7473 - val_loss: 0.1952 - val_accuracy: 0.7261\n",
      "Epoch 605/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.7437 - val_loss: 0.1961 - val_accuracy: 0.7265\n",
      "Epoch 606/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.7417 - val_loss: 0.1979 - val_accuracy: 0.7259\n",
      "Epoch 607/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7392 - val_loss: 0.1957 - val_accuracy: 0.7241\n",
      "Epoch 608/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.7380 - val_loss: 0.1951 - val_accuracy: 0.7267\n",
      "Epoch 609/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7483 - val_loss: 0.1949 - val_accuracy: 0.7252\n",
      "Epoch 610/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7459 - val_loss: 0.1945 - val_accuracy: 0.7254\n",
      "Epoch 611/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.7379 - val_loss: 0.2011 - val_accuracy: 0.7153\n",
      "Epoch 612/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.7324 - val_loss: 0.1951 - val_accuracy: 0.7259\n",
      "Epoch 613/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1875 - accuracy: 0.7409 - val_loss: 0.1948 - val_accuracy: 0.7250\n",
      "Epoch 614/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1917 - accuracy: 0.7268 - val_loss: 0.1948 - val_accuracy: 0.7274\n",
      "Epoch 615/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1892 - accuracy: 0.7373 - val_loss: 0.1952 - val_accuracy: 0.7272\n",
      "Epoch 616/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7518 - val_loss: 0.1964 - val_accuracy: 0.7229\n",
      "Epoch 617/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7336 - val_loss: 0.1959 - val_accuracy: 0.7244\n",
      "Epoch 618/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7480 - val_loss: 0.1961 - val_accuracy: 0.7253\n",
      "Epoch 619/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1879 - accuracy: 0.7368 - val_loss: 0.1962 - val_accuracy: 0.7266\n",
      "Epoch 620/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7394 - val_loss: 0.1963 - val_accuracy: 0.7243\n",
      "Epoch 621/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1903 - accuracy: 0.7339 - val_loss: 0.1963 - val_accuracy: 0.7230\n",
      "Epoch 622/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7443 - val_loss: 0.1966 - val_accuracy: 0.7268\n",
      "Epoch 623/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7422 - val_loss: 0.1956 - val_accuracy: 0.7254\n",
      "Epoch 624/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7412 - val_loss: 0.1961 - val_accuracy: 0.7251\n",
      "Epoch 625/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.7432 - val_loss: 0.1954 - val_accuracy: 0.7239\n",
      "Epoch 626/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7436 - val_loss: 0.1956 - val_accuracy: 0.7248\n",
      "Epoch 627/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.7430 - val_loss: 0.1960 - val_accuracy: 0.7256\n",
      "Epoch 628/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.7407 - val_loss: 0.1959 - val_accuracy: 0.7255\n",
      "Epoch 629/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7416 - val_loss: 0.1958 - val_accuracy: 0.7245\n",
      "Epoch 630/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1881 - accuracy: 0.7372 - val_loss: 0.1958 - val_accuracy: 0.7259\n",
      "Epoch 631/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7411 - val_loss: 0.1962 - val_accuracy: 0.7254\n",
      "Epoch 632/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7436 - val_loss: 0.1971 - val_accuracy: 0.7223\n",
      "Epoch 633/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7391 - val_loss: 0.1960 - val_accuracy: 0.7253\n",
      "Epoch 634/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7454 - val_loss: 0.1967 - val_accuracy: 0.7242\n",
      "Epoch 635/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7364 - val_loss: 0.1948 - val_accuracy: 0.7254\n",
      "Epoch 636/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7389 - val_loss: 0.1962 - val_accuracy: 0.7245\n",
      "Epoch 637/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7435 - val_loss: 0.1952 - val_accuracy: 0.7261\n",
      "Epoch 638/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7361 - val_loss: 0.1953 - val_accuracy: 0.7258\n",
      "Epoch 639/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7379 - val_loss: 0.1952 - val_accuracy: 0.7261\n",
      "Epoch 640/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.7364 - val_loss: 0.1965 - val_accuracy: 0.7219\n",
      "Epoch 641/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7420 - val_loss: 0.1954 - val_accuracy: 0.7260\n",
      "Epoch 642/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.7335 - val_loss: 0.1954 - val_accuracy: 0.7259\n",
      "Epoch 643/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7383 - val_loss: 0.1974 - val_accuracy: 0.7247\n",
      "Epoch 644/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7373 - val_loss: 0.1972 - val_accuracy: 0.7261\n",
      "Epoch 645/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7454 - val_loss: 0.1972 - val_accuracy: 0.7252\n",
      "Epoch 646/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.7383 - val_loss: 0.1958 - val_accuracy: 0.7264\n",
      "Epoch 647/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.7448 - val_loss: 0.1948 - val_accuracy: 0.7252\n",
      "Epoch 648/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.7430 - val_loss: 0.1958 - val_accuracy: 0.7250\n",
      "Epoch 649/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7412 - val_loss: 0.2002 - val_accuracy: 0.7212\n",
      "Epoch 650/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7408 - val_loss: 0.1958 - val_accuracy: 0.7266\n",
      "Epoch 651/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7414 - val_loss: 0.1954 - val_accuracy: 0.7257\n",
      "Epoch 652/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7392 - val_loss: 0.1974 - val_accuracy: 0.7263\n",
      "Epoch 653/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.7455 - val_loss: 0.1967 - val_accuracy: 0.7265\n",
      "Epoch 654/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7420 - val_loss: 0.1973 - val_accuracy: 0.7242\n",
      "Epoch 655/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7405 - val_loss: 0.1965 - val_accuracy: 0.7243\n",
      "Epoch 656/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7415 - val_loss: 0.1961 - val_accuracy: 0.7253\n",
      "Epoch 657/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.7347 - val_loss: 0.1958 - val_accuracy: 0.7246\n",
      "Epoch 658/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.7358 - val_loss: 0.1973 - val_accuracy: 0.7247\n",
      "Epoch 659/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.7341 - val_loss: 0.2020 - val_accuracy: 0.7263\n",
      "Epoch 660/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7378 - val_loss: 0.1978 - val_accuracy: 0.7206\n",
      "Epoch 661/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7336 - val_loss: 0.1965 - val_accuracy: 0.7245\n",
      "Epoch 662/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7368 - val_loss: 0.1973 - val_accuracy: 0.7241\n",
      "Epoch 663/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.7392 - val_loss: 0.1962 - val_accuracy: 0.7254\n",
      "Epoch 664/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1873 - accuracy: 0.7410 - val_loss: 0.1976 - val_accuracy: 0.7221\n",
      "Epoch 665/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.7332 - val_loss: 0.1943 - val_accuracy: 0.7270\n",
      "Epoch 666/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7399 - val_loss: 0.1961 - val_accuracy: 0.7274\n",
      "Epoch 667/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7480 - val_loss: 0.1952 - val_accuracy: 0.7256\n",
      "Epoch 668/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.7397 - val_loss: 0.1984 - val_accuracy: 0.7281\n",
      "Epoch 669/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7465 - val_loss: 0.1964 - val_accuracy: 0.7282\n",
      "Epoch 670/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7397 - val_loss: 0.1950 - val_accuracy: 0.7274\n",
      "Epoch 671/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.7415 - val_loss: 0.1968 - val_accuracy: 0.7229\n",
      "Epoch 672/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7418 - val_loss: 0.1958 - val_accuracy: 0.7272\n",
      "Epoch 673/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7401 - val_loss: 0.1948 - val_accuracy: 0.7267\n",
      "Epoch 674/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7470 - val_loss: 0.1946 - val_accuracy: 0.7280\n",
      "Epoch 675/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7402 - val_loss: 0.1955 - val_accuracy: 0.7249\n",
      "Epoch 676/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7354 - val_loss: 0.1988 - val_accuracy: 0.7221\n",
      "Epoch 677/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7447 - val_loss: 0.1954 - val_accuracy: 0.7277\n",
      "Epoch 678/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7391 - val_loss: 0.1959 - val_accuracy: 0.7245\n",
      "Epoch 679/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7380 - val_loss: 0.1951 - val_accuracy: 0.7259\n",
      "Epoch 680/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7416 - val_loss: 0.1950 - val_accuracy: 0.7272\n",
      "Epoch 681/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7424 - val_loss: 0.1963 - val_accuracy: 0.7235\n",
      "Epoch 682/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7387 - val_loss: 0.1958 - val_accuracy: 0.7259\n",
      "Epoch 683/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7460 - val_loss: 0.1960 - val_accuracy: 0.7288\n",
      "Epoch 684/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7406 - val_loss: 0.1967 - val_accuracy: 0.7242\n",
      "Epoch 685/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.7285 - val_loss: 0.1956 - val_accuracy: 0.7258\n",
      "Epoch 686/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1867 - accuracy: 0.7428 - val_loss: 0.2007 - val_accuracy: 0.7169\n",
      "Epoch 687/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7393 - val_loss: 0.1959 - val_accuracy: 0.7241\n",
      "Epoch 688/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7430 - val_loss: 0.1962 - val_accuracy: 0.7245\n",
      "Epoch 689/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7462 - val_loss: 0.1963 - val_accuracy: 0.7238\n",
      "Epoch 690/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7381 - val_loss: 0.1962 - val_accuracy: 0.7244\n",
      "Epoch 691/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7341 - val_loss: 0.1961 - val_accuracy: 0.7243\n",
      "Epoch 692/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7377 - val_loss: 0.1943 - val_accuracy: 0.7275\n",
      "Epoch 693/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7447 - val_loss: 0.1967 - val_accuracy: 0.7254\n",
      "Epoch 694/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1858 - accuracy: 0.7422 - val_loss: 0.1947 - val_accuracy: 0.7258\n",
      "Epoch 695/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.7470 - val_loss: 0.1943 - val_accuracy: 0.7275\n",
      "Epoch 696/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7433 - val_loss: 0.1959 - val_accuracy: 0.7240\n",
      "Epoch 697/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7527 - val_loss: 0.1956 - val_accuracy: 0.7233\n",
      "Epoch 698/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7413 - val_loss: 0.1971 - val_accuracy: 0.7249\n",
      "Epoch 699/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1899 - accuracy: 0.7353 - val_loss: 0.1987 - val_accuracy: 0.7280\n",
      "Epoch 700/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7391 - val_loss: 0.1985 - val_accuracy: 0.7280\n",
      "Epoch 701/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7430 - val_loss: 0.1951 - val_accuracy: 0.7274\n",
      "Epoch 702/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7405 - val_loss: 0.1954 - val_accuracy: 0.7250\n",
      "Epoch 703/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7367 - val_loss: 0.1961 - val_accuracy: 0.7269\n",
      "Epoch 704/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.7367 - val_loss: 0.1952 - val_accuracy: 0.7261\n",
      "Epoch 705/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7368 - val_loss: 0.1960 - val_accuracy: 0.7272\n",
      "Epoch 706/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7377 - val_loss: 0.1958 - val_accuracy: 0.7270\n",
      "Epoch 707/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.7337 - val_loss: 0.1953 - val_accuracy: 0.7279\n",
      "Epoch 708/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7395 - val_loss: 0.1961 - val_accuracy: 0.7281\n",
      "Epoch 709/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7415 - val_loss: 0.1960 - val_accuracy: 0.7280\n",
      "Epoch 710/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7423 - val_loss: 0.1957 - val_accuracy: 0.7270\n",
      "Epoch 711/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1890 - accuracy: 0.7343 - val_loss: 0.1959 - val_accuracy: 0.7243\n",
      "Epoch 712/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7437 - val_loss: 0.1965 - val_accuracy: 0.7236\n",
      "Epoch 713/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7382 - val_loss: 0.1965 - val_accuracy: 0.7255\n",
      "Epoch 714/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7391 - val_loss: 0.1943 - val_accuracy: 0.7274\n",
      "Epoch 715/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7427 - val_loss: 0.2013 - val_accuracy: 0.7163\n",
      "Epoch 716/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.7329 - val_loss: 0.1964 - val_accuracy: 0.7281\n",
      "Epoch 717/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7411 - val_loss: 0.1973 - val_accuracy: 0.7286\n",
      "Epoch 718/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7409 - val_loss: 0.1951 - val_accuracy: 0.7278\n",
      "Epoch 719/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7474 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 720/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7421 - val_loss: 0.1982 - val_accuracy: 0.7239\n",
      "Epoch 721/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7416 - val_loss: 0.1949 - val_accuracy: 0.7263\n",
      "Epoch 722/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7383 - val_loss: 0.1976 - val_accuracy: 0.7270\n",
      "Epoch 723/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7410 - val_loss: 0.1946 - val_accuracy: 0.7262\n",
      "Epoch 724/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.7373 - val_loss: 0.1950 - val_accuracy: 0.7274\n",
      "Epoch 725/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.7338 - val_loss: 0.1948 - val_accuracy: 0.7280\n",
      "Epoch 726/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7435 - val_loss: 0.1959 - val_accuracy: 0.7270\n",
      "Epoch 727/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7389 - val_loss: 0.1955 - val_accuracy: 0.7268\n",
      "Epoch 728/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7422 - val_loss: 0.1986 - val_accuracy: 0.7275\n",
      "Epoch 729/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.7388 - val_loss: 0.1958 - val_accuracy: 0.7276\n",
      "Epoch 730/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7451 - val_loss: 0.1952 - val_accuracy: 0.7263\n",
      "Epoch 731/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7369 - val_loss: 0.1946 - val_accuracy: 0.7269\n",
      "Epoch 732/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7461 - val_loss: 0.1951 - val_accuracy: 0.7267\n",
      "Epoch 733/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7439 - val_loss: 0.1978 - val_accuracy: 0.7263\n",
      "Epoch 734/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7408 - val_loss: 0.1957 - val_accuracy: 0.7270\n",
      "Epoch 735/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7395 - val_loss: 0.1976 - val_accuracy: 0.7259\n",
      "Epoch 736/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.7351 - val_loss: 0.1964 - val_accuracy: 0.7277\n",
      "Epoch 737/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7338 - val_loss: 0.1964 - val_accuracy: 0.7283\n",
      "Epoch 738/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7386 - val_loss: 0.1959 - val_accuracy: 0.7270\n",
      "Epoch 739/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.7361 - val_loss: 0.1959 - val_accuracy: 0.7252\n",
      "Epoch 740/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7391 - val_loss: 0.1974 - val_accuracy: 0.7251\n",
      "Epoch 741/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7411 - val_loss: 0.1964 - val_accuracy: 0.7244\n",
      "Epoch 742/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7415 - val_loss: 0.1960 - val_accuracy: 0.7273\n",
      "Epoch 743/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7466 - val_loss: 0.1952 - val_accuracy: 0.7256\n",
      "Epoch 744/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7403 - val_loss: 0.1974 - val_accuracy: 0.7170\n",
      "Epoch 745/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.7424 - val_loss: 0.1957 - val_accuracy: 0.7254\n",
      "Epoch 746/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7447 - val_loss: 0.1954 - val_accuracy: 0.7276\n",
      "Epoch 747/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7366 - val_loss: 0.1957 - val_accuracy: 0.7285\n",
      "Epoch 748/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7466 - val_loss: 0.1958 - val_accuracy: 0.7248\n",
      "Epoch 749/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7529 - val_loss: 0.1965 - val_accuracy: 0.7265\n",
      "Epoch 750/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.7431 - val_loss: 0.1970 - val_accuracy: 0.7244\n",
      "Epoch 751/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7465 - val_loss: 0.1950 - val_accuracy: 0.7272\n",
      "Epoch 752/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7390 - val_loss: 0.1960 - val_accuracy: 0.7226\n",
      "Epoch 753/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7355 - val_loss: 0.1978 - val_accuracy: 0.7223\n",
      "Epoch 754/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7442 - val_loss: 0.1967 - val_accuracy: 0.7237\n",
      "Epoch 755/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7390 - val_loss: 0.1971 - val_accuracy: 0.7263\n",
      "Epoch 756/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1878 - accuracy: 0.7395 - val_loss: 0.1948 - val_accuracy: 0.7264\n",
      "Epoch 757/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7394 - val_loss: 0.1951 - val_accuracy: 0.7263\n",
      "Epoch 758/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7327 - val_loss: 0.1954 - val_accuracy: 0.7259\n",
      "Epoch 759/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7397 - val_loss: 0.1967 - val_accuracy: 0.7261\n",
      "Epoch 760/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7413 - val_loss: 0.1957 - val_accuracy: 0.7267\n",
      "Epoch 761/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.7449 - val_loss: 0.1983 - val_accuracy: 0.7241\n",
      "Epoch 762/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.7377 - val_loss: 0.1950 - val_accuracy: 0.7274\n",
      "Epoch 763/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7318 - val_loss: 0.1972 - val_accuracy: 0.7224\n",
      "Epoch 764/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7381 - val_loss: 0.1957 - val_accuracy: 0.7254\n",
      "Epoch 765/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7427 - val_loss: 0.1954 - val_accuracy: 0.7261\n",
      "Epoch 766/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7496 - val_loss: 0.1956 - val_accuracy: 0.7252\n",
      "Epoch 767/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7432 - val_loss: 0.1956 - val_accuracy: 0.7250\n",
      "Epoch 768/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7381 - val_loss: 0.1970 - val_accuracy: 0.7232\n",
      "Epoch 769/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1884 - accuracy: 0.7377 - val_loss: 0.1969 - val_accuracy: 0.7195\n",
      "Epoch 770/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7305 - val_loss: 0.1978 - val_accuracy: 0.7226\n",
      "Epoch 771/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1918 - accuracy: 0.7309 - val_loss: 0.1962 - val_accuracy: 0.7230\n",
      "Epoch 772/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7366 - val_loss: 0.1955 - val_accuracy: 0.7252\n",
      "Epoch 773/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.7375 - val_loss: 0.1974 - val_accuracy: 0.7223\n",
      "Epoch 774/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7325 - val_loss: 0.1974 - val_accuracy: 0.7217\n",
      "Epoch 775/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.7373 - val_loss: 0.1965 - val_accuracy: 0.7252\n",
      "Epoch 776/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7370 - val_loss: 0.1968 - val_accuracy: 0.7246\n",
      "Epoch 777/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7379 - val_loss: 0.1962 - val_accuracy: 0.7226\n",
      "Epoch 778/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7396 - val_loss: 0.1967 - val_accuracy: 0.7232\n",
      "Epoch 779/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.7296 - val_loss: 0.1969 - val_accuracy: 0.7235\n",
      "Epoch 780/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.7379 - val_loss: 0.1960 - val_accuracy: 0.7254\n",
      "Epoch 781/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.7323 - val_loss: 0.1970 - val_accuracy: 0.7239\n",
      "Epoch 782/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.7327 - val_loss: 0.1965 - val_accuracy: 0.7259\n",
      "Epoch 783/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7387 - val_loss: 0.1963 - val_accuracy: 0.7242\n",
      "Epoch 784/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1904 - accuracy: 0.7326 - val_loss: 0.1965 - val_accuracy: 0.7250\n",
      "Epoch 785/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7453 - val_loss: 0.1953 - val_accuracy: 0.7256\n",
      "Epoch 786/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7453 - val_loss: 0.1963 - val_accuracy: 0.7273\n",
      "Epoch 787/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7380 - val_loss: 0.1966 - val_accuracy: 0.7268\n",
      "Epoch 788/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7454 - val_loss: 0.1963 - val_accuracy: 0.7232\n",
      "Epoch 789/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7501 - val_loss: 0.1960 - val_accuracy: 0.7258\n",
      "Epoch 790/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1865 - accuracy: 0.7432 - val_loss: 0.1978 - val_accuracy: 0.7267\n",
      "Epoch 791/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.7454 - val_loss: 0.1955 - val_accuracy: 0.7260\n",
      "Epoch 792/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1893 - accuracy: 0.7364 - val_loss: 0.1953 - val_accuracy: 0.7270\n",
      "Epoch 793/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.7501 - val_loss: 0.1963 - val_accuracy: 0.7236\n",
      "Epoch 794/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.7470 - val_loss: 0.1957 - val_accuracy: 0.7265\n",
      "Epoch 795/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7478 - val_loss: 0.1953 - val_accuracy: 0.7265\n",
      "Epoch 796/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1859 - accuracy: 0.7424 - val_loss: 0.1964 - val_accuracy: 0.7243\n",
      "Epoch 797/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.7384 - val_loss: 0.1986 - val_accuracy: 0.7231\n",
      "Epoch 798/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.7355 - val_loss: 0.1968 - val_accuracy: 0.7252\n",
      "Epoch 799/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7362 - val_loss: 0.1954 - val_accuracy: 0.7254\n",
      "Epoch 800/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7464 - val_loss: 0.1965 - val_accuracy: 0.7255\n",
      "Epoch 801/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1881 - accuracy: 0.7386 - val_loss: 0.1951 - val_accuracy: 0.7268\n",
      "Epoch 802/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1885 - accuracy: 0.7376 - val_loss: 0.1960 - val_accuracy: 0.7258\n",
      "Epoch 803/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.7315 - val_loss: 0.1955 - val_accuracy: 0.7264\n",
      "Epoch 804/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7445 - val_loss: 0.1958 - val_accuracy: 0.7240\n",
      "Epoch 805/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.7413 - val_loss: 0.1951 - val_accuracy: 0.7285\n",
      "Epoch 806/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7388 - val_loss: 0.1960 - val_accuracy: 0.7259\n",
      "Epoch 807/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7401 - val_loss: 0.1963 - val_accuracy: 0.7269\n",
      "Epoch 808/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7437 - val_loss: 0.1966 - val_accuracy: 0.7255\n",
      "Epoch 809/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7423 - val_loss: 0.1962 - val_accuracy: 0.7263\n",
      "Epoch 810/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7440 - val_loss: 0.1964 - val_accuracy: 0.7261\n",
      "Epoch 811/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7512 - val_loss: 0.1955 - val_accuracy: 0.7270\n",
      "Epoch 812/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7400 - val_loss: 0.1959 - val_accuracy: 0.7269\n",
      "Epoch 813/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7355 - val_loss: 0.1963 - val_accuracy: 0.7257\n",
      "Epoch 814/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7404 - val_loss: 0.1960 - val_accuracy: 0.7270\n",
      "Epoch 815/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7416 - val_loss: 0.1961 - val_accuracy: 0.7269\n",
      "Epoch 816/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7463 - val_loss: 0.1956 - val_accuracy: 0.7270\n",
      "Epoch 817/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7405 - val_loss: 0.1954 - val_accuracy: 0.7261\n",
      "Epoch 818/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.7394 - val_loss: 0.1958 - val_accuracy: 0.7259\n",
      "Epoch 819/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7427 - val_loss: 0.1964 - val_accuracy: 0.7241\n",
      "Epoch 820/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7424 - val_loss: 0.1952 - val_accuracy: 0.7272\n",
      "Epoch 821/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7375 - val_loss: 0.1966 - val_accuracy: 0.7250\n",
      "Epoch 822/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7365 - val_loss: 0.1960 - val_accuracy: 0.7265\n",
      "Epoch 823/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7409 - val_loss: 0.1954 - val_accuracy: 0.7239\n",
      "Epoch 824/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7455 - val_loss: 0.1967 - val_accuracy: 0.7257\n",
      "Epoch 825/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7434 - val_loss: 0.1962 - val_accuracy: 0.7272\n",
      "Epoch 826/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7372 - val_loss: 0.1968 - val_accuracy: 0.7247\n",
      "Epoch 827/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7396 - val_loss: 0.1955 - val_accuracy: 0.7259\n",
      "Epoch 828/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7405 - val_loss: 0.1965 - val_accuracy: 0.7267\n",
      "Epoch 829/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7355 - val_loss: 0.1963 - val_accuracy: 0.7265\n",
      "Epoch 830/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7414 - val_loss: 0.1971 - val_accuracy: 0.7267\n",
      "Epoch 831/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7337 - val_loss: 0.1970 - val_accuracy: 0.7229\n",
      "Epoch 832/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7407 - val_loss: 0.1988 - val_accuracy: 0.7256\n",
      "Epoch 833/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7413 - val_loss: 0.1961 - val_accuracy: 0.7270\n",
      "Epoch 834/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7459 - val_loss: 0.2127 - val_accuracy: 0.7130\n",
      "Epoch 835/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7388 - val_loss: 0.1948 - val_accuracy: 0.7269\n",
      "Epoch 836/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.7410 - val_loss: 0.1963 - val_accuracy: 0.7268\n",
      "Epoch 837/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1804 - accuracy: 0.7500 - val_loss: 0.1966 - val_accuracy: 0.7276\n",
      "Epoch 838/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1885 - accuracy: 0.7376 - val_loss: 0.1969 - val_accuracy: 0.7273\n",
      "Epoch 839/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1872 - accuracy: 0.7383 - val_loss: 0.1980 - val_accuracy: 0.7266\n",
      "Epoch 840/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.7366 - val_loss: 0.1958 - val_accuracy: 0.7271\n",
      "Epoch 841/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7376 - val_loss: 0.1963 - val_accuracy: 0.7271\n",
      "Epoch 842/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7453 - val_loss: 0.1958 - val_accuracy: 0.7259\n",
      "Epoch 843/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7448 - val_loss: 0.1956 - val_accuracy: 0.7270\n",
      "Epoch 844/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1878 - accuracy: 0.7405 - val_loss: 0.1956 - val_accuracy: 0.7260\n",
      "Epoch 845/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7439 - val_loss: 0.1999 - val_accuracy: 0.7224\n",
      "Epoch 846/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.7329 - val_loss: 0.1953 - val_accuracy: 0.7264\n",
      "Epoch 847/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.7348 - val_loss: 0.1955 - val_accuracy: 0.7278\n",
      "Epoch 848/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7402 - val_loss: 0.1946 - val_accuracy: 0.7280\n",
      "Epoch 849/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7385 - val_loss: 0.1968 - val_accuracy: 0.7250\n",
      "Epoch 850/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.7403 - val_loss: 0.1953 - val_accuracy: 0.7276\n",
      "Epoch 851/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.7314 - val_loss: 0.1946 - val_accuracy: 0.7269\n",
      "Epoch 852/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.7442 - val_loss: 0.1952 - val_accuracy: 0.7280\n",
      "Epoch 853/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7384 - val_loss: 0.1956 - val_accuracy: 0.7263\n",
      "Epoch 854/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7461 - val_loss: 0.1949 - val_accuracy: 0.7264\n",
      "Epoch 855/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7454 - val_loss: 0.1956 - val_accuracy: 0.7246\n",
      "Epoch 856/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7445 - val_loss: 0.1958 - val_accuracy: 0.7261\n",
      "Epoch 857/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7342 - val_loss: 0.1947 - val_accuracy: 0.7278\n",
      "Epoch 858/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7365 - val_loss: 0.1959 - val_accuracy: 0.7261\n",
      "Epoch 859/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7373 - val_loss: 0.1971 - val_accuracy: 0.7243\n",
      "Epoch 860/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.7333 - val_loss: 0.1971 - val_accuracy: 0.7250\n",
      "Epoch 861/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7394 - val_loss: 0.1950 - val_accuracy: 0.7272\n",
      "Epoch 862/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7409 - val_loss: 0.1946 - val_accuracy: 0.7269\n",
      "Epoch 863/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.7367 - val_loss: 0.1997 - val_accuracy: 0.7258\n",
      "Epoch 864/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1883 - accuracy: 0.7426 - val_loss: 0.1965 - val_accuracy: 0.7285\n",
      "Epoch 865/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7432 - val_loss: 0.1949 - val_accuracy: 0.7282\n",
      "Epoch 866/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.7400 - val_loss: 0.1962 - val_accuracy: 0.7284\n",
      "Epoch 867/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7392 - val_loss: 0.1962 - val_accuracy: 0.7265\n",
      "Epoch 868/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7403 - val_loss: 0.1955 - val_accuracy: 0.7282\n",
      "Epoch 869/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7414 - val_loss: 0.1958 - val_accuracy: 0.7278\n",
      "Epoch 870/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.7402 - val_loss: 0.1968 - val_accuracy: 0.7259\n",
      "Epoch 871/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.7397 - val_loss: 0.1955 - val_accuracy: 0.7272\n",
      "Epoch 872/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.7457 - val_loss: 0.1968 - val_accuracy: 0.7264\n",
      "Epoch 873/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7370 - val_loss: 0.1953 - val_accuracy: 0.7278\n",
      "Epoch 874/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.7413 - val_loss: 0.1952 - val_accuracy: 0.7279\n",
      "Epoch 875/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1888 - accuracy: 0.7370 - val_loss: 0.1962 - val_accuracy: 0.7266\n",
      "Epoch 876/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7438 - val_loss: 0.1970 - val_accuracy: 0.7269\n",
      "Epoch 877/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7412 - val_loss: 0.1947 - val_accuracy: 0.7256\n",
      "Epoch 878/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7402 - val_loss: 0.1962 - val_accuracy: 0.7276\n",
      "Epoch 879/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1882 - accuracy: 0.7361 - val_loss: 0.1952 - val_accuracy: 0.7262\n",
      "Epoch 880/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.7366 - val_loss: 0.1968 - val_accuracy: 0.7285\n",
      "Epoch 881/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7455 - val_loss: 0.1990 - val_accuracy: 0.7249\n",
      "Epoch 882/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7503 - val_loss: 0.1950 - val_accuracy: 0.7265\n",
      "Epoch 883/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7364 - val_loss: 0.1955 - val_accuracy: 0.7254\n",
      "Epoch 884/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7437 - val_loss: 0.1951 - val_accuracy: 0.7256\n",
      "Epoch 885/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7470 - val_loss: 0.1950 - val_accuracy: 0.7272\n",
      "Epoch 886/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7437 - val_loss: 0.1946 - val_accuracy: 0.7281\n",
      "Epoch 887/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7483 - val_loss: 0.1971 - val_accuracy: 0.7287\n",
      "Epoch 888/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7438 - val_loss: 0.1949 - val_accuracy: 0.7276\n",
      "Epoch 889/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1857 - accuracy: 0.7408 - val_loss: 0.1953 - val_accuracy: 0.7247\n",
      "Epoch 890/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7407 - val_loss: 0.1956 - val_accuracy: 0.7263\n",
      "Epoch 891/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1859 - accuracy: 0.7403 - val_loss: 0.1945 - val_accuracy: 0.7298\n",
      "Epoch 892/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1870 - accuracy: 0.7370 - val_loss: 0.1956 - val_accuracy: 0.7283\n",
      "Epoch 893/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.7451 - val_loss: 0.1963 - val_accuracy: 0.7267\n",
      "Epoch 894/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7479 - val_loss: 0.1950 - val_accuracy: 0.7272\n",
      "Epoch 895/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7411 - val_loss: 0.1951 - val_accuracy: 0.7281\n",
      "Epoch 896/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7439 - val_loss: 0.1951 - val_accuracy: 0.7277\n",
      "Epoch 897/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7404 - val_loss: 0.1951 - val_accuracy: 0.7283\n",
      "Epoch 898/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.7343 - val_loss: 0.1957 - val_accuracy: 0.7279\n",
      "Epoch 899/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7447 - val_loss: 0.1951 - val_accuracy: 0.7271\n",
      "Epoch 900/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1875 - accuracy: 0.7345 - val_loss: 0.1951 - val_accuracy: 0.7263\n",
      "Epoch 901/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7397 - val_loss: 0.1973 - val_accuracy: 0.7294\n",
      "Epoch 902/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7393 - val_loss: 0.1954 - val_accuracy: 0.7261\n",
      "Epoch 903/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7388 - val_loss: 0.1953 - val_accuracy: 0.7266\n",
      "Epoch 904/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7426 - val_loss: 0.1977 - val_accuracy: 0.7269\n",
      "Epoch 905/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7504 - val_loss: 0.1954 - val_accuracy: 0.7278\n",
      "Epoch 906/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7372 - val_loss: 0.1966 - val_accuracy: 0.7271\n",
      "Epoch 907/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7474 - val_loss: 0.1965 - val_accuracy: 0.7294\n",
      "Epoch 908/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7396 - val_loss: 0.1989 - val_accuracy: 0.7269\n",
      "Epoch 909/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7388 - val_loss: 0.1959 - val_accuracy: 0.7282\n",
      "Epoch 910/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7414 - val_loss: 0.1955 - val_accuracy: 0.7263\n",
      "Epoch 911/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7415 - val_loss: 0.1984 - val_accuracy: 0.7285\n",
      "Epoch 912/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1862 - accuracy: 0.7412 - val_loss: 0.1989 - val_accuracy: 0.7243\n",
      "Epoch 913/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.7466 - val_loss: 0.1957 - val_accuracy: 0.7254\n",
      "Epoch 914/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7436 - val_loss: 0.1955 - val_accuracy: 0.7276\n",
      "Epoch 915/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1901 - accuracy: 0.7318 - val_loss: 0.1956 - val_accuracy: 0.7285\n",
      "Epoch 916/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7413 - val_loss: 0.1974 - val_accuracy: 0.7276\n",
      "Epoch 917/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7397 - val_loss: 0.1960 - val_accuracy: 0.7264\n",
      "Epoch 918/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7484 - val_loss: 0.1958 - val_accuracy: 0.7282\n",
      "Epoch 919/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7413 - val_loss: 0.1981 - val_accuracy: 0.7266\n",
      "Epoch 920/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7410 - val_loss: 0.1951 - val_accuracy: 0.7274\n",
      "Epoch 921/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.7352 - val_loss: 0.1958 - val_accuracy: 0.7267\n",
      "Epoch 922/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.7432 - val_loss: 0.1954 - val_accuracy: 0.7265\n",
      "Epoch 923/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7369 - val_loss: 0.1954 - val_accuracy: 0.7260\n",
      "Epoch 924/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7480 - val_loss: 0.1996 - val_accuracy: 0.7250\n",
      "Epoch 925/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1818 - accuracy: 0.7487 - val_loss: 0.1950 - val_accuracy: 0.7278\n",
      "Epoch 926/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7407 - val_loss: 0.1964 - val_accuracy: 0.7279\n",
      "Epoch 927/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7469 - val_loss: 0.1986 - val_accuracy: 0.7237\n",
      "Epoch 928/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7415 - val_loss: 0.1980 - val_accuracy: 0.7246\n",
      "Epoch 929/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7459 - val_loss: 0.1954 - val_accuracy: 0.7262\n",
      "Epoch 930/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7392 - val_loss: 0.1953 - val_accuracy: 0.7263\n",
      "Epoch 931/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7436 - val_loss: 0.1978 - val_accuracy: 0.7241\n",
      "Epoch 932/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7348 - val_loss: 0.1989 - val_accuracy: 0.7245\n",
      "Epoch 933/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7430 - val_loss: 0.1981 - val_accuracy: 0.7264\n",
      "Epoch 934/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7468 - val_loss: 0.1955 - val_accuracy: 0.7278\n",
      "Epoch 935/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7482 - val_loss: 0.1953 - val_accuracy: 0.7274\n",
      "Epoch 936/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7472 - val_loss: 0.1954 - val_accuracy: 0.7267\n",
      "Epoch 937/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7404 - val_loss: 0.1955 - val_accuracy: 0.7248\n",
      "Epoch 938/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7460 - val_loss: 0.1955 - val_accuracy: 0.7265\n",
      "Epoch 939/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7394 - val_loss: 0.1969 - val_accuracy: 0.7258\n",
      "Epoch 940/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.7431 - val_loss: 0.1964 - val_accuracy: 0.7265\n",
      "Epoch 941/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7480 - val_loss: 0.1961 - val_accuracy: 0.7272\n",
      "Epoch 942/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7451 - val_loss: 0.1961 - val_accuracy: 0.7268\n",
      "Epoch 943/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.7307 - val_loss: 0.1960 - val_accuracy: 0.7252\n",
      "Epoch 944/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7447 - val_loss: 0.1965 - val_accuracy: 0.7272\n",
      "Epoch 945/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7441 - val_loss: 0.1959 - val_accuracy: 0.7258\n",
      "Epoch 946/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7440 - val_loss: 0.1970 - val_accuracy: 0.7275\n",
      "Epoch 947/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7435 - val_loss: 0.1954 - val_accuracy: 0.7269\n",
      "Epoch 948/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7402 - val_loss: 0.1960 - val_accuracy: 0.7263\n",
      "Epoch 949/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7445 - val_loss: 0.1957 - val_accuracy: 0.7255\n",
      "Epoch 950/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7427 - val_loss: 0.1967 - val_accuracy: 0.7267\n",
      "Epoch 951/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7387 - val_loss: 0.1961 - val_accuracy: 0.7254\n",
      "Epoch 952/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7451 - val_loss: 0.1958 - val_accuracy: 0.7272\n",
      "Epoch 953/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.7414 - val_loss: 0.1978 - val_accuracy: 0.7257\n",
      "Epoch 954/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7404 - val_loss: 0.1966 - val_accuracy: 0.7266\n",
      "Epoch 955/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1863 - accuracy: 0.7417 - val_loss: 0.1954 - val_accuracy: 0.7277\n",
      "Epoch 956/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.7468 - val_loss: 0.1967 - val_accuracy: 0.7261\n",
      "Epoch 957/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1861 - accuracy: 0.7411 - val_loss: 0.1971 - val_accuracy: 0.7239\n",
      "Epoch 958/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7407 - val_loss: 0.1959 - val_accuracy: 0.7272\n",
      "Epoch 959/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7455 - val_loss: 0.1958 - val_accuracy: 0.7269\n",
      "Epoch 960/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7456 - val_loss: 0.1969 - val_accuracy: 0.7273\n",
      "Epoch 961/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1869 - accuracy: 0.7406 - val_loss: 0.1959 - val_accuracy: 0.7276\n",
      "Epoch 962/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7454 - val_loss: 0.2012 - val_accuracy: 0.7262\n",
      "Epoch 963/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7384 - val_loss: 0.1965 - val_accuracy: 0.7269\n",
      "Epoch 964/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1843 - accuracy: 0.7474 - val_loss: 0.1968 - val_accuracy: 0.7256\n",
      "Epoch 965/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7405 - val_loss: 0.1962 - val_accuracy: 0.7256\n",
      "Epoch 966/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7389 - val_loss: 0.1950 - val_accuracy: 0.7265\n",
      "Epoch 967/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.7436 - val_loss: 0.1969 - val_accuracy: 0.7268\n",
      "Epoch 968/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7449 - val_loss: 0.1958 - val_accuracy: 0.7267\n",
      "Epoch 969/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7459 - val_loss: 0.1992 - val_accuracy: 0.7252\n",
      "Epoch 970/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7444 - val_loss: 0.1952 - val_accuracy: 0.7276\n",
      "Epoch 971/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7429 - val_loss: 0.1957 - val_accuracy: 0.7271\n",
      "Epoch 972/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7392 - val_loss: 0.1956 - val_accuracy: 0.7225\n",
      "Epoch 973/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7345 - val_loss: 0.1963 - val_accuracy: 0.7272\n",
      "Epoch 974/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.7365 - val_loss: 0.1957 - val_accuracy: 0.7272\n",
      "Epoch 975/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7431 - val_loss: 0.1955 - val_accuracy: 0.7287\n",
      "Epoch 976/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7330 - val_loss: 0.2042 - val_accuracy: 0.7177\n",
      "Epoch 977/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7469 - val_loss: 0.1965 - val_accuracy: 0.7269\n",
      "Epoch 978/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7464 - val_loss: 0.1959 - val_accuracy: 0.7252\n",
      "Epoch 979/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7467 - val_loss: 0.1982 - val_accuracy: 0.7271\n",
      "Epoch 980/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7406 - val_loss: 0.1954 - val_accuracy: 0.7278\n",
      "Epoch 981/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1889 - accuracy: 0.7348 - val_loss: 0.1963 - val_accuracy: 0.7264\n",
      "Epoch 982/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7342 - val_loss: 0.1973 - val_accuracy: 0.7261\n",
      "Epoch 983/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.7447 - val_loss: 0.1952 - val_accuracy: 0.7268\n",
      "Epoch 984/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.7438 - val_loss: 0.1956 - val_accuracy: 0.7278\n",
      "Epoch 985/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7432 - val_loss: 0.1955 - val_accuracy: 0.7277\n",
      "Epoch 986/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7388 - val_loss: 0.1988 - val_accuracy: 0.7272\n",
      "Epoch 987/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7443 - val_loss: 0.1982 - val_accuracy: 0.7252\n",
      "Epoch 988/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7349 - val_loss: 0.1992 - val_accuracy: 0.7277\n",
      "Epoch 989/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7422 - val_loss: 0.1957 - val_accuracy: 0.7275\n",
      "Epoch 990/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7450 - val_loss: 0.1983 - val_accuracy: 0.7264\n",
      "Epoch 991/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7520 - val_loss: 0.1960 - val_accuracy: 0.7274\n",
      "Epoch 992/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7469 - val_loss: 0.1967 - val_accuracy: 0.7256\n",
      "Epoch 993/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.7390 - val_loss: 0.1960 - val_accuracy: 0.7266\n",
      "Epoch 994/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.7406 - val_loss: 0.1959 - val_accuracy: 0.7243\n",
      "Epoch 995/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1831 - accuracy: 0.7495 - val_loss: 0.1982 - val_accuracy: 0.7241\n",
      "Epoch 996/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1871 - accuracy: 0.7362 - val_loss: 0.1963 - val_accuracy: 0.7272\n",
      "Epoch 997/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7411 - val_loss: 0.1961 - val_accuracy: 0.7259\n",
      "Epoch 998/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7454 - val_loss: 0.1957 - val_accuracy: 0.7270\n",
      "Epoch 999/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7407 - val_loss: 0.1973 - val_accuracy: 0.7259\n",
      "Epoch 1000/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1880 - accuracy: 0.7369 - val_loss: 0.1957 - val_accuracy: 0.7272\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A22 = nn_A22.fit(X_train_scaled, y_train, validation_split=0.6, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 7 Results\n",
      "Loss: 0.1975753903388977, Accuracy: 0.7243148684501648\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 22 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A22.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Model 23+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A23 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A23 =  (number_input_features + number_output_neurons_A23) // 2\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A23 =  (hidden_nodes_layer1_A23 + number_output_neurons_A23) // 2\n",
    "# Review the number of hidden nodes in the second layer\n",
    "hidden_nodes_layer2_A23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\n",
    "hidden_nodes_layer3_A23 =  (hidden_nodes_layer2_A23 + number_output_neurons_A23) // 2\n",
    "# Review the number of hidden nodes in the third layer\n",
    "hidden_nodes_layer3_A23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fourth hidden layer\n",
    "hidden_nodes_layer4_A23 =  (hidden_nodes_layer3_A23 + number_output_neurons_A23) // 2\n",
    "# Review the number of hidden nodes in the fourth layer\n",
    "hidden_nodes_layer4_A23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fifth hidden layer\n",
    "hidden_nodes_layer5_A23 =  (hidden_nodes_layer4_A23 + number_output_neurons_A23) // 2\n",
    "# Review the number of hidden nodes in the fifth layer\n",
    "hidden_nodes_layer5_A23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the Sixth hidden layer\n",
    "hidden_nodes_layer6_A23 =  (hidden_nodes_layer5_A23 + number_output_neurons_A23) // 2\n",
    "# Review the number of hidden nodes in the sixth layer\n",
    "hidden_nodes_layer6_A23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_21 (Dense)             (None, 57)                6555      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 29)                1682      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 8,864\n",
      "Trainable params: 8,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Display the Sequential Model Instance \n",
    "# for Model A23\n",
    "nn_A23 = Sequential() \n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_A23.add(Dense(units=hidden_nodes_layer1_A23, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the second hidden layer\n",
    "nn_A23.add(Dense(units=hidden_nodes_layer2_A23, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the third hidden layer\n",
    "nn_A23.add(Dense(units=hidden_nodes_layer3_A23, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fourth hidden layer\n",
    "nn_A23.add(Dense(units=hidden_nodes_layer4_A23, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fifth hidden layer\n",
    "nn_A23.add(Dense(units=hidden_nodes_layer5_A23, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the sixth hidden layer\n",
    "nn_A23.add(Dense(units=hidden_nodes_layer6_A23, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_A23.add(Dense(units=number_output_neurons_A23, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_A23.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A23.compile(loss=\"mse\", optimizer=\"adagrad\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2498 - accuracy: 0.5198 - val_loss: 0.2494 - val_accuracy: 0.5347\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2491 - accuracy: 0.5430 - val_loss: 0.2492 - val_accuracy: 0.5347\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2490 - accuracy: 0.5302 - val_loss: 0.2491 - val_accuracy: 0.5347\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.5274 - val_loss: 0.2489 - val_accuracy: 0.5347\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.5386 - val_loss: 0.2488 - val_accuracy: 0.5347\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.5309 - val_loss: 0.2486 - val_accuracy: 0.5347\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5349 - val_loss: 0.2485 - val_accuracy: 0.5347\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5355 - val_loss: 0.2484 - val_accuracy: 0.5347\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5327 - val_loss: 0.2482 - val_accuracy: 0.5347\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2484 - accuracy: 0.5303 - val_loss: 0.2481 - val_accuracy: 0.5347\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2482 - accuracy: 0.5250 - val_loss: 0.2479 - val_accuracy: 0.5347\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2481 - accuracy: 0.5269 - val_loss: 0.2477 - val_accuracy: 0.5347\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2473 - accuracy: 0.5326 - val_loss: 0.2476 - val_accuracy: 0.5347\n",
      "Epoch 14/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.5289 - val_loss: 0.2474 - val_accuracy: 0.5347\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2474 - accuracy: 0.5225 - val_loss: 0.2472 - val_accuracy: 0.5347\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2472 - accuracy: 0.5320 - val_loss: 0.2471 - val_accuracy: 0.5347\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.5324 - val_loss: 0.2469 - val_accuracy: 0.5347\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5368 - val_loss: 0.2467 - val_accuracy: 0.5347\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2468 - accuracy: 0.5230 - val_loss: 0.2466 - val_accuracy: 0.5347\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2464 - accuracy: 0.5275 - val_loss: 0.2464 - val_accuracy: 0.5347\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.5352 - val_loss: 0.2463 - val_accuracy: 0.5347\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2461 - accuracy: 0.5357 - val_loss: 0.2461 - val_accuracy: 0.5347\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2457 - accuracy: 0.5333 - val_loss: 0.2459 - val_accuracy: 0.5347\n",
      "Epoch 24/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5353 - val_loss: 0.2457 - val_accuracy: 0.5347\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2456 - accuracy: 0.5280 - val_loss: 0.2453 - val_accuracy: 0.5347\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.5267 - val_loss: 0.2449 - val_accuracy: 0.5347\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2441 - accuracy: 0.5316 - val_loss: 0.2436 - val_accuracy: 0.5347\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2434 - accuracy: 0.5283 - val_loss: 0.2426 - val_accuracy: 0.5347\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.5387 - val_loss: 0.2417 - val_accuracy: 0.5347\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2409 - accuracy: 0.5386 - val_loss: 0.2407 - val_accuracy: 0.5347\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2416 - accuracy: 0.5232 - val_loss: 0.2397 - val_accuracy: 0.5347\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2401 - accuracy: 0.5206 - val_loss: 0.2386 - val_accuracy: 0.5347\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2396 - accuracy: 0.5246 - val_loss: 0.2376 - val_accuracy: 0.5347\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2373 - accuracy: 0.5345 - val_loss: 0.2366 - val_accuracy: 0.5347\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2361 - accuracy: 0.5356 - val_loss: 0.2356 - val_accuracy: 0.5347\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2348 - accuracy: 0.5408 - val_loss: 0.2346 - val_accuracy: 0.5347\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2345 - accuracy: 0.5282 - val_loss: 0.2337 - val_accuracy: 0.5347\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.5308 - val_loss: 0.2328 - val_accuracy: 0.5347\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2326 - accuracy: 0.5311 - val_loss: 0.2319 - val_accuracy: 0.5347\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2326 - accuracy: 0.5266 - val_loss: 0.2311 - val_accuracy: 0.5347\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2318 - accuracy: 0.5292 - val_loss: 0.2303 - val_accuracy: 0.5347\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2302 - accuracy: 0.5307 - val_loss: 0.2295 - val_accuracy: 0.5347\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2286 - accuracy: 0.5410 - val_loss: 0.2288 - val_accuracy: 0.5347\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2274 - accuracy: 0.5336 - val_loss: 0.2280 - val_accuracy: 0.5347\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2270 - accuracy: 0.5344 - val_loss: 0.2273 - val_accuracy: 0.5347\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2284 - accuracy: 0.5307 - val_loss: 0.2266 - val_accuracy: 0.5347\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2249 - accuracy: 0.5366 - val_loss: 0.2260 - val_accuracy: 0.5347\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2269 - accuracy: 0.5314 - val_loss: 0.2254 - val_accuracy: 0.5347\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2271 - accuracy: 0.5298 - val_loss: 0.2248 - val_accuracy: 0.5347\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.5374 - val_loss: 0.2243 - val_accuracy: 0.5347\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.5335 - val_loss: 0.2238 - val_accuracy: 0.5347\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2251 - accuracy: 0.5301 - val_loss: 0.2233 - val_accuracy: 0.5347\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.5293 - val_loss: 0.2228 - val_accuracy: 0.5347\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.5293 - val_loss: 0.2224 - val_accuracy: 0.5347\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2223 - accuracy: 0.5318 - val_loss: 0.2220 - val_accuracy: 0.5347\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2248 - accuracy: 0.5267 - val_loss: 0.2216 - val_accuracy: 0.5347\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2215 - accuracy: 0.5321 - val_loss: 0.2212 - val_accuracy: 0.5347\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.5277 - val_loss: 0.2209 - val_accuracy: 0.5347\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.5312 - val_loss: 0.2206 - val_accuracy: 0.5347\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.5754 - val_loss: 0.2202 - val_accuracy: 0.6917\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.6897 - val_loss: 0.2200 - val_accuracy: 0.6916\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.6989 - val_loss: 0.2197 - val_accuracy: 0.6936\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2207 - accuracy: 0.6913 - val_loss: 0.2194 - val_accuracy: 0.6958\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2198 - accuracy: 0.6955 - val_loss: 0.2192 - val_accuracy: 0.7031\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2200 - accuracy: 0.7096 - val_loss: 0.2189 - val_accuracy: 0.7055\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2188 - accuracy: 0.7106 - val_loss: 0.2187 - val_accuracy: 0.7071\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2187 - accuracy: 0.7107 - val_loss: 0.2184 - val_accuracy: 0.7071\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.6977 - val_loss: 0.2182 - val_accuracy: 0.7071\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2209 - accuracy: 0.7045 - val_loss: 0.2180 - val_accuracy: 0.7075\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.7081 - val_loss: 0.2178 - val_accuracy: 0.7098\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7170 - val_loss: 0.2176 - val_accuracy: 0.7103\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2213 - accuracy: 0.6997 - val_loss: 0.2174 - val_accuracy: 0.7103\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2178 - accuracy: 0.7100 - val_loss: 0.2172 - val_accuracy: 0.7107\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2179 - accuracy: 0.7083 - val_loss: 0.2170 - val_accuracy: 0.7140\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2190 - accuracy: 0.7102 - val_loss: 0.2168 - val_accuracy: 0.7147\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2164 - accuracy: 0.7206 - val_loss: 0.2166 - val_accuracy: 0.7147\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2159 - accuracy: 0.7170 - val_loss: 0.2165 - val_accuracy: 0.7173\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2199 - accuracy: 0.7076 - val_loss: 0.2163 - val_accuracy: 0.7173\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2182 - accuracy: 0.7182 - val_loss: 0.2161 - val_accuracy: 0.7225\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2184 - accuracy: 0.7171 - val_loss: 0.2160 - val_accuracy: 0.7223\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2183 - accuracy: 0.7149 - val_loss: 0.2158 - val_accuracy: 0.7224\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.7314 - val_loss: 0.2156 - val_accuracy: 0.7226\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2147 - accuracy: 0.7217 - val_loss: 0.2155 - val_accuracy: 0.7229\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.7196 - val_loss: 0.2154 - val_accuracy: 0.7229\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2128 - accuracy: 0.7300 - val_loss: 0.2152 - val_accuracy: 0.7228\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.7257 - val_loss: 0.2151 - val_accuracy: 0.7234\n",
      "Epoch 87/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.7187 - val_loss: 0.2149 - val_accuracy: 0.7233\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2161 - accuracy: 0.7167 - val_loss: 0.2148 - val_accuracy: 0.7234\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2141 - accuracy: 0.7287 - val_loss: 0.2147 - val_accuracy: 0.7234\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.7181 - val_loss: 0.2146 - val_accuracy: 0.7234\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2163 - accuracy: 0.7179 - val_loss: 0.2144 - val_accuracy: 0.7236\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.7302 - val_loss: 0.2143 - val_accuracy: 0.7240\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2137 - accuracy: 0.7279 - val_loss: 0.2142 - val_accuracy: 0.7242\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.7231 - val_loss: 0.2141 - val_accuracy: 0.7244\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.7263 - val_loss: 0.2140 - val_accuracy: 0.7261\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.7243 - val_loss: 0.2139 - val_accuracy: 0.7261\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2144 - accuracy: 0.7257 - val_loss: 0.2137 - val_accuracy: 0.7264\n",
      "Epoch 98/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.7325 - val_loss: 0.2136 - val_accuracy: 0.7270\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2150 - accuracy: 0.7247 - val_loss: 0.2135 - val_accuracy: 0.7267\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.7263 - val_loss: 0.2134 - val_accuracy: 0.7274\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2141 - accuracy: 0.7282 - val_loss: 0.2133 - val_accuracy: 0.7274\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.7262 - val_loss: 0.2132 - val_accuracy: 0.7276\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2145 - accuracy: 0.7245 - val_loss: 0.2131 - val_accuracy: 0.7276\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2133 - accuracy: 0.7280 - val_loss: 0.2130 - val_accuracy: 0.7276\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.7254 - val_loss: 0.2130 - val_accuracy: 0.7278\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.7239 - val_loss: 0.2129 - val_accuracy: 0.7277\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2153 - accuracy: 0.7192 - val_loss: 0.2128 - val_accuracy: 0.7274\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2158 - accuracy: 0.7195 - val_loss: 0.2127 - val_accuracy: 0.7276\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2123 - accuracy: 0.7277 - val_loss: 0.2126 - val_accuracy: 0.7275\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.7259 - val_loss: 0.2125 - val_accuracy: 0.7275\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2110 - accuracy: 0.7334 - val_loss: 0.2124 - val_accuracy: 0.7276\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.7327 - val_loss: 0.2123 - val_accuracy: 0.7276\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.7215 - val_loss: 0.2122 - val_accuracy: 0.7276\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2136 - accuracy: 0.7299 - val_loss: 0.2122 - val_accuracy: 0.7274\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.7282 - val_loss: 0.2121 - val_accuracy: 0.7275\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.7339 - val_loss: 0.2120 - val_accuracy: 0.7276\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.7248 - val_loss: 0.2119 - val_accuracy: 0.7276\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2120 - accuracy: 0.7228 - val_loss: 0.2118 - val_accuracy: 0.7282\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2107 - accuracy: 0.7329 - val_loss: 0.2117 - val_accuracy: 0.7280\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.7344 - val_loss: 0.2117 - val_accuracy: 0.7279\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2130 - accuracy: 0.7286 - val_loss: 0.2116 - val_accuracy: 0.7280\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2112 - accuracy: 0.7284 - val_loss: 0.2115 - val_accuracy: 0.7278\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.7269 - val_loss: 0.2114 - val_accuracy: 0.7279\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.7273 - val_loss: 0.2113 - val_accuracy: 0.7278\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.7282 - val_loss: 0.2113 - val_accuracy: 0.7279\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2116 - accuracy: 0.7297 - val_loss: 0.2112 - val_accuracy: 0.7278\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2122 - accuracy: 0.7247 - val_loss: 0.2111 - val_accuracy: 0.7279\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2085 - accuracy: 0.7361 - val_loss: 0.2110 - val_accuracy: 0.7281\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2099 - accuracy: 0.7296 - val_loss: 0.2110 - val_accuracy: 0.7278\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.7310 - val_loss: 0.2109 - val_accuracy: 0.7278\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2135 - accuracy: 0.7193 - val_loss: 0.2108 - val_accuracy: 0.7282\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.7269 - val_loss: 0.2107 - val_accuracy: 0.7282\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.7363 - val_loss: 0.2107 - val_accuracy: 0.7293\n",
      "Epoch 134/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2109 - accuracy: 0.7294 - val_loss: 0.2106 - val_accuracy: 0.7292\n",
      "Epoch 135/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.7353 - val_loss: 0.2105 - val_accuracy: 0.7285\n",
      "Epoch 136/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.7345 - val_loss: 0.2105 - val_accuracy: 0.7285\n",
      "Epoch 137/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.7328 - val_loss: 0.2104 - val_accuracy: 0.7280\n",
      "Epoch 138/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2117 - accuracy: 0.7200 - val_loss: 0.2103 - val_accuracy: 0.7278\n",
      "Epoch 139/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.7295 - val_loss: 0.2103 - val_accuracy: 0.7281\n",
      "Epoch 140/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2114 - accuracy: 0.7263 - val_loss: 0.2102 - val_accuracy: 0.7281\n",
      "Epoch 141/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2122 - accuracy: 0.7222 - val_loss: 0.2101 - val_accuracy: 0.7282\n",
      "Epoch 142/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.7361 - val_loss: 0.2101 - val_accuracy: 0.7284\n",
      "Epoch 143/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2108 - accuracy: 0.7234 - val_loss: 0.2100 - val_accuracy: 0.7284\n",
      "Epoch 144/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.7350 - val_loss: 0.2099 - val_accuracy: 0.7283\n",
      "Epoch 145/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2094 - accuracy: 0.7342 - val_loss: 0.2099 - val_accuracy: 0.7284\n",
      "Epoch 146/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2115 - accuracy: 0.7242 - val_loss: 0.2098 - val_accuracy: 0.7284\n",
      "Epoch 147/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.7291 - val_loss: 0.2097 - val_accuracy: 0.7283\n",
      "Epoch 148/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2086 - accuracy: 0.7285 - val_loss: 0.2097 - val_accuracy: 0.7283\n",
      "Epoch 149/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2080 - accuracy: 0.7373 - val_loss: 0.2096 - val_accuracy: 0.7283\n",
      "Epoch 150/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2083 - accuracy: 0.7330 - val_loss: 0.2095 - val_accuracy: 0.7289\n",
      "Epoch 151/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2124 - accuracy: 0.7279 - val_loss: 0.2095 - val_accuracy: 0.7283\n",
      "Epoch 152/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2106 - accuracy: 0.7327 - val_loss: 0.2094 - val_accuracy: 0.7289\n",
      "Epoch 153/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.7320 - val_loss: 0.2094 - val_accuracy: 0.7289\n",
      "Epoch 154/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.7432 - val_loss: 0.2093 - val_accuracy: 0.7289\n",
      "Epoch 155/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2098 - accuracy: 0.7267 - val_loss: 0.2093 - val_accuracy: 0.7287\n",
      "Epoch 156/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.7340 - val_loss: 0.2092 - val_accuracy: 0.7287\n",
      "Epoch 157/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.7309 - val_loss: 0.2091 - val_accuracy: 0.7287\n",
      "Epoch 158/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.7321 - val_loss: 0.2091 - val_accuracy: 0.7287\n",
      "Epoch 159/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.7377 - val_loss: 0.2090 - val_accuracy: 0.7287\n",
      "Epoch 160/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.7381 - val_loss: 0.2090 - val_accuracy: 0.7287\n",
      "Epoch 161/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2095 - accuracy: 0.7359 - val_loss: 0.2089 - val_accuracy: 0.7287\n",
      "Epoch 162/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.7327 - val_loss: 0.2088 - val_accuracy: 0.7287\n",
      "Epoch 163/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.7396 - val_loss: 0.2088 - val_accuracy: 0.7289\n",
      "Epoch 164/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2084 - accuracy: 0.7259 - val_loss: 0.2087 - val_accuracy: 0.7288\n",
      "Epoch 165/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2100 - accuracy: 0.7286 - val_loss: 0.2087 - val_accuracy: 0.7288\n",
      "Epoch 166/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.7282 - val_loss: 0.2086 - val_accuracy: 0.7289\n",
      "Epoch 167/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2105 - accuracy: 0.7181 - val_loss: 0.2086 - val_accuracy: 0.7289\n",
      "Epoch 168/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2101 - accuracy: 0.7270 - val_loss: 0.2085 - val_accuracy: 0.7290\n",
      "Epoch 169/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.7342 - val_loss: 0.2085 - val_accuracy: 0.7290\n",
      "Epoch 170/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.7278 - val_loss: 0.2084 - val_accuracy: 0.7291\n",
      "Epoch 171/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.7410 - val_loss: 0.2084 - val_accuracy: 0.7291\n",
      "Epoch 172/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.7324 - val_loss: 0.2083 - val_accuracy: 0.7291\n",
      "Epoch 173/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2075 - accuracy: 0.7293 - val_loss: 0.2083 - val_accuracy: 0.7291\n",
      "Epoch 174/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.7292 - val_loss: 0.2082 - val_accuracy: 0.7290\n",
      "Epoch 175/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2065 - accuracy: 0.7321 - val_loss: 0.2082 - val_accuracy: 0.7290\n",
      "Epoch 176/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.7332 - val_loss: 0.2081 - val_accuracy: 0.7290\n",
      "Epoch 177/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2068 - accuracy: 0.7373 - val_loss: 0.2081 - val_accuracy: 0.7288\n",
      "Epoch 178/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.7384 - val_loss: 0.2080 - val_accuracy: 0.7289\n",
      "Epoch 179/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2072 - accuracy: 0.7318 - val_loss: 0.2080 - val_accuracy: 0.7288\n",
      "Epoch 180/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2069 - accuracy: 0.7351 - val_loss: 0.2079 - val_accuracy: 0.7288\n",
      "Epoch 181/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2079 - accuracy: 0.7334 - val_loss: 0.2079 - val_accuracy: 0.7288\n",
      "Epoch 182/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.7357 - val_loss: 0.2078 - val_accuracy: 0.7283\n",
      "Epoch 183/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2096 - accuracy: 0.7308 - val_loss: 0.2078 - val_accuracy: 0.7283\n",
      "Epoch 184/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.7305 - val_loss: 0.2077 - val_accuracy: 0.7283\n",
      "Epoch 185/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2092 - accuracy: 0.7252 - val_loss: 0.2077 - val_accuracy: 0.7285\n",
      "Epoch 186/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.7294 - val_loss: 0.2076 - val_accuracy: 0.7286\n",
      "Epoch 187/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.7429 - val_loss: 0.2076 - val_accuracy: 0.7286\n",
      "Epoch 188/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2088 - accuracy: 0.7301 - val_loss: 0.2075 - val_accuracy: 0.7286\n",
      "Epoch 189/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2073 - accuracy: 0.7305 - val_loss: 0.2075 - val_accuracy: 0.7283\n",
      "Epoch 190/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2078 - accuracy: 0.7321 - val_loss: 0.2075 - val_accuracy: 0.7283\n",
      "Epoch 191/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.7380 - val_loss: 0.2074 - val_accuracy: 0.7283\n",
      "Epoch 192/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.7355 - val_loss: 0.2074 - val_accuracy: 0.7285\n",
      "Epoch 193/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.7380 - val_loss: 0.2073 - val_accuracy: 0.7283\n",
      "Epoch 194/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2058 - accuracy: 0.7299 - val_loss: 0.2073 - val_accuracy: 0.7284\n",
      "Epoch 195/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2082 - accuracy: 0.7311 - val_loss: 0.2072 - val_accuracy: 0.7282\n",
      "Epoch 196/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.7388 - val_loss: 0.2072 - val_accuracy: 0.7283\n",
      "Epoch 197/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2075 - accuracy: 0.7344 - val_loss: 0.2072 - val_accuracy: 0.7282\n",
      "Epoch 198/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.7324 - val_loss: 0.2071 - val_accuracy: 0.7283\n",
      "Epoch 199/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2070 - accuracy: 0.7265 - val_loss: 0.2071 - val_accuracy: 0.7283\n",
      "Epoch 200/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.7363 - val_loss: 0.2070 - val_accuracy: 0.7283\n",
      "Epoch 201/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.7334 - val_loss: 0.2070 - val_accuracy: 0.7283\n",
      "Epoch 202/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2091 - accuracy: 0.7289 - val_loss: 0.2070 - val_accuracy: 0.7282\n",
      "Epoch 203/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2085 - accuracy: 0.7286 - val_loss: 0.2069 - val_accuracy: 0.7282\n",
      "Epoch 204/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.7338 - val_loss: 0.2069 - val_accuracy: 0.7283\n",
      "Epoch 205/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2062 - accuracy: 0.7366 - val_loss: 0.2068 - val_accuracy: 0.7283\n",
      "Epoch 206/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.7335 - val_loss: 0.2068 - val_accuracy: 0.7283\n",
      "Epoch 207/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.7400 - val_loss: 0.2068 - val_accuracy: 0.7283\n",
      "Epoch 208/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.7314 - val_loss: 0.2067 - val_accuracy: 0.7283\n",
      "Epoch 209/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.7344 - val_loss: 0.2067 - val_accuracy: 0.7283\n",
      "Epoch 210/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2067 - accuracy: 0.7306 - val_loss: 0.2066 - val_accuracy: 0.7283\n",
      "Epoch 211/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2055 - accuracy: 0.7300 - val_loss: 0.2066 - val_accuracy: 0.7283\n",
      "Epoch 212/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2055 - accuracy: 0.7244 - val_loss: 0.2066 - val_accuracy: 0.7283\n",
      "Epoch 213/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.7339 - val_loss: 0.2065 - val_accuracy: 0.7283\n",
      "Epoch 214/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2031 - accuracy: 0.7385 - val_loss: 0.2065 - val_accuracy: 0.7282\n",
      "Epoch 215/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.7362 - val_loss: 0.2065 - val_accuracy: 0.7282\n",
      "Epoch 216/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2074 - accuracy: 0.7255 - val_loss: 0.2064 - val_accuracy: 0.7282\n",
      "Epoch 217/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2064 - accuracy: 0.7278 - val_loss: 0.2064 - val_accuracy: 0.7282\n",
      "Epoch 218/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.7340 - val_loss: 0.2063 - val_accuracy: 0.7282\n",
      "Epoch 219/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2066 - accuracy: 0.7296 - val_loss: 0.2063 - val_accuracy: 0.7280\n",
      "Epoch 220/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2039 - accuracy: 0.7360 - val_loss: 0.2063 - val_accuracy: 0.7280\n",
      "Epoch 221/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2063 - accuracy: 0.7307 - val_loss: 0.2062 - val_accuracy: 0.7280\n",
      "Epoch 222/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2047 - accuracy: 0.7342 - val_loss: 0.2062 - val_accuracy: 0.7281\n",
      "Epoch 223/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2089 - accuracy: 0.7217 - val_loss: 0.2062 - val_accuracy: 0.7281\n",
      "Epoch 224/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2047 - accuracy: 0.7361 - val_loss: 0.2061 - val_accuracy: 0.7281\n",
      "Epoch 225/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.7344 - val_loss: 0.2061 - val_accuracy: 0.7281\n",
      "Epoch 226/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.7324 - val_loss: 0.2061 - val_accuracy: 0.7280\n",
      "Epoch 227/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.7303 - val_loss: 0.2060 - val_accuracy: 0.7280\n",
      "Epoch 228/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2057 - accuracy: 0.7339 - val_loss: 0.2060 - val_accuracy: 0.7280\n",
      "Epoch 229/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.7365 - val_loss: 0.2060 - val_accuracy: 0.7281\n",
      "Epoch 230/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.7383 - val_loss: 0.2059 - val_accuracy: 0.7281\n",
      "Epoch 231/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2071 - accuracy: 0.7252 - val_loss: 0.2059 - val_accuracy: 0.7281\n",
      "Epoch 232/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.7338 - val_loss: 0.2059 - val_accuracy: 0.7281\n",
      "Epoch 233/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.7361 - val_loss: 0.2058 - val_accuracy: 0.7281\n",
      "Epoch 234/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.7344 - val_loss: 0.2058 - val_accuracy: 0.7280\n",
      "Epoch 235/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2042 - accuracy: 0.7339 - val_loss: 0.2058 - val_accuracy: 0.7281\n",
      "Epoch 236/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.7313 - val_loss: 0.2057 - val_accuracy: 0.7281\n",
      "Epoch 237/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.7381 - val_loss: 0.2057 - val_accuracy: 0.7281\n",
      "Epoch 238/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2061 - accuracy: 0.7293 - val_loss: 0.2057 - val_accuracy: 0.7280\n",
      "Epoch 239/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.7422 - val_loss: 0.2056 - val_accuracy: 0.7280\n",
      "Epoch 240/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.7368 - val_loss: 0.2056 - val_accuracy: 0.7280\n",
      "Epoch 241/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.7356 - val_loss: 0.2056 - val_accuracy: 0.7280\n",
      "Epoch 242/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2045 - accuracy: 0.7298 - val_loss: 0.2055 - val_accuracy: 0.7280\n",
      "Epoch 243/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.7315 - val_loss: 0.2055 - val_accuracy: 0.7280\n",
      "Epoch 244/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2041 - accuracy: 0.7351 - val_loss: 0.2055 - val_accuracy: 0.7280\n",
      "Epoch 245/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2039 - accuracy: 0.7304 - val_loss: 0.2054 - val_accuracy: 0.7280\n",
      "Epoch 246/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.7340 - val_loss: 0.2054 - val_accuracy: 0.7280\n",
      "Epoch 247/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2027 - accuracy: 0.7374 - val_loss: 0.2054 - val_accuracy: 0.7280\n",
      "Epoch 248/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7405 - val_loss: 0.2053 - val_accuracy: 0.7280\n",
      "Epoch 249/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.7311 - val_loss: 0.2053 - val_accuracy: 0.7280\n",
      "Epoch 250/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.7345 - val_loss: 0.2053 - val_accuracy: 0.7280\n",
      "Epoch 251/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.7355 - val_loss: 0.2052 - val_accuracy: 0.7280\n",
      "Epoch 252/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2048 - accuracy: 0.7264 - val_loss: 0.2052 - val_accuracy: 0.7280\n",
      "Epoch 253/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.7282 - val_loss: 0.2052 - val_accuracy: 0.7280\n",
      "Epoch 254/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.7368 - val_loss: 0.2051 - val_accuracy: 0.7280\n",
      "Epoch 255/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.7327 - val_loss: 0.2051 - val_accuracy: 0.7280\n",
      "Epoch 256/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2032 - accuracy: 0.7348 - val_loss: 0.2051 - val_accuracy: 0.7280\n",
      "Epoch 257/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.7297 - val_loss: 0.2051 - val_accuracy: 0.7281\n",
      "Epoch 258/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.7317 - val_loss: 0.2050 - val_accuracy: 0.7280\n",
      "Epoch 259/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.7318 - val_loss: 0.2050 - val_accuracy: 0.7280\n",
      "Epoch 260/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.7330 - val_loss: 0.2050 - val_accuracy: 0.7280\n",
      "Epoch 261/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.7357 - val_loss: 0.2049 - val_accuracy: 0.7280\n",
      "Epoch 262/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2050 - accuracy: 0.7330 - val_loss: 0.2049 - val_accuracy: 0.7281\n",
      "Epoch 263/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.7323 - val_loss: 0.2049 - val_accuracy: 0.7284\n",
      "Epoch 264/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.7336 - val_loss: 0.2049 - val_accuracy: 0.7284\n",
      "Epoch 265/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.7409 - val_loss: 0.2048 - val_accuracy: 0.7284\n",
      "Epoch 266/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.7359 - val_loss: 0.2048 - val_accuracy: 0.7284\n",
      "Epoch 267/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.7358 - val_loss: 0.2048 - val_accuracy: 0.7284\n",
      "Epoch 268/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.7355 - val_loss: 0.2047 - val_accuracy: 0.7284\n",
      "Epoch 269/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.7419 - val_loss: 0.2047 - val_accuracy: 0.7284\n",
      "Epoch 270/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.7276 - val_loss: 0.2047 - val_accuracy: 0.7284\n",
      "Epoch 271/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.7409 - val_loss: 0.2047 - val_accuracy: 0.7284\n",
      "Epoch 272/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.7285 - val_loss: 0.2046 - val_accuracy: 0.7284\n",
      "Epoch 273/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.7392 - val_loss: 0.2046 - val_accuracy: 0.7284\n",
      "Epoch 274/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.7421 - val_loss: 0.2046 - val_accuracy: 0.7284\n",
      "Epoch 275/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.7299 - val_loss: 0.2045 - val_accuracy: 0.7284\n",
      "Epoch 276/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.7362 - val_loss: 0.2045 - val_accuracy: 0.7284\n",
      "Epoch 277/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.7412 - val_loss: 0.2045 - val_accuracy: 0.7284\n",
      "Epoch 278/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2056 - accuracy: 0.7306 - val_loss: 0.2045 - val_accuracy: 0.7284\n",
      "Epoch 279/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.7323 - val_loss: 0.2044 - val_accuracy: 0.7284\n",
      "Epoch 280/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2036 - accuracy: 0.7364 - val_loss: 0.2044 - val_accuracy: 0.7288\n",
      "Epoch 281/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.7309 - val_loss: 0.2044 - val_accuracy: 0.7288\n",
      "Epoch 282/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2054 - accuracy: 0.7268 - val_loss: 0.2043 - val_accuracy: 0.7288\n",
      "Epoch 283/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2041 - accuracy: 0.7308 - val_loss: 0.2043 - val_accuracy: 0.7288\n",
      "Epoch 284/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.7372 - val_loss: 0.2043 - val_accuracy: 0.7288\n",
      "Epoch 285/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.7363 - val_loss: 0.2043 - val_accuracy: 0.7288\n",
      "Epoch 286/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.7408 - val_loss: 0.2042 - val_accuracy: 0.7288\n",
      "Epoch 287/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7404 - val_loss: 0.2042 - val_accuracy: 0.7289\n",
      "Epoch 288/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.7374 - val_loss: 0.2042 - val_accuracy: 0.7288\n",
      "Epoch 289/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2022 - accuracy: 0.7343 - val_loss: 0.2042 - val_accuracy: 0.7288\n",
      "Epoch 290/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.7358 - val_loss: 0.2041 - val_accuracy: 0.7289\n",
      "Epoch 291/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7374 - val_loss: 0.2041 - val_accuracy: 0.7299\n",
      "Epoch 292/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.7354 - val_loss: 0.2041 - val_accuracy: 0.7299\n",
      "Epoch 293/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.7392 - val_loss: 0.2041 - val_accuracy: 0.7298\n",
      "Epoch 294/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.7329 - val_loss: 0.2040 - val_accuracy: 0.7299\n",
      "Epoch 295/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.7379 - val_loss: 0.2040 - val_accuracy: 0.7300\n",
      "Epoch 296/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.7327 - val_loss: 0.2040 - val_accuracy: 0.7300\n",
      "Epoch 297/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.7384 - val_loss: 0.2040 - val_accuracy: 0.7298\n",
      "Epoch 298/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7377 - val_loss: 0.2039 - val_accuracy: 0.7298\n",
      "Epoch 299/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2046 - accuracy: 0.7326 - val_loss: 0.2039 - val_accuracy: 0.7298\n",
      "Epoch 300/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.7295 - val_loss: 0.2039 - val_accuracy: 0.7300\n",
      "Epoch 301/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.7348 - val_loss: 0.2039 - val_accuracy: 0.7300\n",
      "Epoch 302/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.7368 - val_loss: 0.2038 - val_accuracy: 0.7302\n",
      "Epoch 303/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2033 - accuracy: 0.7314 - val_loss: 0.2038 - val_accuracy: 0.7301\n",
      "Epoch 304/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2024 - accuracy: 0.7362 - val_loss: 0.2038 - val_accuracy: 0.7301\n",
      "Epoch 305/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2023 - accuracy: 0.7301 - val_loss: 0.2038 - val_accuracy: 0.7301\n",
      "Epoch 306/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.7365 - val_loss: 0.2037 - val_accuracy: 0.7301\n",
      "Epoch 307/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2025 - accuracy: 0.7373 - val_loss: 0.2037 - val_accuracy: 0.7302\n",
      "Epoch 308/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.7338 - val_loss: 0.2037 - val_accuracy: 0.7302\n",
      "Epoch 309/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2043 - accuracy: 0.7274 - val_loss: 0.2037 - val_accuracy: 0.7302\n",
      "Epoch 310/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2028 - accuracy: 0.7356 - val_loss: 0.2036 - val_accuracy: 0.7302\n",
      "Epoch 311/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.7334 - val_loss: 0.2036 - val_accuracy: 0.7302\n",
      "Epoch 312/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7358 - val_loss: 0.2036 - val_accuracy: 0.7302\n",
      "Epoch 313/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2032 - accuracy: 0.7292 - val_loss: 0.2036 - val_accuracy: 0.7302\n",
      "Epoch 314/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7401 - val_loss: 0.2035 - val_accuracy: 0.7302\n",
      "Epoch 315/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.7300 - val_loss: 0.2035 - val_accuracy: 0.7302\n",
      "Epoch 316/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.7366 - val_loss: 0.2035 - val_accuracy: 0.7303\n",
      "Epoch 317/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.7385 - val_loss: 0.2035 - val_accuracy: 0.7300\n",
      "Epoch 318/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.7411 - val_loss: 0.2034 - val_accuracy: 0.7300\n",
      "Epoch 319/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.7411 - val_loss: 0.2034 - val_accuracy: 0.7300\n",
      "Epoch 320/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7349 - val_loss: 0.2034 - val_accuracy: 0.7300\n",
      "Epoch 321/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7337 - val_loss: 0.2034 - val_accuracy: 0.7300\n",
      "Epoch 322/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7356 - val_loss: 0.2034 - val_accuracy: 0.7300\n",
      "Epoch 323/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2034 - accuracy: 0.7330 - val_loss: 0.2033 - val_accuracy: 0.7301\n",
      "Epoch 324/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7395 - val_loss: 0.2033 - val_accuracy: 0.7300\n",
      "Epoch 325/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.7291 - val_loss: 0.2033 - val_accuracy: 0.7301\n",
      "Epoch 326/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.7386 - val_loss: 0.2033 - val_accuracy: 0.7301\n",
      "Epoch 327/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2002 - accuracy: 0.7359 - val_loss: 0.2032 - val_accuracy: 0.7301\n",
      "Epoch 328/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.7326 - val_loss: 0.2032 - val_accuracy: 0.7301\n",
      "Epoch 329/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.7365 - val_loss: 0.2032 - val_accuracy: 0.7301\n",
      "Epoch 330/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2029 - accuracy: 0.7265 - val_loss: 0.2032 - val_accuracy: 0.7301\n",
      "Epoch 331/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.7289 - val_loss: 0.2032 - val_accuracy: 0.7301\n",
      "Epoch 332/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.7389 - val_loss: 0.2031 - val_accuracy: 0.7301\n",
      "Epoch 333/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2015 - accuracy: 0.7330 - val_loss: 0.2031 - val_accuracy: 0.7301\n",
      "Epoch 334/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.7402 - val_loss: 0.2031 - val_accuracy: 0.7302\n",
      "Epoch 335/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7301 - val_loss: 0.2031 - val_accuracy: 0.7302\n",
      "Epoch 336/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.7351 - val_loss: 0.2030 - val_accuracy: 0.7302\n",
      "Epoch 337/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.7397 - val_loss: 0.2030 - val_accuracy: 0.7302\n",
      "Epoch 338/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.7357 - val_loss: 0.2030 - val_accuracy: 0.7302\n",
      "Epoch 339/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.7374 - val_loss: 0.2030 - val_accuracy: 0.7302\n",
      "Epoch 340/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.7342 - val_loss: 0.2030 - val_accuracy: 0.7302\n",
      "Epoch 341/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.7400 - val_loss: 0.2029 - val_accuracy: 0.7302\n",
      "Epoch 342/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.7325 - val_loss: 0.2029 - val_accuracy: 0.7302\n",
      "Epoch 343/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.7365 - val_loss: 0.2029 - val_accuracy: 0.7302\n",
      "Epoch 344/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2044 - accuracy: 0.7269 - val_loss: 0.2029 - val_accuracy: 0.7302\n",
      "Epoch 345/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.7383 - val_loss: 0.2029 - val_accuracy: 0.7302\n",
      "Epoch 346/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.7322 - val_loss: 0.2028 - val_accuracy: 0.7302\n",
      "Epoch 347/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2030 - accuracy: 0.7318 - val_loss: 0.2028 - val_accuracy: 0.7302\n",
      "Epoch 348/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.7322 - val_loss: 0.2028 - val_accuracy: 0.7302\n",
      "Epoch 349/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2021 - accuracy: 0.7340 - val_loss: 0.2028 - val_accuracy: 0.7302\n",
      "Epoch 350/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2008 - accuracy: 0.7338 - val_loss: 0.2027 - val_accuracy: 0.7302\n",
      "Epoch 351/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.7403 - val_loss: 0.2027 - val_accuracy: 0.7301\n",
      "Epoch 352/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2035 - accuracy: 0.7296 - val_loss: 0.2027 - val_accuracy: 0.7302\n",
      "Epoch 353/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.7355 - val_loss: 0.2027 - val_accuracy: 0.7302\n",
      "Epoch 354/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7454 - val_loss: 0.2027 - val_accuracy: 0.7300\n",
      "Epoch 355/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7385 - val_loss: 0.2026 - val_accuracy: 0.7301\n",
      "Epoch 356/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2019 - accuracy: 0.7332 - val_loss: 0.2026 - val_accuracy: 0.7302\n",
      "Epoch 357/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7376 - val_loss: 0.2026 - val_accuracy: 0.7298\n",
      "Epoch 358/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2003 - accuracy: 0.7383 - val_loss: 0.2026 - val_accuracy: 0.7298\n",
      "Epoch 359/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2024 - accuracy: 0.7315 - val_loss: 0.2026 - val_accuracy: 0.7298\n",
      "Epoch 360/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.7384 - val_loss: 0.2025 - val_accuracy: 0.7297\n",
      "Epoch 361/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7359 - val_loss: 0.2025 - val_accuracy: 0.7297\n",
      "Epoch 362/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7327 - val_loss: 0.2025 - val_accuracy: 0.7296\n",
      "Epoch 363/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.7350 - val_loss: 0.2025 - val_accuracy: 0.7297\n",
      "Epoch 364/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2026 - accuracy: 0.7329 - val_loss: 0.2025 - val_accuracy: 0.7297\n",
      "Epoch 365/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.7340 - val_loss: 0.2024 - val_accuracy: 0.7297\n",
      "Epoch 366/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.7313 - val_loss: 0.2024 - val_accuracy: 0.7297\n",
      "Epoch 367/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.7340 - val_loss: 0.2024 - val_accuracy: 0.7297\n",
      "Epoch 368/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7368 - val_loss: 0.2024 - val_accuracy: 0.7297\n",
      "Epoch 369/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2060 - accuracy: 0.7220 - val_loss: 0.2024 - val_accuracy: 0.7297\n",
      "Epoch 370/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7294 - val_loss: 0.2023 - val_accuracy: 0.7297\n",
      "Epoch 371/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7338 - val_loss: 0.2023 - val_accuracy: 0.7296\n",
      "Epoch 372/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7395 - val_loss: 0.2023 - val_accuracy: 0.7296\n",
      "Epoch 373/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.7385 - val_loss: 0.2023 - val_accuracy: 0.7296\n",
      "Epoch 374/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2010 - accuracy: 0.7340 - val_loss: 0.2023 - val_accuracy: 0.7296\n",
      "Epoch 375/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.7356 - val_loss: 0.2022 - val_accuracy: 0.7296\n",
      "Epoch 376/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2002 - accuracy: 0.7365 - val_loss: 0.2022 - val_accuracy: 0.7296\n",
      "Epoch 377/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.7386 - val_loss: 0.2022 - val_accuracy: 0.7296\n",
      "Epoch 378/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7364 - val_loss: 0.2022 - val_accuracy: 0.7296\n",
      "Epoch 379/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7329 - val_loss: 0.2022 - val_accuracy: 0.7296\n",
      "Epoch 380/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7368 - val_loss: 0.2021 - val_accuracy: 0.7296\n",
      "Epoch 381/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.7365 - val_loss: 0.2021 - val_accuracy: 0.7299\n",
      "Epoch 382/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7330 - val_loss: 0.2021 - val_accuracy: 0.7296\n",
      "Epoch 383/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.7330 - val_loss: 0.2021 - val_accuracy: 0.7299\n",
      "Epoch 384/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7413 - val_loss: 0.2021 - val_accuracy: 0.7298\n",
      "Epoch 385/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.7337 - val_loss: 0.2020 - val_accuracy: 0.7298\n",
      "Epoch 386/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.7406 - val_loss: 0.2020 - val_accuracy: 0.7298\n",
      "Epoch 387/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7351 - val_loss: 0.2020 - val_accuracy: 0.7298\n",
      "Epoch 388/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2018 - accuracy: 0.7324 - val_loss: 0.2020 - val_accuracy: 0.7298\n",
      "Epoch 389/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2018 - accuracy: 0.7347 - val_loss: 0.2020 - val_accuracy: 0.7298\n",
      "Epoch 390/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.7374 - val_loss: 0.2020 - val_accuracy: 0.7298\n",
      "Epoch 391/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.7340 - val_loss: 0.2019 - val_accuracy: 0.7298\n",
      "Epoch 392/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7427 - val_loss: 0.2019 - val_accuracy: 0.7298\n",
      "Epoch 393/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1997 - accuracy: 0.7388 - val_loss: 0.2019 - val_accuracy: 0.7298\n",
      "Epoch 394/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.7366 - val_loss: 0.2019 - val_accuracy: 0.7298\n",
      "Epoch 395/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2000 - accuracy: 0.7308 - val_loss: 0.2019 - val_accuracy: 0.7298\n",
      "Epoch 396/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2007 - accuracy: 0.7307 - val_loss: 0.2018 - val_accuracy: 0.7298\n",
      "Epoch 397/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2013 - accuracy: 0.7335 - val_loss: 0.2018 - val_accuracy: 0.7298\n",
      "Epoch 398/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.7405 - val_loss: 0.2018 - val_accuracy: 0.7298\n",
      "Epoch 399/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.7304 - val_loss: 0.2018 - val_accuracy: 0.7298\n",
      "Epoch 400/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7328 - val_loss: 0.2018 - val_accuracy: 0.7298\n",
      "Epoch 401/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.7414 - val_loss: 0.2018 - val_accuracy: 0.7298\n",
      "Epoch 402/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.7380 - val_loss: 0.2017 - val_accuracy: 0.7303\n",
      "Epoch 403/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7357 - val_loss: 0.2017 - val_accuracy: 0.7298\n",
      "Epoch 404/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.7359 - val_loss: 0.2017 - val_accuracy: 0.7298\n",
      "Epoch 405/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1973 - accuracy: 0.7434 - val_loss: 0.2017 - val_accuracy: 0.7303\n",
      "Epoch 406/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.7327 - val_loss: 0.2017 - val_accuracy: 0.7298\n",
      "Epoch 407/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.7398 - val_loss: 0.2016 - val_accuracy: 0.7298\n",
      "Epoch 408/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.7354 - val_loss: 0.2016 - val_accuracy: 0.7298\n",
      "Epoch 409/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7444 - val_loss: 0.2016 - val_accuracy: 0.7302\n",
      "Epoch 410/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.7344 - val_loss: 0.2016 - val_accuracy: 0.7296\n",
      "Epoch 411/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.7334 - val_loss: 0.2016 - val_accuracy: 0.7301\n",
      "Epoch 412/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.7360 - val_loss: 0.2016 - val_accuracy: 0.7296\n",
      "Epoch 413/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.7303 - val_loss: 0.2015 - val_accuracy: 0.7296\n",
      "Epoch 414/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7404 - val_loss: 0.2015 - val_accuracy: 0.7296\n",
      "Epoch 415/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7389 - val_loss: 0.2015 - val_accuracy: 0.7296\n",
      "Epoch 416/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.7361 - val_loss: 0.2015 - val_accuracy: 0.7304\n",
      "Epoch 417/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.7326 - val_loss: 0.2015 - val_accuracy: 0.7299\n",
      "Epoch 418/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.7405 - val_loss: 0.2014 - val_accuracy: 0.7299\n",
      "Epoch 419/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.7413 - val_loss: 0.2014 - val_accuracy: 0.7304\n",
      "Epoch 420/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.7365 - val_loss: 0.2014 - val_accuracy: 0.7299\n",
      "Epoch 421/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7352 - val_loss: 0.2014 - val_accuracy: 0.7299\n",
      "Epoch 422/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7394 - val_loss: 0.2014 - val_accuracy: 0.7299\n",
      "Epoch 423/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.7391 - val_loss: 0.2014 - val_accuracy: 0.7299\n",
      "Epoch 424/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7429 - val_loss: 0.2013 - val_accuracy: 0.7304\n",
      "Epoch 425/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.7355 - val_loss: 0.2013 - val_accuracy: 0.7299\n",
      "Epoch 426/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.7433 - val_loss: 0.2013 - val_accuracy: 0.7304\n",
      "Epoch 427/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2011 - accuracy: 0.7294 - val_loss: 0.2013 - val_accuracy: 0.7299\n",
      "Epoch 428/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7353 - val_loss: 0.2013 - val_accuracy: 0.7299\n",
      "Epoch 429/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2017 - accuracy: 0.7320 - val_loss: 0.2013 - val_accuracy: 0.7299\n",
      "Epoch 430/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.7412 - val_loss: 0.2012 - val_accuracy: 0.7299\n",
      "Epoch 431/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7362 - val_loss: 0.2012 - val_accuracy: 0.7304\n",
      "Epoch 432/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7349 - val_loss: 0.2012 - val_accuracy: 0.7299\n",
      "Epoch 433/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.7348 - val_loss: 0.2012 - val_accuracy: 0.7299\n",
      "Epoch 434/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.7344 - val_loss: 0.2012 - val_accuracy: 0.7299\n",
      "Epoch 435/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2006 - accuracy: 0.7316 - val_loss: 0.2012 - val_accuracy: 0.7298\n",
      "Epoch 436/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7356 - val_loss: 0.2011 - val_accuracy: 0.7298\n",
      "Epoch 437/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.7341 - val_loss: 0.2011 - val_accuracy: 0.7298\n",
      "Epoch 438/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.7353 - val_loss: 0.2011 - val_accuracy: 0.7298\n",
      "Epoch 439/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.7385 - val_loss: 0.2011 - val_accuracy: 0.7298\n",
      "Epoch 440/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.7382 - val_loss: 0.2011 - val_accuracy: 0.7298\n",
      "Epoch 441/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1995 - accuracy: 0.7348 - val_loss: 0.2011 - val_accuracy: 0.7298\n",
      "Epoch 442/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7386 - val_loss: 0.2010 - val_accuracy: 0.7296\n",
      "Epoch 443/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.7417 - val_loss: 0.2010 - val_accuracy: 0.7305\n",
      "Epoch 444/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1983 - accuracy: 0.7418 - val_loss: 0.2010 - val_accuracy: 0.7298\n",
      "Epoch 445/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.7377 - val_loss: 0.2010 - val_accuracy: 0.7298\n",
      "Epoch 446/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.7396 - val_loss: 0.2010 - val_accuracy: 0.7296\n",
      "Epoch 447/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1986 - accuracy: 0.7353 - val_loss: 0.2010 - val_accuracy: 0.7296\n",
      "Epoch 448/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.7364 - val_loss: 0.2009 - val_accuracy: 0.7297\n",
      "Epoch 449/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7281 - val_loss: 0.2009 - val_accuracy: 0.7297\n",
      "Epoch 450/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2009 - accuracy: 0.7315 - val_loss: 0.2009 - val_accuracy: 0.7302\n",
      "Epoch 451/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7461 - val_loss: 0.2009 - val_accuracy: 0.7301\n",
      "Epoch 452/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7389 - val_loss: 0.2009 - val_accuracy: 0.7301\n",
      "Epoch 453/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1990 - accuracy: 0.7365 - val_loss: 0.2009 - val_accuracy: 0.7301\n",
      "Epoch 454/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7329 - val_loss: 0.2009 - val_accuracy: 0.7301\n",
      "Epoch 455/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.7399 - val_loss: 0.2008 - val_accuracy: 0.7301\n",
      "Epoch 456/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7345 - val_loss: 0.2008 - val_accuracy: 0.7296\n",
      "Epoch 457/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.7321 - val_loss: 0.2008 - val_accuracy: 0.7296\n",
      "Epoch 458/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7492 - val_loss: 0.2008 - val_accuracy: 0.7301\n",
      "Epoch 459/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.7384 - val_loss: 0.2008 - val_accuracy: 0.7296\n",
      "Epoch 460/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7299 - val_loss: 0.2008 - val_accuracy: 0.7301\n",
      "Epoch 461/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7362 - val_loss: 0.2007 - val_accuracy: 0.7296\n",
      "Epoch 462/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.7387 - val_loss: 0.2007 - val_accuracy: 0.7301\n",
      "Epoch 463/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.7357 - val_loss: 0.2007 - val_accuracy: 0.7296\n",
      "Epoch 464/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7358 - val_loss: 0.2007 - val_accuracy: 0.7296\n",
      "Epoch 465/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7481 - val_loss: 0.2007 - val_accuracy: 0.7301\n",
      "Epoch 466/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1968 - accuracy: 0.7374 - val_loss: 0.2007 - val_accuracy: 0.7301\n",
      "Epoch 467/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7331 - val_loss: 0.2007 - val_accuracy: 0.7296\n",
      "Epoch 468/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7387 - val_loss: 0.2006 - val_accuracy: 0.7296\n",
      "Epoch 469/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7318 - val_loss: 0.2006 - val_accuracy: 0.7296\n",
      "Epoch 470/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7354 - val_loss: 0.2006 - val_accuracy: 0.7296\n",
      "Epoch 471/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7371 - val_loss: 0.2006 - val_accuracy: 0.7296\n",
      "Epoch 472/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.7418 - val_loss: 0.2006 - val_accuracy: 0.7296\n",
      "Epoch 473/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1962 - accuracy: 0.7409 - val_loss: 0.2006 - val_accuracy: 0.7297\n",
      "Epoch 474/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.7352 - val_loss: 0.2005 - val_accuracy: 0.7302\n",
      "Epoch 475/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.7371 - val_loss: 0.2005 - val_accuracy: 0.7302\n",
      "Epoch 476/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7407 - val_loss: 0.2005 - val_accuracy: 0.7297\n",
      "Epoch 477/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1990 - accuracy: 0.7370 - val_loss: 0.2005 - val_accuracy: 0.7297\n",
      "Epoch 478/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7380 - val_loss: 0.2005 - val_accuracy: 0.7302\n",
      "Epoch 479/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7391 - val_loss: 0.2005 - val_accuracy: 0.7297\n",
      "Epoch 480/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7405 - val_loss: 0.2005 - val_accuracy: 0.7297\n",
      "Epoch 481/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7369 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 482/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7387 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 483/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.7358 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 484/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.7315 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 485/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7441 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 486/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.7383 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 487/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7372 - val_loss: 0.2004 - val_accuracy: 0.7297\n",
      "Epoch 488/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.7402 - val_loss: 0.2003 - val_accuracy: 0.7297\n",
      "Epoch 489/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7372 - val_loss: 0.2003 - val_accuracy: 0.7297\n",
      "Epoch 490/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.7367 - val_loss: 0.2003 - val_accuracy: 0.7297\n",
      "Epoch 491/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7431 - val_loss: 0.2003 - val_accuracy: 0.7297\n",
      "Epoch 492/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.7330 - val_loss: 0.2003 - val_accuracy: 0.7297\n",
      "Epoch 493/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.7404 - val_loss: 0.2003 - val_accuracy: 0.7295\n",
      "Epoch 494/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1994 - accuracy: 0.7314 - val_loss: 0.2003 - val_accuracy: 0.7295\n",
      "Epoch 495/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1971 - accuracy: 0.7347 - val_loss: 0.2003 - val_accuracy: 0.7295\n",
      "Epoch 496/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.7433 - val_loss: 0.2002 - val_accuracy: 0.7295\n",
      "Epoch 497/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7479 - val_loss: 0.2002 - val_accuracy: 0.7295\n",
      "Epoch 498/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7403 - val_loss: 0.2002 - val_accuracy: 0.7295\n",
      "Epoch 499/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7368 - val_loss: 0.2002 - val_accuracy: 0.7300\n",
      "Epoch 500/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7374 - val_loss: 0.2002 - val_accuracy: 0.7295\n",
      "Epoch 501/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7357 - val_loss: 0.2002 - val_accuracy: 0.7295\n",
      "Epoch 502/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7382 - val_loss: 0.2002 - val_accuracy: 0.7300\n",
      "Epoch 503/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7411 - val_loss: 0.2001 - val_accuracy: 0.7295\n",
      "Epoch 504/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7321 - val_loss: 0.2001 - val_accuracy: 0.7295\n",
      "Epoch 505/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1998 - accuracy: 0.7263 - val_loss: 0.2001 - val_accuracy: 0.7300\n",
      "Epoch 506/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.7422 - val_loss: 0.2001 - val_accuracy: 0.7295\n",
      "Epoch 507/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.7345 - val_loss: 0.2001 - val_accuracy: 0.7295\n",
      "Epoch 508/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.7392 - val_loss: 0.2001 - val_accuracy: 0.7300\n",
      "Epoch 509/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7495 - val_loss: 0.2001 - val_accuracy: 0.7295\n",
      "Epoch 510/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7441 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 511/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7397 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 512/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7322 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 513/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7401 - val_loss: 0.2000 - val_accuracy: 0.7300\n",
      "Epoch 514/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7363 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 515/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.7392 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 516/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.7336 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 517/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7379 - val_loss: 0.2000 - val_accuracy: 0.7295\n",
      "Epoch 518/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.7340 - val_loss: 0.1999 - val_accuracy: 0.7300\n",
      "Epoch 519/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7361 - val_loss: 0.1999 - val_accuracy: 0.7295\n",
      "Epoch 520/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7314 - val_loss: 0.1999 - val_accuracy: 0.7295\n",
      "Epoch 521/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7368 - val_loss: 0.1999 - val_accuracy: 0.7295\n",
      "Epoch 522/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7300 - val_loss: 0.1999 - val_accuracy: 0.7295\n",
      "Epoch 523/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1987 - accuracy: 0.7326 - val_loss: 0.1999 - val_accuracy: 0.7295\n",
      "Epoch 524/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7458 - val_loss: 0.1999 - val_accuracy: 0.7295\n",
      "Epoch 525/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7323 - val_loss: 0.1998 - val_accuracy: 0.7294\n",
      "Epoch 526/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.7373 - val_loss: 0.1998 - val_accuracy: 0.7295\n",
      "Epoch 527/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7431 - val_loss: 0.1998 - val_accuracy: 0.7294\n",
      "Epoch 528/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1988 - accuracy: 0.7314 - val_loss: 0.1998 - val_accuracy: 0.7295\n",
      "Epoch 529/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7360 - val_loss: 0.1998 - val_accuracy: 0.7299\n",
      "Epoch 530/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7402 - val_loss: 0.1998 - val_accuracy: 0.7294\n",
      "Epoch 531/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7382 - val_loss: 0.1998 - val_accuracy: 0.7294\n",
      "Epoch 532/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7413 - val_loss: 0.1998 - val_accuracy: 0.7299\n",
      "Epoch 533/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7403 - val_loss: 0.1998 - val_accuracy: 0.7299\n",
      "Epoch 534/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.7390 - val_loss: 0.1997 - val_accuracy: 0.7299\n",
      "Epoch 535/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2001 - accuracy: 0.7286 - val_loss: 0.1997 - val_accuracy: 0.7294\n",
      "Epoch 536/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.7311 - val_loss: 0.1997 - val_accuracy: 0.7294\n",
      "Epoch 537/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7316 - val_loss: 0.1997 - val_accuracy: 0.7295\n",
      "Epoch 538/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7361 - val_loss: 0.1997 - val_accuracy: 0.7300\n",
      "Epoch 539/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1976 - accuracy: 0.7345 - val_loss: 0.1997 - val_accuracy: 0.7294\n",
      "Epoch 540/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7416 - val_loss: 0.1997 - val_accuracy: 0.7300\n",
      "Epoch 541/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7383 - val_loss: 0.1997 - val_accuracy: 0.7298\n",
      "Epoch 542/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.7333 - val_loss: 0.1996 - val_accuracy: 0.7298\n",
      "Epoch 543/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.7357 - val_loss: 0.1996 - val_accuracy: 0.7300\n",
      "Epoch 544/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1991 - accuracy: 0.7340 - val_loss: 0.1996 - val_accuracy: 0.7300\n",
      "Epoch 545/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7352 - val_loss: 0.1996 - val_accuracy: 0.7294\n",
      "Epoch 546/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7340 - val_loss: 0.1996 - val_accuracy: 0.7294\n",
      "Epoch 547/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7367 - val_loss: 0.1996 - val_accuracy: 0.7294\n",
      "Epoch 548/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.7324 - val_loss: 0.1996 - val_accuracy: 0.7294\n",
      "Epoch 549/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7423 - val_loss: 0.1996 - val_accuracy: 0.7294\n",
      "Epoch 550/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7412 - val_loss: 0.1995 - val_accuracy: 0.7298\n",
      "Epoch 551/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7352 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 552/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7414 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 553/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7374 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 554/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7367 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 555/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7341 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 556/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7468 - val_loss: 0.1995 - val_accuracy: 0.7298\n",
      "Epoch 557/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7370 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 558/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1982 - accuracy: 0.7331 - val_loss: 0.1995 - val_accuracy: 0.7294\n",
      "Epoch 559/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7415 - val_loss: 0.1994 - val_accuracy: 0.7294\n",
      "Epoch 560/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1962 - accuracy: 0.7383 - val_loss: 0.1994 - val_accuracy: 0.7294\n",
      "Epoch 561/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.7421 - val_loss: 0.1994 - val_accuracy: 0.7293\n",
      "Epoch 562/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7365 - val_loss: 0.1994 - val_accuracy: 0.7293\n",
      "Epoch 563/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7322 - val_loss: 0.1994 - val_accuracy: 0.7298\n",
      "Epoch 564/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.7313 - val_loss: 0.1994 - val_accuracy: 0.7293\n",
      "Epoch 565/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1968 - accuracy: 0.7360 - val_loss: 0.1994 - val_accuracy: 0.7293\n",
      "Epoch 566/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7350 - val_loss: 0.1994 - val_accuracy: 0.7293\n",
      "Epoch 567/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7287 - val_loss: 0.1993 - val_accuracy: 0.7293\n",
      "Epoch 568/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7345 - val_loss: 0.1993 - val_accuracy: 0.7298\n",
      "Epoch 569/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.7312 - val_loss: 0.1993 - val_accuracy: 0.7297\n",
      "Epoch 570/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1959 - accuracy: 0.7400 - val_loss: 0.1993 - val_accuracy: 0.7297\n",
      "Epoch 571/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.7349 - val_loss: 0.1993 - val_accuracy: 0.7297\n",
      "Epoch 572/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7397 - val_loss: 0.1993 - val_accuracy: 0.7293\n",
      "Epoch 573/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1978 - accuracy: 0.7348 - val_loss: 0.1993 - val_accuracy: 0.7293\n",
      "Epoch 574/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7354 - val_loss: 0.1993 - val_accuracy: 0.7293\n",
      "Epoch 575/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7377 - val_loss: 0.1993 - val_accuracy: 0.7296\n",
      "Epoch 576/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.7333 - val_loss: 0.1992 - val_accuracy: 0.7293\n",
      "Epoch 577/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.7375 - val_loss: 0.1992 - val_accuracy: 0.7291\n",
      "Epoch 578/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.7355 - val_loss: 0.1992 - val_accuracy: 0.7291\n",
      "Epoch 579/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.7330 - val_loss: 0.1992 - val_accuracy: 0.7293\n",
      "Epoch 580/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7434 - val_loss: 0.1992 - val_accuracy: 0.7291\n",
      "Epoch 581/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.7361 - val_loss: 0.1992 - val_accuracy: 0.7293\n",
      "Epoch 582/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7437 - val_loss: 0.1992 - val_accuracy: 0.7291\n",
      "Epoch 583/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7366 - val_loss: 0.1992 - val_accuracy: 0.7291\n",
      "Epoch 584/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1979 - accuracy: 0.7310 - val_loss: 0.1992 - val_accuracy: 0.7291\n",
      "Epoch 585/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1972 - accuracy: 0.7314 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 586/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7411 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 587/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1962 - accuracy: 0.7366 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 588/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7386 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 589/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.7361 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 590/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.7370 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 591/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.7401 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 592/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7328 - val_loss: 0.1991 - val_accuracy: 0.7291\n",
      "Epoch 593/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.7425 - val_loss: 0.1991 - val_accuracy: 0.7296\n",
      "Epoch 594/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7369 - val_loss: 0.1990 - val_accuracy: 0.7291\n",
      "Epoch 595/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7397 - val_loss: 0.1990 - val_accuracy: 0.7296\n",
      "Epoch 596/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7378 - val_loss: 0.1990 - val_accuracy: 0.7291\n",
      "Epoch 597/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.7406 - val_loss: 0.1990 - val_accuracy: 0.7291\n",
      "Epoch 598/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.7280 - val_loss: 0.1990 - val_accuracy: 0.7291\n",
      "Epoch 599/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1945 - accuracy: 0.7401 - val_loss: 0.1990 - val_accuracy: 0.7291\n",
      "Epoch 600/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1974 - accuracy: 0.7332 - val_loss: 0.1990 - val_accuracy: 0.7291\n",
      "Epoch 601/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7317 - val_loss: 0.1990 - val_accuracy: 0.7292\n",
      "Epoch 602/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1969 - accuracy: 0.7342 - val_loss: 0.1990 - val_accuracy: 0.7292\n",
      "Epoch 603/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1973 - accuracy: 0.7345 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 604/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7425 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 605/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7294 - val_loss: 0.1989 - val_accuracy: 0.7292\n",
      "Epoch 606/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.7354 - val_loss: 0.1989 - val_accuracy: 0.7292\n",
      "Epoch 607/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.7385 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 608/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.7395 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 609/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7372 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 610/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7437 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 611/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.7421 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 612/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7452 - val_loss: 0.1989 - val_accuracy: 0.7291\n",
      "Epoch 613/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7424 - val_loss: 0.1988 - val_accuracy: 0.7291\n",
      "Epoch 614/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7379 - val_loss: 0.1988 - val_accuracy: 0.7292\n",
      "Epoch 615/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7394 - val_loss: 0.1988 - val_accuracy: 0.7291\n",
      "Epoch 616/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.7402 - val_loss: 0.1988 - val_accuracy: 0.7292\n",
      "Epoch 617/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.7340 - val_loss: 0.1988 - val_accuracy: 0.7292\n",
      "Epoch 618/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.7339 - val_loss: 0.1988 - val_accuracy: 0.7292\n",
      "Epoch 619/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7461 - val_loss: 0.1988 - val_accuracy: 0.7291\n",
      "Epoch 620/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7376 - val_loss: 0.1988 - val_accuracy: 0.7291\n",
      "Epoch 621/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.7388 - val_loss: 0.1988 - val_accuracy: 0.7291\n",
      "Epoch 622/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7342 - val_loss: 0.1988 - val_accuracy: 0.7291\n",
      "Epoch 623/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7398 - val_loss: 0.1987 - val_accuracy: 0.7291\n",
      "Epoch 624/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7362 - val_loss: 0.1987 - val_accuracy: 0.7291\n",
      "Epoch 625/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7369 - val_loss: 0.1987 - val_accuracy: 0.7292\n",
      "Epoch 626/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.7387 - val_loss: 0.1987 - val_accuracy: 0.7292\n",
      "Epoch 627/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7349 - val_loss: 0.1987 - val_accuracy: 0.7292\n",
      "Epoch 628/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.7313 - val_loss: 0.1987 - val_accuracy: 0.7292\n",
      "Epoch 629/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7407 - val_loss: 0.1987 - val_accuracy: 0.7291\n",
      "Epoch 630/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7424 - val_loss: 0.1987 - val_accuracy: 0.7291\n",
      "Epoch 631/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7375 - val_loss: 0.1987 - val_accuracy: 0.7292\n",
      "Epoch 632/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7383 - val_loss: 0.1986 - val_accuracy: 0.7291\n",
      "Epoch 633/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7348 - val_loss: 0.1986 - val_accuracy: 0.7291\n",
      "Epoch 634/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.7346 - val_loss: 0.1986 - val_accuracy: 0.7291\n",
      "Epoch 635/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7405 - val_loss: 0.1986 - val_accuracy: 0.7289\n",
      "Epoch 636/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.7349 - val_loss: 0.1986 - val_accuracy: 0.7291\n",
      "Epoch 637/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7376 - val_loss: 0.1986 - val_accuracy: 0.7291\n",
      "Epoch 638/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7411 - val_loss: 0.1986 - val_accuracy: 0.7289\n",
      "Epoch 639/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.7402 - val_loss: 0.1986 - val_accuracy: 0.7289\n",
      "Epoch 640/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7355 - val_loss: 0.1986 - val_accuracy: 0.7289\n",
      "Epoch 641/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7338 - val_loss: 0.1986 - val_accuracy: 0.7289\n",
      "Epoch 642/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7466 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 643/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7447 - val_loss: 0.1985 - val_accuracy: 0.7289\n",
      "Epoch 644/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1981 - accuracy: 0.7323 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 645/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.7259 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 646/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7354 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 647/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7327 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 648/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7420 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 649/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7410 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 650/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1973 - accuracy: 0.7317 - val_loss: 0.1985 - val_accuracy: 0.7291\n",
      "Epoch 651/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7334 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 652/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1976 - accuracy: 0.7314 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 653/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7437 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 654/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.7355 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 655/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7391 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 656/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1992 - accuracy: 0.7297 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 657/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7421 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 658/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.7499 - val_loss: 0.1984 - val_accuracy: 0.7294\n",
      "Epoch 659/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7414 - val_loss: 0.1984 - val_accuracy: 0.7291\n",
      "Epoch 660/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.7450 - val_loss: 0.1984 - val_accuracy: 0.7294\n",
      "Epoch 661/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7381 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 662/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7324 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 663/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.7331 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 664/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7341 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 665/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.7414 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 666/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.7357 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 667/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1984 - accuracy: 0.7311 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 668/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7330 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 669/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7427 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 670/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7383 - val_loss: 0.1983 - val_accuracy: 0.7294\n",
      "Epoch 671/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1975 - accuracy: 0.7313 - val_loss: 0.1982 - val_accuracy: 0.7294\n",
      "Epoch 672/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1966 - accuracy: 0.7338 - val_loss: 0.1982 - val_accuracy: 0.7294\n",
      "Epoch 673/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7465 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 674/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7325 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 675/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1980 - accuracy: 0.7300 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 676/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7455 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 677/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.7479 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 678/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7451 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 679/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7404 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 680/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7411 - val_loss: 0.1982 - val_accuracy: 0.7291\n",
      "Epoch 681/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7399 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 682/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7377 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 683/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7405 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 684/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7381 - val_loss: 0.1981 - val_accuracy: 0.7293\n",
      "Epoch 685/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.7356 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 686/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7386 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 687/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1985 - accuracy: 0.7280 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 688/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7407 - val_loss: 0.1981 - val_accuracy: 0.7293\n",
      "Epoch 689/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1961 - accuracy: 0.7389 - val_loss: 0.1981 - val_accuracy: 0.7291\n",
      "Epoch 690/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.7415 - val_loss: 0.1981 - val_accuracy: 0.7293\n",
      "Epoch 691/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1968 - accuracy: 0.7339 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 692/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7361 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 693/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7376 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 694/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7404 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 695/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7385 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 696/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7405 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 697/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7395 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 698/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7450 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 699/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7410 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 700/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7417 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 701/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1964 - accuracy: 0.7326 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 702/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7417 - val_loss: 0.1980 - val_accuracy: 0.7293\n",
      "Epoch 703/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7349 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 704/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7413 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 705/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7411 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 706/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7388 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 707/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7358 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 708/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7376 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 709/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1975 - accuracy: 0.7330 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 710/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.7371 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 711/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7403 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 712/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7342 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 713/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7370 - val_loss: 0.1979 - val_accuracy: 0.7293\n",
      "Epoch 714/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.7426 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 715/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7407 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 716/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7421 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 717/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7353 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 718/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7420 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 719/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7364 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 720/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7363 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 721/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.7391 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 722/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1924 - accuracy: 0.7463 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 723/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.7327 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 724/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7394 - val_loss: 0.1978 - val_accuracy: 0.7293\n",
      "Epoch 725/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7369 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 726/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7438 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 727/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7359 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 728/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7452 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 729/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7301 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 730/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.7417 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 731/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7404 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 732/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7412 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 733/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7436 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 734/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7424 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 735/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.7395 - val_loss: 0.1977 - val_accuracy: 0.7293\n",
      "Epoch 736/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.7359 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 737/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7426 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 738/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7397 - val_loss: 0.1976 - val_accuracy: 0.7292\n",
      "Epoch 739/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7455 - val_loss: 0.1976 - val_accuracy: 0.7292\n",
      "Epoch 740/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7410 - val_loss: 0.1976 - val_accuracy: 0.7292\n",
      "Epoch 741/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.7325 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 742/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7434 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 743/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7433 - val_loss: 0.1976 - val_accuracy: 0.7292\n",
      "Epoch 744/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.7423 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 745/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7371 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 746/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7406 - val_loss: 0.1976 - val_accuracy: 0.7293\n",
      "Epoch 747/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7384 - val_loss: 0.1976 - val_accuracy: 0.7292\n",
      "Epoch 748/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7358 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 749/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7318 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 750/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7392 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 751/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7398 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 752/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7384 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 753/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7374 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 754/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7339 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 755/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.7431 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 756/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7434 - val_loss: 0.1975 - val_accuracy: 0.7294\n",
      "Epoch 757/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7382 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 758/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7460 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 759/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7501 - val_loss: 0.1975 - val_accuracy: 0.7293\n",
      "Epoch 760/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.7453 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 761/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.7391 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 762/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7394 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 763/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7381 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 764/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7449 - val_loss: 0.1974 - val_accuracy: 0.7294\n",
      "Epoch 765/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.7367 - val_loss: 0.1974 - val_accuracy: 0.7294\n",
      "Epoch 766/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.7462 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 767/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1963 - accuracy: 0.7343 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 768/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.7403 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 769/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7416 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 770/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7340 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 771/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7438 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 772/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7439 - val_loss: 0.1974 - val_accuracy: 0.7293\n",
      "Epoch 773/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.7443 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 774/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7388 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 775/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7444 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 776/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7422 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 777/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7431 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 778/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.7418 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 779/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7399 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 780/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7452 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 781/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7415 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 782/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7363 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 783/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7349 - val_loss: 0.1973 - val_accuracy: 0.7293\n",
      "Epoch 784/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7421 - val_loss: 0.1973 - val_accuracy: 0.7292\n",
      "Epoch 785/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.7446 - val_loss: 0.1972 - val_accuracy: 0.7292\n",
      "Epoch 786/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1978 - accuracy: 0.7285 - val_loss: 0.1972 - val_accuracy: 0.7294\n",
      "Epoch 787/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.7372 - val_loss: 0.1972 - val_accuracy: 0.7293\n",
      "Epoch 788/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7457 - val_loss: 0.1972 - val_accuracy: 0.7293\n",
      "Epoch 789/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1943 - accuracy: 0.7375 - val_loss: 0.1972 - val_accuracy: 0.7292\n",
      "Epoch 790/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7404 - val_loss: 0.1972 - val_accuracy: 0.7291\n",
      "Epoch 791/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7434 - val_loss: 0.1972 - val_accuracy: 0.7293\n",
      "Epoch 792/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.7446 - val_loss: 0.1972 - val_accuracy: 0.7292\n",
      "Epoch 793/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7395 - val_loss: 0.1972 - val_accuracy: 0.7292\n",
      "Epoch 794/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7388 - val_loss: 0.1972 - val_accuracy: 0.7291\n",
      "Epoch 795/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7378 - val_loss: 0.1972 - val_accuracy: 0.7291\n",
      "Epoch 796/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7348 - val_loss: 0.1972 - val_accuracy: 0.7291\n",
      "Epoch 797/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7364 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 798/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.7403 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 799/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7404 - val_loss: 0.1971 - val_accuracy: 0.7292\n",
      "Epoch 800/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7425 - val_loss: 0.1971 - val_accuracy: 0.7292\n",
      "Epoch 801/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1953 - accuracy: 0.7386 - val_loss: 0.1971 - val_accuracy: 0.7292\n",
      "Epoch 802/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7450 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 803/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7379 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 804/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1954 - accuracy: 0.7378 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 805/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7415 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 806/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1937 - accuracy: 0.7377 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 807/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.7339 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 808/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7383 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 809/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7382 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 810/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.7435 - val_loss: 0.1971 - val_accuracy: 0.7291\n",
      "Epoch 811/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7346 - val_loss: 0.1970 - val_accuracy: 0.7292\n",
      "Epoch 812/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7404 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 813/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1944 - accuracy: 0.7352 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 814/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7384 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 815/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1910 - accuracy: 0.7482 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 816/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.7403 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 817/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7351 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 818/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7425 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 819/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7290 - val_loss: 0.1970 - val_accuracy: 0.7292\n",
      "Epoch 820/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7367 - val_loss: 0.1970 - val_accuracy: 0.7292\n",
      "Epoch 821/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7399 - val_loss: 0.1970 - val_accuracy: 0.7291\n",
      "Epoch 822/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7406 - val_loss: 0.1970 - val_accuracy: 0.7292\n",
      "Epoch 823/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7399 - val_loss: 0.1970 - val_accuracy: 0.7292\n",
      "Epoch 824/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7434 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 825/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7352 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 826/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7403 - val_loss: 0.1969 - val_accuracy: 0.7292\n",
      "Epoch 827/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7382 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 828/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7402 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 829/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7401 - val_loss: 0.1969 - val_accuracy: 0.7292\n",
      "Epoch 830/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1967 - accuracy: 0.7320 - val_loss: 0.1969 - val_accuracy: 0.7292\n",
      "Epoch 831/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.7448 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 832/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.7401 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 833/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.7424 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 834/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7412 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 835/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7404 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 836/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.7435 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 837/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.7424 - val_loss: 0.1969 - val_accuracy: 0.7291\n",
      "Epoch 838/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7394 - val_loss: 0.1968 - val_accuracy: 0.7292\n",
      "Epoch 839/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7421 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 840/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7397 - val_loss: 0.1968 - val_accuracy: 0.7292\n",
      "Epoch 841/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.7398 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 842/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7393 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 843/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7347 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 844/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7481 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 845/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7380 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 846/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1936 - accuracy: 0.7378 - val_loss: 0.1968 - val_accuracy: 0.7292\n",
      "Epoch 847/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7384 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 848/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7421 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 849/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.7400 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 850/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1957 - accuracy: 0.7331 - val_loss: 0.1968 - val_accuracy: 0.7291\n",
      "Epoch 851/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.7358 - val_loss: 0.1968 - val_accuracy: 0.7292\n",
      "Epoch 852/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7404 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 853/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7343 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 854/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7372 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 855/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.7414 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 856/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.7351 - val_loss: 0.1967 - val_accuracy: 0.7292\n",
      "Epoch 857/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7385 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 858/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7356 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 859/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7345 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 860/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7332 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 861/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7371 - val_loss: 0.1967 - val_accuracy: 0.7290\n",
      "Epoch 862/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7392 - val_loss: 0.1967 - val_accuracy: 0.7290\n",
      "Epoch 863/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7381 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 864/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7370 - val_loss: 0.1967 - val_accuracy: 0.7291\n",
      "Epoch 865/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7442 - val_loss: 0.1967 - val_accuracy: 0.7290\n",
      "Epoch 866/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.7416 - val_loss: 0.1967 - val_accuracy: 0.7290\n",
      "Epoch 867/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7389 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 868/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1926 - accuracy: 0.7389 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 869/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7412 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 870/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1919 - accuracy: 0.7378 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 871/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.7421 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 872/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7382 - val_loss: 0.1966 - val_accuracy: 0.7291\n",
      "Epoch 873/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7384 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 874/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7378 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 875/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7400 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 876/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1943 - accuracy: 0.7364 - val_loss: 0.1966 - val_accuracy: 0.7291\n",
      "Epoch 877/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.7369 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 878/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7411 - val_loss: 0.1966 - val_accuracy: 0.7289\n",
      "Epoch 879/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7426 - val_loss: 0.1966 - val_accuracy: 0.7290\n",
      "Epoch 880/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7351 - val_loss: 0.1966 - val_accuracy: 0.7289\n",
      "Epoch 881/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.7415 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 882/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1933 - accuracy: 0.7400 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 883/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7383 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 884/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.7347 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 885/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.7419 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 886/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7397 - val_loss: 0.1965 - val_accuracy: 0.7291\n",
      "Epoch 887/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7407 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 888/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7421 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 889/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7377 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 890/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7347 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 891/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7424 - val_loss: 0.1965 - val_accuracy: 0.7290\n",
      "Epoch 892/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7423 - val_loss: 0.1965 - val_accuracy: 0.7289\n",
      "Epoch 893/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7330 - val_loss: 0.1965 - val_accuracy: 0.7289\n",
      "Epoch 894/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.7414 - val_loss: 0.1965 - val_accuracy: 0.7289\n",
      "Epoch 895/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7325 - val_loss: 0.1965 - val_accuracy: 0.7289\n",
      "Epoch 896/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7381 - val_loss: 0.1965 - val_accuracy: 0.7289\n",
      "Epoch 897/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1969 - accuracy: 0.7316 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 898/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1929 - accuracy: 0.7401 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 899/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7437 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 900/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7430 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 901/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7396 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 902/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.7395 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 903/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7369 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 904/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.7463 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 905/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1959 - accuracy: 0.7332 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 906/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7387 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 907/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1926 - accuracy: 0.7396 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 908/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1940 - accuracy: 0.7368 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 909/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1921 - accuracy: 0.7408 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 910/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7461 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 911/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.7329 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 912/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7370 - val_loss: 0.1964 - val_accuracy: 0.7289\n",
      "Epoch 913/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.7414 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 914/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.7392 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 915/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1958 - accuracy: 0.7338 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 916/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7405 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 917/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1921 - accuracy: 0.7388 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 918/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1931 - accuracy: 0.7384 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 919/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1949 - accuracy: 0.7350 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 920/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1922 - accuracy: 0.7402 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 921/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7383 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 922/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.7353 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 923/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7318 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 924/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7479 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 925/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7420 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 926/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.7418 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 927/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1907 - accuracy: 0.7418 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 928/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.7467 - val_loss: 0.1963 - val_accuracy: 0.7289\n",
      "Epoch 929/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7366 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 930/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1928 - accuracy: 0.7390 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 931/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.7405 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 932/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7394 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 933/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.7416 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 934/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1931 - accuracy: 0.7366 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 935/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1918 - accuracy: 0.7403 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 936/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: 0.7395 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 937/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7425 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 938/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1950 - accuracy: 0.7329 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 939/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1935 - accuracy: 0.7393 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 940/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1939 - accuracy: 0.7375 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 941/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1902 - accuracy: 0.7461 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 942/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7380 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 943/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.7457 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 944/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1923 - accuracy: 0.7413 - val_loss: 0.1962 - val_accuracy: 0.7289\n",
      "Epoch 945/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1905 - accuracy: 0.7456 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 946/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1938 - accuracy: 0.7352 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 947/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1922 - accuracy: 0.7381 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 948/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1925 - accuracy: 0.7338 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 949/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.7436 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 950/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1941 - accuracy: 0.7359 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 951/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7366 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 952/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1942 - accuracy: 0.7362 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 953/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7405 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 954/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1913 - accuracy: 0.7447 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 955/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1916 - accuracy: 0.7413 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 956/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.7461 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 957/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7425 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 958/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1924 - accuracy: 0.7428 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 959/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.7398 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 960/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.7449 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 961/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1930 - accuracy: 0.7381 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 962/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1906 - accuracy: 0.7437 - val_loss: 0.1961 - val_accuracy: 0.7289\n",
      "Epoch 963/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1927 - accuracy: 0.7390 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 964/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1903 - accuracy: 0.7463 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 965/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1918 - accuracy: 0.7445 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 966/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1940 - accuracy: 0.7395 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 967/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7412 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 968/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.7449 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 969/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.7319 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 970/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1942 - accuracy: 0.7346 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 971/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7389 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 972/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7376 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 973/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.7349 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 974/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1914 - accuracy: 0.7425 - val_loss: 0.1960 - val_accuracy: 0.7290\n",
      "Epoch 975/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1908 - accuracy: 0.7406 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 976/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1934 - accuracy: 0.7376 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 977/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7452 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 978/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7484 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 979/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1932 - accuracy: 0.7369 - val_loss: 0.1960 - val_accuracy: 0.7289\n",
      "Epoch 980/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1944 - accuracy: 0.7333 - val_loss: 0.1959 - val_accuracy: 0.7290\n",
      "Epoch 981/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1960 - accuracy: 0.7320 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 982/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1955 - accuracy: 0.7334 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 983/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7354 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 984/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.7458 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 985/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1909 - accuracy: 0.7445 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 986/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1951 - accuracy: 0.7288 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 987/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1945 - accuracy: 0.7321 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 988/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1949 - accuracy: 0.7297 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 989/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.7448 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 990/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1920 - accuracy: 0.7408 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 991/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1898 - accuracy: 0.7465 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 992/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 0.7436 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 993/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1900 - accuracy: 0.7449 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 994/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1937 - accuracy: 0.7360 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 995/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.7426 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 996/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1950 - accuracy: 0.7308 - val_loss: 0.1959 - val_accuracy: 0.7290\n",
      "Epoch 997/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.7434 - val_loss: 0.1959 - val_accuracy: 0.7289\n",
      "Epoch 998/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1905 - accuracy: 0.7409 - val_loss: 0.1958 - val_accuracy: 0.7289\n",
      "Epoch 999/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1897 - accuracy: 0.7439 - val_loss: 0.1958 - val_accuracy: 0.7289\n",
      "Epoch 1000/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1935 - accuracy: 0.7357 - val_loss: 0.1958 - val_accuracy: 0.7289\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A23 = nn_A23.fit(X_train_scaled, y_train, validation_split=0.6, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 8 Results\n",
      "Loss: 0.19754020869731903, Accuracy: 0.7290962338447571\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 23 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A23.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Model 24+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the the number of inputs (features) to the model\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "# Review the number of features\n",
    "number_input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of neurons in the output layer\n",
    "number_output_neurons_A24 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the first hidden layer\n",
    "hidden_nodes_layer1_A24 =  (number_input_features + number_output_neurons_A24) // 2\n",
    "# Review the number of hidden nodes in the first layer\n",
    "hidden_nodes_layer1_A24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the second hidden layer\n",
    "hidden_nodes_layer2_A24 =  (hidden_nodes_layer1_A24 + number_output_neurons_A24) // 2\n",
    "# Review the number of hidden nodes in the second layer\n",
    "hidden_nodes_layer2_A24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the third hidden layer\n",
    "hidden_nodes_layer3_A24 =  (hidden_nodes_layer2_A24 + number_output_neurons_A24) // 2\n",
    "# Review the number of hidden nodes in the third layer\n",
    "hidden_nodes_layer3_A24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fourth hidden layer\n",
    "hidden_nodes_layer4_A24 =  (hidden_nodes_layer3_A24 + number_output_neurons_A24) // 2\n",
    "# Review the number of hidden nodes in the fourth layer\n",
    "hidden_nodes_layer4_A24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the fifth hidden layer\n",
    "hidden_nodes_layer5_A24 =  (hidden_nodes_layer4_A24 + number_output_neurons_A24) // 2\n",
    "# Review the number of hidden nodes in the fifth layer\n",
    "hidden_nodes_layer5_A24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of hidden nodes for the Sixth hidden layer\n",
    "hidden_nodes_layer6_A24 =  (hidden_nodes_layer5_A24 + number_output_neurons_A24) // 2\n",
    "# Review the number of hidden nodes in the sixth layer\n",
    "hidden_nodes_layer6_A24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_28 (Dense)             (None, 57)                6555      \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 29)                1682      \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 15)                450       \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 8)                 128       \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 8,864\n",
      "Trainable params: 8,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and Display the Sequential Model Instance \n",
    "# for Model A24\n",
    "nn_A24 = Sequential() \n",
    "\n",
    "# Add the first hidden layer\n",
    "nn_A24.add(Dense(units=hidden_nodes_layer1_A24, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the second hidden layer\n",
    "nn_A24.add(Dense(units=hidden_nodes_layer2_A24, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the third hidden layer\n",
    "nn_A24.add(Dense(units=hidden_nodes_layer3_A24, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fourth hidden layer\n",
    "nn_A24.add(Dense(units=hidden_nodes_layer4_A24, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the fifth hidden layer\n",
    "nn_A24.add(Dense(units=hidden_nodes_layer5_A24, input_dim=number_input_features, activation=\"relu\"))\n",
    "# Add the sixth hidden layer\n",
    "nn_A24.add(Dense(units=hidden_nodes_layer6_A24, activation=\"relu\"))\n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn_A24.add(Dense(units=number_output_neurons_A24, activation=\"sigmoid\"))\n",
    "\n",
    "# Display the Sequential model summary\n",
    "nn_A24.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn_A24.compile(loss=\"mse\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2509 - accuracy: 0.4952 - val_loss: 0.2498 - val_accuracy: 0.5191\n",
      "Epoch 2/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2498 - accuracy: 0.5169 - val_loss: 0.2492 - val_accuracy: 0.5318\n",
      "Epoch 3/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2489 - accuracy: 0.5324 - val_loss: 0.2488 - val_accuracy: 0.5326\n",
      "Epoch 4/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5334 - val_loss: 0.2486 - val_accuracy: 0.5328\n",
      "Epoch 5/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2486 - accuracy: 0.5292 - val_loss: 0.2480 - val_accuracy: 0.5339\n",
      "Epoch 6/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.5336 - val_loss: 0.2474 - val_accuracy: 0.5342\n",
      "Epoch 7/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2469 - accuracy: 0.5396 - val_loss: 0.2465 - val_accuracy: 0.5357\n",
      "Epoch 8/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.5583 - val_loss: 0.2455 - val_accuracy: 0.5600\n",
      "Epoch 9/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2455 - accuracy: 0.5594 - val_loss: 0.2443 - val_accuracy: 0.5885\n",
      "Epoch 10/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.5944 - val_loss: 0.2428 - val_accuracy: 0.6226\n",
      "Epoch 11/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2427 - accuracy: 0.6312 - val_loss: 0.2409 - val_accuracy: 0.6451\n",
      "Epoch 12/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2396 - accuracy: 0.6504 - val_loss: 0.2372 - val_accuracy: 0.6579\n",
      "Epoch 13/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2362 - accuracy: 0.6932 - val_loss: 0.2330 - val_accuracy: 0.7009\n",
      "Epoch 14/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2319 - accuracy: 0.7023 - val_loss: 0.2289 - val_accuracy: 0.7079\n",
      "Epoch 15/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2268 - accuracy: 0.7130 - val_loss: 0.2244 - val_accuracy: 0.7099\n",
      "Epoch 16/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2225 - accuracy: 0.7161 - val_loss: 0.2197 - val_accuracy: 0.7118\n",
      "Epoch 17/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.2181 - accuracy: 0.7156 - val_loss: 0.2154 - val_accuracy: 0.7119\n",
      "Epoch 18/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2132 - accuracy: 0.7169 - val_loss: 0.2117 - val_accuracy: 0.7158\n",
      "Epoch 19/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.2101 - accuracy: 0.7184 - val_loss: 0.2086 - val_accuracy: 0.7180\n",
      "Epoch 20/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.7277 - val_loss: 0.2061 - val_accuracy: 0.7184\n",
      "Epoch 21/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2038 - accuracy: 0.7235 - val_loss: 0.2042 - val_accuracy: 0.7190\n",
      "Epoch 22/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2020 - accuracy: 0.7216 - val_loss: 0.2025 - val_accuracy: 0.7185\n",
      "Epoch 23/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2014 - accuracy: 0.7225 - val_loss: 0.2013 - val_accuracy: 0.7190\n",
      "Epoch 24/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1997 - accuracy: 0.7216 - val_loss: 0.2004 - val_accuracy: 0.7191\n",
      "Epoch 25/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.2004 - accuracy: 0.7188 - val_loss: 0.1997 - val_accuracy: 0.7191\n",
      "Epoch 26/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1989 - accuracy: 0.7194 - val_loss: 0.1989 - val_accuracy: 0.7193\n",
      "Epoch 27/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1947 - accuracy: 0.7294 - val_loss: 0.1982 - val_accuracy: 0.7195\n",
      "Epoch 28/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1974 - accuracy: 0.7216 - val_loss: 0.1977 - val_accuracy: 0.7201\n",
      "Epoch 29/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1948 - accuracy: 0.7250 - val_loss: 0.1974 - val_accuracy: 0.7204\n",
      "Epoch 30/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1956 - accuracy: 0.7228 - val_loss: 0.1968 - val_accuracy: 0.7199\n",
      "Epoch 31/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1965 - accuracy: 0.7204 - val_loss: 0.1959 - val_accuracy: 0.7198\n",
      "Epoch 32/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1941 - accuracy: 0.7245 - val_loss: 0.1948 - val_accuracy: 0.7232\n",
      "Epoch 33/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.7210 - val_loss: 0.1943 - val_accuracy: 0.7241\n",
      "Epoch 34/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1922 - accuracy: 0.7272 - val_loss: 0.1941 - val_accuracy: 0.7243\n",
      "Epoch 35/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7294 - val_loss: 0.1937 - val_accuracy: 0.7243\n",
      "Epoch 36/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1917 - accuracy: 0.7276 - val_loss: 0.1934 - val_accuracy: 0.7238\n",
      "Epoch 37/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1952 - accuracy: 0.7194 - val_loss: 0.1932 - val_accuracy: 0.7244\n",
      "Epoch 38/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1911 - accuracy: 0.7259 - val_loss: 0.1931 - val_accuracy: 0.7237\n",
      "Epoch 39/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1925 - accuracy: 0.7249 - val_loss: 0.1928 - val_accuracy: 0.7237\n",
      "Epoch 40/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1912 - accuracy: 0.7267 - val_loss: 0.1926 - val_accuracy: 0.7237\n",
      "Epoch 41/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.7307 - val_loss: 0.1924 - val_accuracy: 0.7241\n",
      "Epoch 42/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1902 - accuracy: 0.7276 - val_loss: 0.1924 - val_accuracy: 0.7241\n",
      "Epoch 43/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1904 - accuracy: 0.7274 - val_loss: 0.1921 - val_accuracy: 0.7242\n",
      "Epoch 44/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7253 - val_loss: 0.1920 - val_accuracy: 0.7243\n",
      "Epoch 45/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7323 - val_loss: 0.1919 - val_accuracy: 0.7239\n",
      "Epoch 46/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.7283 - val_loss: 0.1919 - val_accuracy: 0.7243\n",
      "Epoch 47/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.7266 - val_loss: 0.1918 - val_accuracy: 0.7241\n",
      "Epoch 48/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7292 - val_loss: 0.1917 - val_accuracy: 0.7243\n",
      "Epoch 49/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7344 - val_loss: 0.1915 - val_accuracy: 0.7239\n",
      "Epoch 50/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1900 - accuracy: 0.7275 - val_loss: 0.1915 - val_accuracy: 0.7237\n",
      "Epoch 51/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7320 - val_loss: 0.1914 - val_accuracy: 0.7240\n",
      "Epoch 52/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7378 - val_loss: 0.1913 - val_accuracy: 0.7241\n",
      "Epoch 53/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7348 - val_loss: 0.1916 - val_accuracy: 0.7237\n",
      "Epoch 54/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7265 - val_loss: 0.1912 - val_accuracy: 0.7243\n",
      "Epoch 55/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.7249 - val_loss: 0.1912 - val_accuracy: 0.7241\n",
      "Epoch 56/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7401 - val_loss: 0.1911 - val_accuracy: 0.7239\n",
      "Epoch 57/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7413 - val_loss: 0.1912 - val_accuracy: 0.7240\n",
      "Epoch 58/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.7249 - val_loss: 0.1910 - val_accuracy: 0.7245\n",
      "Epoch 59/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7327 - val_loss: 0.1912 - val_accuracy: 0.7244\n",
      "Epoch 60/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1895 - accuracy: 0.7236 - val_loss: 0.1911 - val_accuracy: 0.7242\n",
      "Epoch 61/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7325 - val_loss: 0.1910 - val_accuracy: 0.7247\n",
      "Epoch 62/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7286 - val_loss: 0.1910 - val_accuracy: 0.7243\n",
      "Epoch 63/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7282 - val_loss: 0.1909 - val_accuracy: 0.7257\n",
      "Epoch 64/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7304 - val_loss: 0.1909 - val_accuracy: 0.7261\n",
      "Epoch 65/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1888 - accuracy: 0.7325 - val_loss: 0.1909 - val_accuracy: 0.7261\n",
      "Epoch 66/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7300 - val_loss: 0.1908 - val_accuracy: 0.7271\n",
      "Epoch 67/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7334 - val_loss: 0.1908 - val_accuracy: 0.7269\n",
      "Epoch 68/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1880 - accuracy: 0.7324 - val_loss: 0.1909 - val_accuracy: 0.7270\n",
      "Epoch 69/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7296 - val_loss: 0.1907 - val_accuracy: 0.7269\n",
      "Epoch 70/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7366 - val_loss: 0.1909 - val_accuracy: 0.7281\n",
      "Epoch 71/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7330 - val_loss: 0.1909 - val_accuracy: 0.7266\n",
      "Epoch 72/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7359 - val_loss: 0.1909 - val_accuracy: 0.7262\n",
      "Epoch 73/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1890 - accuracy: 0.7317 - val_loss: 0.1906 - val_accuracy: 0.7279\n",
      "Epoch 74/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1893 - accuracy: 0.7296 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 75/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7347 - val_loss: 0.1907 - val_accuracy: 0.7273\n",
      "Epoch 76/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7353 - val_loss: 0.1907 - val_accuracy: 0.7275\n",
      "Epoch 77/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7365 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 78/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1915 - accuracy: 0.7242 - val_loss: 0.1908 - val_accuracy: 0.7265\n",
      "Epoch 79/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7420 - val_loss: 0.1906 - val_accuracy: 0.7270\n",
      "Epoch 80/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7356 - val_loss: 0.1908 - val_accuracy: 0.7265\n",
      "Epoch 81/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7326 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 82/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7355 - val_loss: 0.1906 - val_accuracy: 0.7278\n",
      "Epoch 83/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7300 - val_loss: 0.1906 - val_accuracy: 0.7271\n",
      "Epoch 84/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.7271 - val_loss: 0.1907 - val_accuracy: 0.7267\n",
      "Epoch 85/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7347 - val_loss: 0.1906 - val_accuracy: 0.7278\n",
      "Epoch 86/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1854 - accuracy: 0.7390 - val_loss: 0.1907 - val_accuracy: 0.7285\n",
      "Epoch 87/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1871 - accuracy: 0.7321 - val_loss: 0.1906 - val_accuracy: 0.7276\n",
      "Epoch 88/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7439 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 89/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7353 - val_loss: 0.1908 - val_accuracy: 0.7273\n",
      "Epoch 90/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7342 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 91/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7330 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 92/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.7471 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 93/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1841 - accuracy: 0.7392 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 94/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7293 - val_loss: 0.1908 - val_accuracy: 0.7272\n",
      "Epoch 95/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1889 - accuracy: 0.7301 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 96/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7292 - val_loss: 0.1908 - val_accuracy: 0.7262\n",
      "Epoch 97/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7375 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 98/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7324 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 99/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7304 - val_loss: 0.1906 - val_accuracy: 0.7273\n",
      "Epoch 100/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1892 - accuracy: 0.7303 - val_loss: 0.1907 - val_accuracy: 0.7271\n",
      "Epoch 101/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7369 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 102/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7333 - val_loss: 0.1906 - val_accuracy: 0.7289\n",
      "Epoch 103/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1859 - accuracy: 0.7364 - val_loss: 0.1908 - val_accuracy: 0.7272\n",
      "Epoch 104/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7337 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 105/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7408 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 106/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7392 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 107/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7344 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 108/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7342 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 109/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.7297 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 110/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7321 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 111/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7332 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 112/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7436 - val_loss: 0.1907 - val_accuracy: 0.7277\n",
      "Epoch 113/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7352 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 114/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7326 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 115/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7350 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 116/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7368 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 117/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7428 - val_loss: 0.1906 - val_accuracy: 0.7287\n",
      "Epoch 118/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7363 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 119/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7431 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 120/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7341 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 121/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7335 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 122/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7400 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 123/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7354 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 124/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7321 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 125/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7407 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 126/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7310 - val_loss: 0.1908 - val_accuracy: 0.7277\n",
      "Epoch 127/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7336 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 128/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1894 - accuracy: 0.7292 - val_loss: 0.1906 - val_accuracy: 0.7291\n",
      "Epoch 129/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7356 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 130/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.7290 - val_loss: 0.1907 - val_accuracy: 0.7270\n",
      "Epoch 131/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7415 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 132/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7461 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 133/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7363 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 134/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1868 - accuracy: 0.7326 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 135/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7408 - val_loss: 0.1911 - val_accuracy: 0.7272\n",
      "Epoch 136/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7306 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 137/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7315 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 138/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7353 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 139/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7351 - val_loss: 0.1905 - val_accuracy: 0.7293\n",
      "Epoch 140/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7359 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 141/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7400 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 142/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7304 - val_loss: 0.1907 - val_accuracy: 0.7269\n",
      "Epoch 143/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7416 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 144/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7372 - val_loss: 0.1907 - val_accuracy: 0.7270\n",
      "Epoch 145/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7327 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 146/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7348 - val_loss: 0.1905 - val_accuracy: 0.7293\n",
      "Epoch 147/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7354 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 148/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7358 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 149/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7422 - val_loss: 0.1905 - val_accuracy: 0.7292\n",
      "Epoch 150/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7407 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 151/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7416 - val_loss: 0.1911 - val_accuracy: 0.7264\n",
      "Epoch 152/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7404 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 153/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7323 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 154/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7425 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 155/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7323 - val_loss: 0.1909 - val_accuracy: 0.7274\n",
      "Epoch 156/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7380 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 157/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7399 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 158/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7307 - val_loss: 0.1905 - val_accuracy: 0.7294\n",
      "Epoch 159/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7344 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 160/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7413 - val_loss: 0.1908 - val_accuracy: 0.7278\n",
      "Epoch 161/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7383 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 162/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7363 - val_loss: 0.1908 - val_accuracy: 0.7282\n",
      "Epoch 163/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7385 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 164/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7388 - val_loss: 0.1906 - val_accuracy: 0.7287\n",
      "Epoch 165/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7429 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 166/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7346 - val_loss: 0.1904 - val_accuracy: 0.7294\n",
      "Epoch 167/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7447 - val_loss: 0.1913 - val_accuracy: 0.7271\n",
      "Epoch 168/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7350 - val_loss: 0.1906 - val_accuracy: 0.7285\n",
      "Epoch 169/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1886 - accuracy: 0.7312 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 170/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7356 - val_loss: 0.1906 - val_accuracy: 0.7285\n",
      "Epoch 171/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7384 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 172/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7329 - val_loss: 0.1905 - val_accuracy: 0.7276\n",
      "Epoch 173/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1870 - accuracy: 0.7319 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 174/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1823 - accuracy: 0.7424 - val_loss: 0.1908 - val_accuracy: 0.7279\n",
      "Epoch 175/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.7375 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 176/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.7374 - val_loss: 0.1909 - val_accuracy: 0.7273\n",
      "Epoch 177/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1867 - accuracy: 0.7315 - val_loss: 0.1906 - val_accuracy: 0.7277\n",
      "Epoch 178/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.7300 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 179/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.7458 - val_loss: 0.1906 - val_accuracy: 0.7285\n",
      "Epoch 180/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1853 - accuracy: 0.7327 - val_loss: 0.1906 - val_accuracy: 0.7279\n",
      "Epoch 181/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7389 - val_loss: 0.1909 - val_accuracy: 0.7272\n",
      "Epoch 182/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7397 - val_loss: 0.1909 - val_accuracy: 0.7269\n",
      "Epoch 183/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7404 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 184/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7383 - val_loss: 0.1904 - val_accuracy: 0.7276\n",
      "Epoch 185/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7397 - val_loss: 0.1904 - val_accuracy: 0.7274\n",
      "Epoch 186/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7373 - val_loss: 0.1903 - val_accuracy: 0.7275\n",
      "Epoch 187/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7420 - val_loss: 0.1901 - val_accuracy: 0.7280\n",
      "Epoch 188/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7375 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 189/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7375 - val_loss: 0.1904 - val_accuracy: 0.7268\n",
      "Epoch 190/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7384 - val_loss: 0.1901 - val_accuracy: 0.7290\n",
      "Epoch 191/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7408 - val_loss: 0.1906 - val_accuracy: 0.7269\n",
      "Epoch 192/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7415 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 193/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7384 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 194/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7370 - val_loss: 0.1905 - val_accuracy: 0.7272\n",
      "Epoch 195/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7431 - val_loss: 0.1903 - val_accuracy: 0.7274\n",
      "Epoch 196/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7402 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 197/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7325 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 198/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.7348 - val_loss: 0.1902 - val_accuracy: 0.7292\n",
      "Epoch 199/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7460 - val_loss: 0.1901 - val_accuracy: 0.7288\n",
      "Epoch 200/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7326 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 201/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7434 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 202/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7382 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 203/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7433 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 204/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7384 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 205/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1897 - accuracy: 0.7270 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 206/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7433 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 207/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.7374 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 208/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7473 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 209/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7397 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 210/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7354 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 211/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7420 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 212/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7341 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 213/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7414 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 214/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7365 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 215/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1849 - accuracy: 0.7354 - val_loss: 0.1906 - val_accuracy: 0.7272\n",
      "Epoch 216/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7402 - val_loss: 0.1910 - val_accuracy: 0.7263\n",
      "Epoch 217/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7374 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 218/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7432 - val_loss: 0.1907 - val_accuracy: 0.7275\n",
      "Epoch 219/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7301 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 220/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7414 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 221/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7413 - val_loss: 0.1902 - val_accuracy: 0.7292\n",
      "Epoch 222/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7376 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 223/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7414 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 224/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.7410 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 225/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7350 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 226/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7442 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 227/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7350 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 228/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7376 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 229/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7422 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 230/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7381 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 231/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7304 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 232/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7333 - val_loss: 0.1902 - val_accuracy: 0.7290\n",
      "Epoch 233/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7426 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 234/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7459 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 235/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7422 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 236/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7368 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 237/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7341 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 238/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7463 - val_loss: 0.1910 - val_accuracy: 0.7276\n",
      "Epoch 239/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7383 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 240/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7388 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 241/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7356 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 242/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.7374 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 243/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7366 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 244/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7359 - val_loss: 0.1901 - val_accuracy: 0.7290\n",
      "Epoch 245/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7406 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 246/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7379 - val_loss: 0.1903 - val_accuracy: 0.7276\n",
      "Epoch 247/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7413 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 248/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7374 - val_loss: 0.1900 - val_accuracy: 0.7292\n",
      "Epoch 249/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7411 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 250/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1872 - accuracy: 0.7330 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 251/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7401 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 252/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7380 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 253/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7377 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 254/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7362 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 255/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7326 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 256/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7412 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 257/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7329 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 258/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7279 - val_loss: 0.1905 - val_accuracy: 0.7276\n",
      "Epoch 259/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1820 - accuracy: 0.7435 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 260/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7375 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 261/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7380 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 262/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7428 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 263/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7354 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 264/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7373 - val_loss: 0.1905 - val_accuracy: 0.7277\n",
      "Epoch 265/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7416 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 266/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7382 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 267/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7422 - val_loss: 0.1901 - val_accuracy: 0.7292\n",
      "Epoch 268/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7382 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 269/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7346 - val_loss: 0.1908 - val_accuracy: 0.7274\n",
      "Epoch 270/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7391 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 271/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7352 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 272/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.7285 - val_loss: 0.1907 - val_accuracy: 0.7279\n",
      "Epoch 273/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7395 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 274/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7356 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 275/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7389 - val_loss: 0.1904 - val_accuracy: 0.7277\n",
      "Epoch 276/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7385 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 277/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.7302 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 278/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7447 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 279/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7360 - val_loss: 0.1903 - val_accuracy: 0.7288\n",
      "Epoch 280/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.7403 - val_loss: 0.1907 - val_accuracy: 0.7272\n",
      "Epoch 281/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.7324 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 282/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7359 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 283/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7355 - val_loss: 0.1906 - val_accuracy: 0.7276\n",
      "Epoch 284/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7310 - val_loss: 0.1902 - val_accuracy: 0.7290\n",
      "Epoch 285/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7363 - val_loss: 0.1900 - val_accuracy: 0.7295\n",
      "Epoch 286/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7382 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 287/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1860 - accuracy: 0.7332 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 288/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7398 - val_loss: 0.1901 - val_accuracy: 0.7290\n",
      "Epoch 289/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.7354 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 290/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7307 - val_loss: 0.1905 - val_accuracy: 0.7288\n",
      "Epoch 291/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7446 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 292/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7376 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 293/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7450 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 294/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7321 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 295/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7389 - val_loss: 0.1903 - val_accuracy: 0.7276\n",
      "Epoch 296/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7422 - val_loss: 0.1906 - val_accuracy: 0.7273\n",
      "Epoch 297/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7349 - val_loss: 0.1902 - val_accuracy: 0.7293\n",
      "Epoch 298/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7417 - val_loss: 0.1905 - val_accuracy: 0.7293\n",
      "Epoch 299/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7403 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 300/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7343 - val_loss: 0.1902 - val_accuracy: 0.7288\n",
      "Epoch 301/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7405 - val_loss: 0.1905 - val_accuracy: 0.7274\n",
      "Epoch 302/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.7470 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 303/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1853 - accuracy: 0.7330 - val_loss: 0.1907 - val_accuracy: 0.7283\n",
      "Epoch 304/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7289 - val_loss: 0.1909 - val_accuracy: 0.7278\n",
      "Epoch 305/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7426 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 306/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7371 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 307/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7377 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 308/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1798 - accuracy: 0.7488 - val_loss: 0.1906 - val_accuracy: 0.7278\n",
      "Epoch 309/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7318 - val_loss: 0.1902 - val_accuracy: 0.7288\n",
      "Epoch 310/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1827 - accuracy: 0.7436 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 311/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.7336 - val_loss: 0.1903 - val_accuracy: 0.7288\n",
      "Epoch 312/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.7278 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 313/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7434 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 314/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7385 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 315/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7397 - val_loss: 0.1906 - val_accuracy: 0.7287\n",
      "Epoch 316/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1809 - accuracy: 0.7452 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 317/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7357 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 318/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7347 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 319/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7333 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 320/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7415 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 321/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7394 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 322/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7363 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 323/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7446 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 324/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1850 - accuracy: 0.7389 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 325/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7362 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 326/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7328 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 327/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7353 - val_loss: 0.1905 - val_accuracy: 0.7290\n",
      "Epoch 328/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.7394 - val_loss: 0.1907 - val_accuracy: 0.7276\n",
      "Epoch 329/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1876 - accuracy: 0.7312 - val_loss: 0.1907 - val_accuracy: 0.7282\n",
      "Epoch 330/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7373 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 331/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7378 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 332/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1809 - accuracy: 0.7431 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 333/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7400 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 334/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7415 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 335/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7367 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 336/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7352 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 337/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7363 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 338/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7407 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 339/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7435 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 340/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1868 - accuracy: 0.7324 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 341/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7431 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 342/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7380 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 343/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.7391 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 344/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1801 - accuracy: 0.7461 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 345/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1826 - accuracy: 0.7381 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 346/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7398 - val_loss: 0.1902 - val_accuracy: 0.7293\n",
      "Epoch 347/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7368 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 348/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7428 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 349/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7354 - val_loss: 0.1906 - val_accuracy: 0.7276\n",
      "Epoch 350/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7346 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 351/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7380 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 352/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7461 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 353/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7362 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 354/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7363 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 355/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7483 - val_loss: 0.1905 - val_accuracy: 0.7290\n",
      "Epoch 356/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7356 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 357/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7333 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 358/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7404 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 359/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7451 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 360/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7396 - val_loss: 0.1905 - val_accuracy: 0.7291\n",
      "Epoch 361/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7327 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 362/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7338 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 363/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7363 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 364/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7413 - val_loss: 0.1903 - val_accuracy: 0.7293\n",
      "Epoch 365/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.7310 - val_loss: 0.1905 - val_accuracy: 0.7291\n",
      "Epoch 366/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7409 - val_loss: 0.1903 - val_accuracy: 0.7288\n",
      "Epoch 367/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7386 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 368/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7400 - val_loss: 0.1902 - val_accuracy: 0.7290\n",
      "Epoch 369/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7345 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 370/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7334 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 371/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7399 - val_loss: 0.1905 - val_accuracy: 0.7275\n",
      "Epoch 372/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7381 - val_loss: 0.1909 - val_accuracy: 0.7289\n",
      "Epoch 373/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7332 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 374/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7389 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 375/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7414 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 376/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7352 - val_loss: 0.1908 - val_accuracy: 0.7267\n",
      "Epoch 377/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7300 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 378/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7395 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 379/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7381 - val_loss: 0.1906 - val_accuracy: 0.7289\n",
      "Epoch 380/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7376 - val_loss: 0.1903 - val_accuracy: 0.7292\n",
      "Epoch 381/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7450 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 382/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7349 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 383/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.7455 - val_loss: 0.1906 - val_accuracy: 0.7276\n",
      "Epoch 384/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7431 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 385/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7358 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 386/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7439 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 387/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7452 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 388/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7392 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 389/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7399 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 390/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7375 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 391/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.7378 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 392/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7320 - val_loss: 0.1909 - val_accuracy: 0.7274\n",
      "Epoch 393/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7334 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 394/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7411 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 395/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7432 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 396/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7408 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 397/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7314 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 398/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7431 - val_loss: 0.1903 - val_accuracy: 0.7293\n",
      "Epoch 399/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7404 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 400/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7405 - val_loss: 0.1906 - val_accuracy: 0.7278\n",
      "Epoch 401/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7317 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 402/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7294 - val_loss: 0.1908 - val_accuracy: 0.7276\n",
      "Epoch 403/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7397 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 404/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7408 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 405/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7451 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 406/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7358 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 407/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7357 - val_loss: 0.1907 - val_accuracy: 0.7282\n",
      "Epoch 408/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1866 - accuracy: 0.7327 - val_loss: 0.1910 - val_accuracy: 0.7274\n",
      "Epoch 409/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7350 - val_loss: 0.1906 - val_accuracy: 0.7279\n",
      "Epoch 410/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7358 - val_loss: 0.1902 - val_accuracy: 0.7288\n",
      "Epoch 411/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1846 - accuracy: 0.7348 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 412/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7364 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 413/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7322 - val_loss: 0.1915 - val_accuracy: 0.7270\n",
      "Epoch 414/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7397 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 415/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7352 - val_loss: 0.1903 - val_accuracy: 0.7292\n",
      "Epoch 416/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7383 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 417/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7397 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 418/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7390 - val_loss: 0.1909 - val_accuracy: 0.7264\n",
      "Epoch 419/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7358 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 420/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7386 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 421/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7391 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 422/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7392 - val_loss: 0.1905 - val_accuracy: 0.7289\n",
      "Epoch 423/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7333 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 424/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7340 - val_loss: 0.1905 - val_accuracy: 0.7286\n",
      "Epoch 425/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7389 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 426/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7310 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 427/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7390 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 428/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7396 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 429/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7322 - val_loss: 0.1911 - val_accuracy: 0.7277\n",
      "Epoch 430/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7377 - val_loss: 0.1911 - val_accuracy: 0.7279\n",
      "Epoch 431/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7388 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 432/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.7329 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 433/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7363 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 434/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7413 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 435/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7355 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 436/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7304 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 437/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7334 - val_loss: 0.1907 - val_accuracy: 0.7287\n",
      "Epoch 438/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7417 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 439/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7317 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 440/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7429 - val_loss: 0.1909 - val_accuracy: 0.7278\n",
      "Epoch 441/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7450 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 442/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7401 - val_loss: 0.1910 - val_accuracy: 0.7276\n",
      "Epoch 443/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7348 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 444/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7422 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 445/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7396 - val_loss: 0.1909 - val_accuracy: 0.7276\n",
      "Epoch 446/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7326 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 447/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7478 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 448/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7433 - val_loss: 0.1907 - val_accuracy: 0.7272\n",
      "Epoch 449/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7383 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 450/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7330 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 451/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7414 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 452/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7390 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 453/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7420 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 454/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7344 - val_loss: 0.1904 - val_accuracy: 0.7279\n",
      "Epoch 455/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7426 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 456/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7372 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 457/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7347 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 458/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7394 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 459/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7403 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 460/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7412 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 461/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7379 - val_loss: 0.1906 - val_accuracy: 0.7275\n",
      "Epoch 462/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7374 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 463/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7326 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 464/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7327 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 465/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7412 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 466/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7402 - val_loss: 0.1904 - val_accuracy: 0.7276\n",
      "Epoch 467/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7415 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 468/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7370 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 469/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7382 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 470/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.7436 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 471/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7370 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 472/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1873 - accuracy: 0.7305 - val_loss: 0.1905 - val_accuracy: 0.7275\n",
      "Epoch 473/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.7469 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 474/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7442 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 475/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7391 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 476/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7372 - val_loss: 0.1903 - val_accuracy: 0.7277\n",
      "Epoch 477/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7361 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 478/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7419 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 479/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7378 - val_loss: 0.1902 - val_accuracy: 0.7281\n",
      "Epoch 480/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7313 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 481/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7433 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 482/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7376 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 483/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7352 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 484/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7321 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 485/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7319 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 486/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7392 - val_loss: 0.1907 - val_accuracy: 0.7279\n",
      "Epoch 487/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7382 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 488/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.7427 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 489/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.7400 - val_loss: 0.1902 - val_accuracy: 0.7288\n",
      "Epoch 490/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7381 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 491/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7404 - val_loss: 0.1907 - val_accuracy: 0.7286\n",
      "Epoch 492/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7408 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 493/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7364 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 494/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7355 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 495/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7390 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 496/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7380 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 497/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7427 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 498/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7392 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 499/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1891 - accuracy: 0.7279 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 500/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1878 - accuracy: 0.7307 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 501/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7420 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 502/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7428 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 503/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7387 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 504/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7367 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 505/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7362 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 506/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7365 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 507/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7382 - val_loss: 0.1909 - val_accuracy: 0.7272\n",
      "Epoch 508/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7384 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 509/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7425 - val_loss: 0.1905 - val_accuracy: 0.7288\n",
      "Epoch 510/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7398 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 511/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.7462 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 512/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7323 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 513/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7347 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 514/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7406 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 515/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7326 - val_loss: 0.1907 - val_accuracy: 0.7279\n",
      "Epoch 516/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7391 - val_loss: 0.1907 - val_accuracy: 0.7276\n",
      "Epoch 517/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7420 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 518/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1885 - accuracy: 0.7285 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 519/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7402 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 520/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7378 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 521/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7419 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 522/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7332 - val_loss: 0.1901 - val_accuracy: 0.7282\n",
      "Epoch 523/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7333 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 524/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7422 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 525/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7376 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 526/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7374 - val_loss: 0.1906 - val_accuracy: 0.7288\n",
      "Epoch 527/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7400 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 528/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7404 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 529/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.7428 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 530/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7401 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 531/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7350 - val_loss: 0.1903 - val_accuracy: 0.7276\n",
      "Epoch 532/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7439 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 533/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7407 - val_loss: 0.1904 - val_accuracy: 0.7275\n",
      "Epoch 534/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7407 - val_loss: 0.1906 - val_accuracy: 0.7278\n",
      "Epoch 535/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7379 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 536/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7387 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 537/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7350 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 538/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7418 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 539/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.7351 - val_loss: 0.1903 - val_accuracy: 0.7289\n",
      "Epoch 540/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7376 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 541/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1864 - accuracy: 0.7323 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 542/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7336 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 543/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7381 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 544/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7411 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 545/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7447 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 546/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7352 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 547/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7391 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 548/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7466 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 549/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7297 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 550/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7368 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 551/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7318 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 552/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7368 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 553/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.7428 - val_loss: 0.1919 - val_accuracy: 0.7250\n",
      "Epoch 554/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7414 - val_loss: 0.1906 - val_accuracy: 0.7284\n",
      "Epoch 555/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7376 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 556/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7350 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 557/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7392 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 558/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7431 - val_loss: 0.1904 - val_accuracy: 0.7273\n",
      "Epoch 559/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7340 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 560/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7394 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 561/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7394 - val_loss: 0.1906 - val_accuracy: 0.7276\n",
      "Epoch 562/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7414 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 563/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7449 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 564/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7406 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 565/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7391 - val_loss: 0.1911 - val_accuracy: 0.7270\n",
      "Epoch 566/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7408 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 567/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7386 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 568/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7361 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 569/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7376 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 570/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7422 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 571/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7398 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 572/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7394 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 573/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7420 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 574/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7408 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 575/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7430 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 576/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7376 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 577/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7350 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 578/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7363 - val_loss: 0.1908 - val_accuracy: 0.7276\n",
      "Epoch 579/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.7312 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 580/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7360 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 581/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7352 - val_loss: 0.1904 - val_accuracy: 0.7277\n",
      "Epoch 582/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7440 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 583/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7367 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 584/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7387 - val_loss: 0.1907 - val_accuracy: 0.7275\n",
      "Epoch 585/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7394 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 586/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7356 - val_loss: 0.1903 - val_accuracy: 0.7279\n",
      "Epoch 587/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7435 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 588/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7367 - val_loss: 0.1905 - val_accuracy: 0.7276\n",
      "Epoch 589/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7350 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 590/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7416 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 591/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7313 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 592/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7450 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 593/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7349 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 594/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7378 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 595/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7366 - val_loss: 0.1908 - val_accuracy: 0.7278\n",
      "Epoch 596/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7398 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 597/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7405 - val_loss: 0.1903 - val_accuracy: 0.7277\n",
      "Epoch 598/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7437 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 599/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7385 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 600/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7344 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 601/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7396 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 602/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7411 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 603/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1875 - accuracy: 0.7306 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 604/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7383 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 605/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7352 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 606/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7438 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 607/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7356 - val_loss: 0.1902 - val_accuracy: 0.7281\n",
      "Epoch 608/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1808 - accuracy: 0.7453 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 609/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1783 - accuracy: 0.7521 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 610/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7417 - val_loss: 0.1907 - val_accuracy: 0.7273\n",
      "Epoch 611/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7475 - val_loss: 0.1908 - val_accuracy: 0.7276\n",
      "Epoch 612/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7365 - val_loss: 0.1912 - val_accuracy: 0.7264\n",
      "Epoch 613/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7318 - val_loss: 0.1905 - val_accuracy: 0.7287\n",
      "Epoch 614/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7407 - val_loss: 0.1906 - val_accuracy: 0.7279\n",
      "Epoch 615/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7385 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 616/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1830 - accuracy: 0.7383 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 617/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.7355 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 618/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7401 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 619/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7343 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 620/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7411 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 621/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7337 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 622/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1811 - accuracy: 0.7412 - val_loss: 0.1903 - val_accuracy: 0.7287\n",
      "Epoch 623/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7398 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 624/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7421 - val_loss: 0.1905 - val_accuracy: 0.7273\n",
      "Epoch 625/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7425 - val_loss: 0.1905 - val_accuracy: 0.7290\n",
      "Epoch 626/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7393 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 627/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7381 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 628/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7371 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 629/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7421 - val_loss: 0.1906 - val_accuracy: 0.7283\n",
      "Epoch 630/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7357 - val_loss: 0.1903 - val_accuracy: 0.7286\n",
      "Epoch 631/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1869 - accuracy: 0.7315 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 632/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7383 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 633/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7356 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 634/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7440 - val_loss: 0.1905 - val_accuracy: 0.7283\n",
      "Epoch 635/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7340 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 636/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7348 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 637/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7337 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 638/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7391 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 639/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7418 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 640/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7417 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 641/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7422 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 642/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7418 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 643/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7414 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 644/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7411 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 645/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7436 - val_loss: 0.1906 - val_accuracy: 0.7271\n",
      "Epoch 646/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7372 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 647/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7334 - val_loss: 0.1914 - val_accuracy: 0.7257\n",
      "Epoch 648/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7430 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 649/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7355 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 650/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7329 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 651/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7356 - val_loss: 0.1907 - val_accuracy: 0.7272\n",
      "Epoch 652/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1858 - accuracy: 0.7351 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 653/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1802 - accuracy: 0.7422 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 654/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.7365 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 655/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7389 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 656/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7429 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 657/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1896 - accuracy: 0.7242 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 658/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7329 - val_loss: 0.1907 - val_accuracy: 0.7282\n",
      "Epoch 659/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7416 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 660/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1841 - accuracy: 0.7377 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 661/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1867 - accuracy: 0.7320 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 662/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7367 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 663/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7419 - val_loss: 0.1910 - val_accuracy: 0.7274\n",
      "Epoch 664/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7421 - val_loss: 0.1907 - val_accuracy: 0.7276\n",
      "Epoch 665/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7351 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 666/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7402 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 667/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7345 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 668/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7436 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 669/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7456 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 670/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7341 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 671/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7384 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 672/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1815 - accuracy: 0.7447 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 673/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.7418 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 674/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7394 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 675/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7428 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 676/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7398 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 677/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7471 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 678/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7432 - val_loss: 0.1908 - val_accuracy: 0.7280\n",
      "Epoch 679/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1832 - accuracy: 0.7374 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 680/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1799 - accuracy: 0.7483 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 681/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7369 - val_loss: 0.1903 - val_accuracy: 0.7277\n",
      "Epoch 682/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7384 - val_loss: 0.1901 - val_accuracy: 0.7282\n",
      "Epoch 683/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7428 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 684/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7411 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 685/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7370 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 686/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7389 - val_loss: 0.1905 - val_accuracy: 0.7275\n",
      "Epoch 687/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.7475 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 688/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1780 - accuracy: 0.7510 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 689/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.7401 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 690/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7411 - val_loss: 0.1915 - val_accuracy: 0.7261\n",
      "Epoch 691/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7363 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 692/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7436 - val_loss: 0.1905 - val_accuracy: 0.7285\n",
      "Epoch 693/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7400 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 694/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7390 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 695/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7378 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 696/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7420 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 697/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1858 - accuracy: 0.7341 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 698/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7380 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 699/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7413 - val_loss: 0.1906 - val_accuracy: 0.7281\n",
      "Epoch 700/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7450 - val_loss: 0.1908 - val_accuracy: 0.7265\n",
      "Epoch 701/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7334 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 702/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7324 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 703/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7321 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 704/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7408 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 705/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7374 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 706/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7342 - val_loss: 0.1905 - val_accuracy: 0.7276\n",
      "Epoch 707/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7392 - val_loss: 0.1904 - val_accuracy: 0.7279\n",
      "Epoch 708/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7415 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 709/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7410 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 710/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7383 - val_loss: 0.1905 - val_accuracy: 0.7284\n",
      "Epoch 711/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7392 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 712/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7376 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 713/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7394 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 714/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7452 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 715/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7359 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 716/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1812 - accuracy: 0.7436 - val_loss: 0.1903 - val_accuracy: 0.7274\n",
      "Epoch 717/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7406 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 718/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7397 - val_loss: 0.1901 - val_accuracy: 0.7279\n",
      "Epoch 719/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7430 - val_loss: 0.1903 - val_accuracy: 0.7275\n",
      "Epoch 720/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.7379 - val_loss: 0.1904 - val_accuracy: 0.7279\n",
      "Epoch 721/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7348 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 722/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1829 - accuracy: 0.7396 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 723/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7373 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 724/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7369 - val_loss: 0.1915 - val_accuracy: 0.7263\n",
      "Epoch 725/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7396 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 726/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7392 - val_loss: 0.1903 - val_accuracy: 0.7278\n",
      "Epoch 727/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7388 - val_loss: 0.1902 - val_accuracy: 0.7281\n",
      "Epoch 728/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7368 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 729/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7439 - val_loss: 0.1905 - val_accuracy: 0.7274\n",
      "Epoch 730/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7373 - val_loss: 0.1907 - val_accuracy: 0.7273\n",
      "Epoch 731/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7440 - val_loss: 0.1906 - val_accuracy: 0.7272\n",
      "Epoch 732/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7331 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 733/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7413 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 734/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7337 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 735/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1881 - accuracy: 0.7311 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 736/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1813 - accuracy: 0.7437 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 737/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7327 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 738/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7376 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 739/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7428 - val_loss: 0.1906 - val_accuracy: 0.7272\n",
      "Epoch 740/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7377 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 741/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7473 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 742/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1835 - accuracy: 0.7390 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 743/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7343 - val_loss: 0.1909 - val_accuracy: 0.7279\n",
      "Epoch 744/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7380 - val_loss: 0.1905 - val_accuracy: 0.7281\n",
      "Epoch 745/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1856 - accuracy: 0.7348 - val_loss: 0.1903 - val_accuracy: 0.7276\n",
      "Epoch 746/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7377 - val_loss: 0.1903 - val_accuracy: 0.7275\n",
      "Epoch 747/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7404 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 748/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1800 - accuracy: 0.7458 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 749/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7379 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 750/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7320 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 751/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7370 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 752/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7374 - val_loss: 0.1903 - val_accuracy: 0.7281\n",
      "Epoch 753/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7380 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 754/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7352 - val_loss: 0.1901 - val_accuracy: 0.7280\n",
      "Epoch 755/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7352 - val_loss: 0.1904 - val_accuracy: 0.7277\n",
      "Epoch 756/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7419 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 757/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.7385 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 758/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7402 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 759/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7345 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 760/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7421 - val_loss: 0.1909 - val_accuracy: 0.7274\n",
      "Epoch 761/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7440 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 762/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1790 - accuracy: 0.7474 - val_loss: 0.1903 - val_accuracy: 0.7276\n",
      "Epoch 763/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7410 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 764/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1828 - accuracy: 0.7432 - val_loss: 0.1904 - val_accuracy: 0.7276\n",
      "Epoch 765/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.7450 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 766/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7369 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 767/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7345 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 768/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1843 - accuracy: 0.7350 - val_loss: 0.1903 - val_accuracy: 0.7279\n",
      "Epoch 769/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7425 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 770/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7382 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 771/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7370 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 772/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.7447 - val_loss: 0.1907 - val_accuracy: 0.7280\n",
      "Epoch 773/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7327 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 774/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7324 - val_loss: 0.1901 - val_accuracy: 0.7281\n",
      "Epoch 775/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7383 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 776/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7339 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 777/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7367 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 778/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7410 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 779/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7334 - val_loss: 0.1906 - val_accuracy: 0.7274\n",
      "Epoch 780/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7384 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 781/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7412 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 782/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7404 - val_loss: 0.1903 - val_accuracy: 0.7277\n",
      "Epoch 783/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1793 - accuracy: 0.7494 - val_loss: 0.1905 - val_accuracy: 0.7279\n",
      "Epoch 784/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1835 - accuracy: 0.7368 - val_loss: 0.1907 - val_accuracy: 0.7278\n",
      "Epoch 785/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7406 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 786/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1848 - accuracy: 0.7366 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 787/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7389 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 788/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7385 - val_loss: 0.1904 - val_accuracy: 0.7281\n",
      "Epoch 789/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7339 - val_loss: 0.1909 - val_accuracy: 0.7269\n",
      "Epoch 790/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7405 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 791/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7358 - val_loss: 0.1905 - val_accuracy: 0.7278\n",
      "Epoch 792/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7398 - val_loss: 0.1903 - val_accuracy: 0.7288\n",
      "Epoch 793/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7407 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 794/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7383 - val_loss: 0.1909 - val_accuracy: 0.7263\n",
      "Epoch 795/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1833 - accuracy: 0.7375 - val_loss: 0.1905 - val_accuracy: 0.7282\n",
      "Epoch 796/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7378 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 797/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7317 - val_loss: 0.1908 - val_accuracy: 0.7276\n",
      "Epoch 798/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.7470 - val_loss: 0.1904 - val_accuracy: 0.7286\n",
      "Epoch 799/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1799 - accuracy: 0.7466 - val_loss: 0.1904 - val_accuracy: 0.7277\n",
      "Epoch 800/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7427 - val_loss: 0.1902 - val_accuracy: 0.7285\n",
      "Epoch 801/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7438 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 802/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7431 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 803/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1864 - accuracy: 0.7300 - val_loss: 0.1903 - val_accuracy: 0.7285\n",
      "Epoch 804/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1817 - accuracy: 0.7423 - val_loss: 0.1901 - val_accuracy: 0.7276\n",
      "Epoch 805/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7433 - val_loss: 0.1907 - val_accuracy: 0.7274\n",
      "Epoch 806/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1857 - accuracy: 0.7320 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 807/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1830 - accuracy: 0.7401 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 808/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7425 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 809/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7433 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 810/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1804 - accuracy: 0.7447 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 811/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7355 - val_loss: 0.1900 - val_accuracy: 0.7283\n",
      "Epoch 812/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7401 - val_loss: 0.1902 - val_accuracy: 0.7280\n",
      "Epoch 813/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7331 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 814/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1830 - accuracy: 0.7400 - val_loss: 0.1900 - val_accuracy: 0.7282\n",
      "Epoch 815/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7335 - val_loss: 0.1908 - val_accuracy: 0.7278\n",
      "Epoch 816/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7369 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 817/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7353 - val_loss: 0.1902 - val_accuracy: 0.7281\n",
      "Epoch 818/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7368 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 819/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7361 - val_loss: 0.1900 - val_accuracy: 0.7282\n",
      "Epoch 820/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7292 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 821/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1862 - accuracy: 0.7302 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 822/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7402 - val_loss: 0.1904 - val_accuracy: 0.7275\n",
      "Epoch 823/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7408 - val_loss: 0.1903 - val_accuracy: 0.7283\n",
      "Epoch 824/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7427 - val_loss: 0.1903 - val_accuracy: 0.7279\n",
      "Epoch 825/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7359 - val_loss: 0.1900 - val_accuracy: 0.7286\n",
      "Epoch 826/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1834 - accuracy: 0.7402 - val_loss: 0.1904 - val_accuracy: 0.7280\n",
      "Epoch 827/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7437 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 828/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.7347 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 829/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7343 - val_loss: 0.1903 - val_accuracy: 0.7284\n",
      "Epoch 830/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1820 - accuracy: 0.7421 - val_loss: 0.1902 - val_accuracy: 0.7279\n",
      "Epoch 831/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7380 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 832/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7404 - val_loss: 0.1903 - val_accuracy: 0.7279\n",
      "Epoch 833/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7338 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 834/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1804 - accuracy: 0.7431 - val_loss: 0.1904 - val_accuracy: 0.7284\n",
      "Epoch 835/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1845 - accuracy: 0.7362 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 836/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7364 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 837/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7406 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 838/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.7414 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 839/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7407 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 840/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7431 - val_loss: 0.1904 - val_accuracy: 0.7285\n",
      "Epoch 841/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7392 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 842/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7394 - val_loss: 0.1901 - val_accuracy: 0.7282\n",
      "Epoch 843/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1827 - accuracy: 0.7404 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 844/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1854 - accuracy: 0.7301 - val_loss: 0.1902 - val_accuracy: 0.7277\n",
      "Epoch 845/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7311 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 846/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1824 - accuracy: 0.7399 - val_loss: 0.1904 - val_accuracy: 0.7278\n",
      "Epoch 847/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1803 - accuracy: 0.7453 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 848/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7370 - val_loss: 0.1900 - val_accuracy: 0.7283\n",
      "Epoch 849/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7344 - val_loss: 0.1900 - val_accuracy: 0.7282\n",
      "Epoch 850/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.7326 - val_loss: 0.1903 - val_accuracy: 0.7282\n",
      "Epoch 851/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1824 - accuracy: 0.7398 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 852/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7411 - val_loss: 0.1901 - val_accuracy: 0.7283\n",
      "Epoch 853/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1856 - accuracy: 0.7318 - val_loss: 0.1900 - val_accuracy: 0.7282\n",
      "Epoch 854/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7316 - val_loss: 0.1900 - val_accuracy: 0.7286\n",
      "Epoch 855/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1842 - accuracy: 0.7386 - val_loss: 0.1905 - val_accuracy: 0.7280\n",
      "Epoch 856/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7413 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 857/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.7312 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 858/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7424 - val_loss: 0.1904 - val_accuracy: 0.7292\n",
      "Epoch 859/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7352 - val_loss: 0.1902 - val_accuracy: 0.7292\n",
      "Epoch 860/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7436 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 861/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1855 - accuracy: 0.7329 - val_loss: 0.1900 - val_accuracy: 0.7280\n",
      "Epoch 862/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7361 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 863/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1786 - accuracy: 0.7494 - val_loss: 0.1901 - val_accuracy: 0.7294\n",
      "Epoch 864/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1849 - accuracy: 0.7355 - val_loss: 0.1906 - val_accuracy: 0.7280\n",
      "Epoch 865/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7348 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 866/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1838 - accuracy: 0.7355 - val_loss: 0.1903 - val_accuracy: 0.7280\n",
      "Epoch 867/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7393 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 868/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1851 - accuracy: 0.7318 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 869/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7370 - val_loss: 0.1901 - val_accuracy: 0.7282\n",
      "Epoch 870/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7445 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 871/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7341 - val_loss: 0.1900 - val_accuracy: 0.7282\n",
      "Epoch 872/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7395 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 873/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7495 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 874/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1826 - accuracy: 0.7431 - val_loss: 0.1902 - val_accuracy: 0.7283\n",
      "Epoch 875/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7382 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 876/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7322 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 877/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7273 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 878/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.7499 - val_loss: 0.1902 - val_accuracy: 0.7284\n",
      "Epoch 879/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.7461 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 880/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.7460 - val_loss: 0.1901 - val_accuracy: 0.7292\n",
      "Epoch 881/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1854 - accuracy: 0.7342 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 882/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7373 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 883/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7405 - val_loss: 0.1910 - val_accuracy: 0.7282\n",
      "Epoch 884/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7396 - val_loss: 0.1900 - val_accuracy: 0.7287\n",
      "Epoch 885/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7437 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 886/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7409 - val_loss: 0.1899 - val_accuracy: 0.7289\n",
      "Epoch 887/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1817 - accuracy: 0.7440 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 888/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7433 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 889/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7354 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 890/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7358 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 891/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7441 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 892/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1849 - accuracy: 0.7363 - val_loss: 0.1900 - val_accuracy: 0.7280\n",
      "Epoch 893/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7410 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 894/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.7405 - val_loss: 0.1900 - val_accuracy: 0.7287\n",
      "Epoch 895/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7381 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 896/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7445 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 897/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1798 - accuracy: 0.7451 - val_loss: 0.1899 - val_accuracy: 0.7287\n",
      "Epoch 898/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1844 - accuracy: 0.7397 - val_loss: 0.1905 - val_accuracy: 0.7290\n",
      "Epoch 899/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.7428 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 900/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1794 - accuracy: 0.7474 - val_loss: 0.1902 - val_accuracy: 0.7278\n",
      "Epoch 901/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.7339 - val_loss: 0.1900 - val_accuracy: 0.7288\n",
      "Epoch 902/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.7407 - val_loss: 0.1898 - val_accuracy: 0.7286\n",
      "Epoch 903/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1829 - accuracy: 0.7376 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 904/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7383 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 905/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1806 - accuracy: 0.7413 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 906/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7377 - val_loss: 0.1899 - val_accuracy: 0.7284\n",
      "Epoch 907/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7353 - val_loss: 0.1904 - val_accuracy: 0.7283\n",
      "Epoch 908/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7388 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 909/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1823 - accuracy: 0.7391 - val_loss: 0.1899 - val_accuracy: 0.7295\n",
      "Epoch 910/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1848 - accuracy: 0.7367 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 911/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1818 - accuracy: 0.7409 - val_loss: 0.1900 - val_accuracy: 0.7292\n",
      "Epoch 912/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7343 - val_loss: 0.1900 - val_accuracy: 0.7292\n",
      "Epoch 913/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1831 - accuracy: 0.7390 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 914/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7379 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 915/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1828 - accuracy: 0.7365 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 916/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1796 - accuracy: 0.7448 - val_loss: 0.1900 - val_accuracy: 0.7286\n",
      "Epoch 917/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1806 - accuracy: 0.7432 - val_loss: 0.1900 - val_accuracy: 0.7283\n",
      "Epoch 918/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7409 - val_loss: 0.1899 - val_accuracy: 0.7293\n",
      "Epoch 919/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1840 - accuracy: 0.7373 - val_loss: 0.1899 - val_accuracy: 0.7291\n",
      "Epoch 920/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7492 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 921/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7429 - val_loss: 0.1903 - val_accuracy: 0.7290\n",
      "Epoch 922/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1834 - accuracy: 0.7358 - val_loss: 0.1900 - val_accuracy: 0.7283\n",
      "Epoch 923/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1852 - accuracy: 0.7359 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 924/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1841 - accuracy: 0.7373 - val_loss: 0.1899 - val_accuracy: 0.7287\n",
      "Epoch 925/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1787 - accuracy: 0.7441 - val_loss: 0.1899 - val_accuracy: 0.7290\n",
      "Epoch 926/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1811 - accuracy: 0.7415 - val_loss: 0.1904 - val_accuracy: 0.7290\n",
      "Epoch 927/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7375 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 928/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1825 - accuracy: 0.7404 - val_loss: 0.1901 - val_accuracy: 0.7296\n",
      "Epoch 929/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7403 - val_loss: 0.1902 - val_accuracy: 0.7282\n",
      "Epoch 930/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7445 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 931/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7415 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 932/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1832 - accuracy: 0.7382 - val_loss: 0.1901 - val_accuracy: 0.7294\n",
      "Epoch 933/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1821 - accuracy: 0.7394 - val_loss: 0.1901 - val_accuracy: 0.7291\n",
      "Epoch 934/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7348 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 935/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7415 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 936/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1831 - accuracy: 0.7360 - val_loss: 0.1907 - val_accuracy: 0.7285\n",
      "Epoch 937/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1845 - accuracy: 0.7363 - val_loss: 0.1900 - val_accuracy: 0.7288\n",
      "Epoch 938/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7396 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 939/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1824 - accuracy: 0.7414 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 940/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7378 - val_loss: 0.1899 - val_accuracy: 0.7290\n",
      "Epoch 941/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1842 - accuracy: 0.7374 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 942/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.7454 - val_loss: 0.1901 - val_accuracy: 0.7288\n",
      "Epoch 943/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.7353 - val_loss: 0.1899 - val_accuracy: 0.7289\n",
      "Epoch 944/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1877 - accuracy: 0.7288 - val_loss: 0.1901 - val_accuracy: 0.7281\n",
      "Epoch 945/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7401 - val_loss: 0.1900 - val_accuracy: 0.7286\n",
      "Epoch 946/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.7410 - val_loss: 0.1901 - val_accuracy: 0.7288\n",
      "Epoch 947/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1839 - accuracy: 0.7364 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 948/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1837 - accuracy: 0.7358 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 949/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1860 - accuracy: 0.7323 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 950/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1836 - accuracy: 0.7331 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 951/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.7485 - val_loss: 0.1901 - val_accuracy: 0.7284\n",
      "Epoch 952/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1847 - accuracy: 0.7360 - val_loss: 0.1900 - val_accuracy: 0.7284\n",
      "Epoch 953/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1815 - accuracy: 0.7432 - val_loss: 0.1900 - val_accuracy: 0.7287\n",
      "Epoch 954/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1813 - accuracy: 0.7430 - val_loss: 0.1903 - val_accuracy: 0.7291\n",
      "Epoch 955/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1833 - accuracy: 0.7366 - val_loss: 0.1900 - val_accuracy: 0.7287\n",
      "Epoch 956/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1838 - accuracy: 0.7364 - val_loss: 0.1899 - val_accuracy: 0.7285\n",
      "Epoch 957/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1822 - accuracy: 0.7392 - val_loss: 0.1901 - val_accuracy: 0.7286\n",
      "Epoch 958/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1874 - accuracy: 0.7284 - val_loss: 0.1906 - val_accuracy: 0.7282\n",
      "Epoch 959/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1803 - accuracy: 0.7434 - val_loss: 0.1900 - val_accuracy: 0.7285\n",
      "Epoch 960/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1797 - accuracy: 0.7461 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 961/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7360 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 962/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1802 - accuracy: 0.7432 - val_loss: 0.1902 - val_accuracy: 0.7297\n",
      "Epoch 963/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1868 - accuracy: 0.7294 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 964/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1875 - accuracy: 0.7298 - val_loss: 0.1902 - val_accuracy: 0.7289\n",
      "Epoch 965/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1794 - accuracy: 0.7458 - val_loss: 0.1904 - val_accuracy: 0.7288\n",
      "Epoch 966/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1819 - accuracy: 0.7433 - val_loss: 0.1900 - val_accuracy: 0.7288\n",
      "Epoch 967/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.7410 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 968/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1847 - accuracy: 0.7360 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 969/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1846 - accuracy: 0.7348 - val_loss: 0.1899 - val_accuracy: 0.7284\n",
      "Epoch 970/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7419 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 971/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.7333 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 972/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1810 - accuracy: 0.7428 - val_loss: 0.1900 - val_accuracy: 0.7291\n",
      "Epoch 973/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7417 - val_loss: 0.1904 - val_accuracy: 0.7287\n",
      "Epoch 974/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1853 - accuracy: 0.7332 - val_loss: 0.1900 - val_accuracy: 0.7292\n",
      "Epoch 975/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7391 - val_loss: 0.1902 - val_accuracy: 0.7290\n",
      "Epoch 976/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1825 - accuracy: 0.7387 - val_loss: 0.1899 - val_accuracy: 0.7289\n",
      "Epoch 977/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1840 - accuracy: 0.7371 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 978/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7413 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 979/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1822 - accuracy: 0.7412 - val_loss: 0.1899 - val_accuracy: 0.7287\n",
      "Epoch 980/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1842 - accuracy: 0.7405 - val_loss: 0.1902 - val_accuracy: 0.7287\n",
      "Epoch 981/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1805 - accuracy: 0.7431 - val_loss: 0.1901 - val_accuracy: 0.7286\n",
      "Epoch 982/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7410 - val_loss: 0.1904 - val_accuracy: 0.7291\n",
      "Epoch 983/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7393 - val_loss: 0.1904 - val_accuracy: 0.7289\n",
      "Epoch 984/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.7466 - val_loss: 0.1902 - val_accuracy: 0.7286\n",
      "Epoch 985/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1785 - accuracy: 0.7481 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 986/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1844 - accuracy: 0.7353 - val_loss: 0.1900 - val_accuracy: 0.7289\n",
      "Epoch 987/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1790 - accuracy: 0.7486 - val_loss: 0.1899 - val_accuracy: 0.7286\n",
      "Epoch 988/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1819 - accuracy: 0.7418 - val_loss: 0.1902 - val_accuracy: 0.7296\n",
      "Epoch 989/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1835 - accuracy: 0.7381 - val_loss: 0.1899 - val_accuracy: 0.7291\n",
      "Epoch 990/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1839 - accuracy: 0.7366 - val_loss: 0.1904 - val_accuracy: 0.7282\n",
      "Epoch 991/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1839 - accuracy: 0.7339 - val_loss: 0.1901 - val_accuracy: 0.7289\n",
      "Epoch 992/1000\n",
      "322/322 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.7345 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 993/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1807 - accuracy: 0.7439 - val_loss: 0.1901 - val_accuracy: 0.7285\n",
      "Epoch 994/1000\n",
      "322/322 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.7312 - val_loss: 0.1901 - val_accuracy: 0.7287\n",
      "Epoch 995/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1829 - accuracy: 0.7413 - val_loss: 0.1902 - val_accuracy: 0.7291\n",
      "Epoch 996/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1843 - accuracy: 0.7359 - val_loss: 0.1898 - val_accuracy: 0.7291\n",
      "Epoch 997/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1850 - accuracy: 0.7357 - val_loss: 0.1901 - val_accuracy: 0.7293\n",
      "Epoch 998/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1827 - accuracy: 0.7398 - val_loss: 0.1899 - val_accuracy: 0.7290\n",
      "Epoch 999/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1838 - accuracy: 0.7327 - val_loss: 0.1900 - val_accuracy: 0.7290\n",
      "Epoch 1000/1000\n",
      "322/322 [==============================] - 0s 1ms/step - loss: 0.1818 - accuracy: 0.7407 - val_loss: 0.1899 - val_accuracy: 0.7289\n"
     ]
    }
   ],
   "source": [
    "# Fit the model using 50 epochs and the training data\n",
    "fit_model_A24 = nn_A24.fit(X_train_scaled, y_train, validation_split=0.6, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 9 Results\n",
      "Loss: 0.18881872296333313, Accuracy: 0.7272303104400635\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 24 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A24.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### Step 2: After completing your models, display the accuracy scores achieved by each model, and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 5 Results\n",
      "Loss: 0.19056975841522217, Accuracy: 0.7264139652252197\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 20 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A20.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 6 Results\n",
      "Loss: 0.21291719377040863, Accuracy: 0.7204664945602417\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 21 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A21.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 7 Results\n",
      "Loss: 0.1975753903388977, Accuracy: 0.7243148684501648\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 22 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A22.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 8 Results\n",
      "Loss: 0.19754020869731903, Accuracy: 0.7290962338447571\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 23 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A23.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alternative Model 9 Results\n",
      "Loss: 0.18881872296333313, Accuracy: 0.7272303104400635\n"
     ]
    }
   ],
   "source": [
    "print(\"Alternative Model 24 Results\")\n",
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy = nn_A24.evaluate(X_test_scaled,y_test,verbose=0)\n",
    "# Display the model loss and accuracy results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2(b): Plot and Compare the Results of each Alternative Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAB14UlEQVR4nO2dd3yURfrAv7M1vRdCCoTeQm8qVVTAhl1sPwuIvZwVPc87z3KeZ1c8xHo2sCBILyJI772FGiAhJCG9b5vfH+9mSdmQDSQkLPP9fPaz+05535nd5JlnnnnmGSGlRKFQKBTei66pG6BQKBSKxkUJeoVCofBylKBXKBQKL0cJeoVCofBylKBXKBQKL0cJeoVCofBylKBXnBYhRIoQ4rJz/EwhhPhKCJErhFh/jp89Xwhx97l8ZkMihBgshEhu6LKK8xuh/OgVp0MIkQKMl1L+fg6fORiYCnSUUhY34nP+AbSTUt7ZWM/wsB0vAi86Lw2AESh1Xh+RUnZtkoYpvAal0SuaI62AlMYU8s0JKeUbUsoAKWUA8CCwpuK6spB3znTU/6yi3qg/GoXHCCHMQoj3hRDHna/3hRBmZ16EEGKOECJPCJEjhFhRIZSEEM8LIdKEEIVCiGQhxIjTPGMc8DlwkRCiSAjxihDiHiHEymrlpBCinfPz10KISUKIuc5nrBNCtK1UtqsQYrGzXRlCiBeFEKPQtOhbnc/Z5iy7TAgx3vlZJ4R4SQhxRAiRKYT4RggR7Mxr7WzD3UKIo0KIk0KIvzbk912pPa8LIVYBJUAbIcS9Qog9zr4eEkI8UKn8MCFEaqXrFCHEM0KI7UKIfCHEj0IIn/qWdeY/J4RId/724yv/BormjRL0ivrwV2Ag0BPoAfQHXnLmPQ2kApFANJoQlUKIjsCjQD8pZSAwEkip7QFSyi+oqtX+3cO23Qa8AoQCB4DXAYQQgcDvwAKgJdAOWCKlXAC8AfzofE4PN/e8x/kaDrQBAoCPq5UZBHQERgAvCyE6e9je+nAXMAEIBI4AmcDVQBBwL/CeEKL3aerfAowCEoHuaH2qV1nnwPgUcBnadzj0TDujOPcoQa+oD3cA/5RSZkops9AE613OPCsQA7SSUlqllCuktgBkB8xAFyGEUUqZIqU82Aht+1VKuV5KaQO+RxuMQBOIJ6SU70gpy6SUhVLKdR7e8w7gXSnlISllEfACMFYIYahU5hUpZamUchuwDW0AbGi+llLuklLanN/tXCnlQanxJ7AIGHya+h9KKY9LKXOA2Zz6bupT9hbgK2c7StB+e8V5ghL0ivrQEk2jrOCIMw3gP2ia9CKnOWEigJTyAPAk8A8gUwgxTQjRkobnRKXPJWjaN0A8cKYDi7v+GtBmLHU914UQIsFpHioSQhSdQTuOVbvfaCHEWqcpKg+4Eog4Tf062+hB2ZbV2lGlTYrmjRL0ivpwHG2htIIEZxpOTflpKWUb4BrgqQpbvJTyBynlIGddCfy7ns8tBvwqLoQQLepR9xjQtpa8ulzO3PXXBmTU4/lIKY9WWlw9nZCt9RYVH5xrItOBt4FoKWUIMA8QZ3Df+pAOxFW6jm/k5ykaECXoFfVhKvCSECJSCBEBvAx8ByCEuFoI0U4IIYACNJONXQjRUQhxqVNAlaG5Ddrr+dxtQFchRE/n4uA/6lF3DtBCCPGkczE5UAgxwJmXAbQ+jSfLVOAvQohEIUQAp2z6tnq2vyExoZnCsgCbEGI0cMU5eO5PwL1CiM5CCD+0315xnqAEvaI+vAZsBLYDO4DNzjSA9miLnkXAGuATKeUyNKH0JnASzSwQxSmfcY+QUu4D/um8/35g5elrVKlbCFyONss44aw/3Jn9s/M9Wwix2U31L4FvgeXAYbSB6rH6tL2hcfbncTTBmwvcDsw6B8+dD3wILEUz0a1xZpU39rMVZ4/aMKVQKOqN07toJ2Bu4hmOwgOURq9QKDxCCHG9EMIkhAhFW2eZrYT8+YES9IomQWgxZYrcvOpl1lGcUx5AWxs4iLbO8lDTNkfhKcp0o1AoFF6O0ugVCoXCyzHUXeTcExERIVu3bt3UzVAoFIrzhk2bNp2UUka6y2uWgr5169Zs3LixqZuhUCgU5w1CiCO15SnTjUKhUHg5StArFAqFl6MEvUKhUHg5zdJGr1AomgdWq5XU1FTKysqauikKJz4+PsTFxWE0Gj2uowS9QqGoldTUVAIDA2ndujVavDpFUyKlJDs7m9TUVBITEz2up0w3CoWiVsrKyggPD1dCvpkghCA8PLzeMyyPBL0QYpTQzvo8UHGgRLX8O5znTG4XQqwWQvSolJcihNghhNgqhFA+kwrFeYYS8s2LM/k96jTdCCH0wCS0UK+pwAYhxCwp5e5KxQ4DQ6WUuc742FOAAZXyh0spT9a7dfXA4ZBsXniEqFaBJHQJb8xHKRQKxXmFJxp9f+CA89xMCzANGFO5gJRytZQy13m5lqon0ZwTdDrB1sVHSdnWqOOJQqE4x7Ru3ZqkpCR69uxJ3759z+geWVlZGI1GPv30U7f3TkpKokuXLrz00kuUl1cNsf/EE08QGxuLw+FwpX399dcIIViyZIkrbcaMGQgh+OWXX86ojY2JJ4I+lqrnQ6Y602pjHDC/0rVEO0d0kxBiQm2VhBAThBAbhRAbs7KyPGhWVRwWC36imNyDx0EFalMovIqlS5eydevWM94x//PPPzNw4ECmTp3q9t47duxg/fr1HDp0iAkTTokph8PBjBkziI+PZ/ny5VXqJSUlVbnftGnT6NGjMc6GP3s88bpxZxByK0mFEMPRBP2gSsmXSCmPCyGigMVCiL1SyuXV60opp6CZfOjbt2+9JbUQAuPRXeTlxsA/w8EvDPzCwTfM+bnydbjzVZEWCj4hoFNr0wqFNzJ16lTeeecdbr/9dtLS0oiNramrBgQEMHnyZOLj48nJySEsLIylS5fSrVs3br31VqZOncqwYcNc5QcPHsyKFSuwWq2Ul5dz4MABevbsee46VQ88EfSpVD0IOA7ngdCVEUJ0Bz4HRkspsyvSpZQVh0dnCiFmoJmCagj6s0UYDERGSXbZY8iJupewODuU5kBJDuQchtSNUJINDmstN9BVGhTCwT8SAqK1V2D0qc8B0VqeXnmmKi4sXpm9i93HCxr0nl1aBvH3a7qetowQgiuuuAIhBA888EAVjdsTjh07xokTJ+jfvz+33HILP/74I0899ZTbskFBQSQmJrJ//34GDBjA1KlTue222xgzZgwvvvgiVqvV5b8uhOCyyy5j4cKF5Ofnc+2113L48OF6te1c4Ym02gC0F0IkAmnAWLRzKl0IIRKAX4G7nOd7VqT7AzopZaHz8xVoZ382PELQ6dG72PXBbrbMlwyZMhFjixZVy0gJliJN4Jc4B4GSbOeAkF0pPRtO7oPDy6Esz93DwD+iqvAPiIKgWAiJh+B47d0nuFG6qlBcSKxatYqWLVuSmZnJ5ZdfTqdOnRgyZIjH9adNm8Ytt9wCwNixYxk3blytgh40X3UAi8XCvHnzeO+99wgMDGTAgAEsWrSIq666ylV27NixfPjhh+Tn5/POO+/wxhtvnGEvG5c6Bb2U0iaEeBRYCOiBL6WUu4QQDzrzJ6OdCB8OfOJ0/bFJKfsC0cAMZ5oB+EFKuaBRegJEd4omLHI/Jwq6kPrwI7T6/jt0vr6nCggB5kDtFdras5vayqEoA4oytffCE87PzvfCE5CVrOVVny2Yg6sK/uB4CGsD4e0gLBEM5gbru0LR2NSleTcWLVu2BCAqKorrr7+e9evXVxH0drudPn36AHDttdfyz39W1SWnTp1KRkYG33//PQDHjx9n//79tG/fvsazCgsLSUlJoUOHDixYsID8/HySkpIAKCkpwc/Pr4qg79+/Pzt37sTX15cOHTo0bMcbEI/sD1LKecC8ammTK30eD4x3U+8QcM5WJ4QQxHSKZH++ldLFe0h/6W+0fPs/Z+cHbDBDSIL2Oh0OBxRnQf4xyDvqfD926vrIKiivNO0VOk3wR7TXBH94OwhvC1FdtBmC8l1WKCguLsbhcBAYGEhxcTGLFi3i5ZdfrlJGr9ezdetWt/WTk5MpLi4mLS3Nlfb3v/+dadOm8be//a1K2aKiIh5++GGuu+46QkNDmTp1Kp9//jm33Xabqy2JiYmUlJRUqfevf/0LHx+fBuht4+F1hubQFv5YLBD08F8omPQugSMuJejKKxv/wTqdZssPjIa4WlzASnMh5xBkH4TsA6deR9dqJqUKfMMguqv2iurifO8MJv/G74dC0YzIyMjg+uuvB8Bms3H77bczatQoj+tPnTrVVb+CG2+8kbFjx7oE/fDhw5FS4nA4uP766/nb3/5GSUkJCxcurOKO6e/vz6BBg5g9e3aV+40ePfpMu3fOaJZnxvbt21eeqRvVsd05zPpwK2Me7471H49gPXKExFm/YYyObuBWNiBSaqafk/sgcw9k7NJemXvAWuwsJDStP7Y3tOwNsX2gRRIYm7cmoTi/2bNnD507d27qZiiq4e53EUJscprMa+B1Gn1ICz8A8rPLaffvNzl8w40cf34iCV9+gWiu7pNCQGAL7ZVYaZHJ4YC8FMjYrQn+9G1w6E/Y/qOWrzNoGn/CQGh1MSRcrM0oFAqFohJeJ+j9g00InaAotxzz4Da0+OuLpL/0N3K+/JLw8TWWEZo3Op22eBvWBjpffSq94DikbYK0zZC2EbZ8B+unaHlhbTWhnzgE2l6qeQcpFIoLGq8T9Dq9Dv9gE4U5WnS34BtvpGjFSjLf/wC/AQPxTerWxC1sAIJaaq/O12jXdiukb9cWfI+shj2zYcu3gICYHtDuMmg3AuL6gd7zGNYKhcI78DpBDxAY5kORU9ALIYj55yuUbNhA9pRPifvooyZuXSOgN0JcH+11yePgsEP6VjjwBxz4HVa+ByveBnOQpul3ugo6jtZ2BCsUCq/HKwV9QKiZjCOFrmt9cDBBV11F3o8/Yi8qQh8Q0IStOwfo9NpibWwfGPoslObB4T/hwBLYvxj2ztHs+4lDoPO10OlqCIhs6lYrFIpGopmuTp4dAaE+FOWWUdmjyP/ii5AWC+X79zdhy5oI3xDoMgau/RCe2g3j/4CLHtFCQ8x5Et7pAN/dCDt+AUtJXXdTKBTnGV4p6H0DTThsEmu53ZVmdAYxsh6vEabnwkIIzcRz+T/h8S3w4EoY9Bdtd+/0cfB2B/jtEUhZpaKAKpoFeXl53HTTTXTq1InOnTuzZs2aet/jTMIUp6Sk4OvrS8+ePV2vb775xlXv5EktJPr1119Pz549adeuHcHBwa6yq1evBqBHjx6uTVdNhVeabnwCtG6VFVkx+WifjS2VoK+BEJovfoskGP4SHFkJ26bBrpmaJ09EB+h7H/QYq+z5iibjiSeeYNSoUfzyyy9YLJYaO1M9oXKY4gceeKBK3tKlS4mIiKCoqIgJEyYwYcIE/ve//wHQtm3bWnfdVjBjxgwAli1bxttvv82cOXNceXv27MHhcLB8+XKKi4vx92+aTY9eqdH7+GueJWXFp2LP6AP80QUHY0tPb6pmNW90Os1mf90n8Mw+GPOJFpRtwUR4pxPMfBhSNyktX3FOKSgoYPny5YwbNw4Ak8lESEhIve9TEaY4NTW1SjiEylSEKZ45cyY5OTln02wXP/zwA3fddRdXXHEFs2bNapB7ngneqdFXCPqiqkHGjC1bYk1TGn2dmPyh1x3aK30bbPwKtv8EW7/XFngveUJbwNXpm7qlinPJ/IlwYkfD3rNFEox+s9bsQ4cOERkZyb333su2bdvo06cPH3zwQb004zMNUxwdHc3BgwerxJj/6KOPGDx4sMfP/vHHH1m8eDHJycl8/PHHTWbC8U6NPkAT9KXVBX1MjDLd1JeYHnDN+/D0XrjybS2M80//Bx/30wYAa/1Oo1co6oPNZmPz5s089NBDbNmyBX9/f958s/aBwR3VwxS7O2WqMpWdOCpMNxWv+gj5DRs2EBkZSatWrRgxYgSbN28mNze37oqNgHdq9AE1TTegafQl69YhpVQn29cXnyDof79ms98zC1a+r3nsLH0DBj6k5ZkDm7qVisbkNJp3YxEXF0dcXBwDBgwA4Kabbqoh6BsrTHF+fv5ZtX3q1Kns3buX1q1bA5oZavr06Yxvgh36XqnRm/2MINybbhzFxTgKGvaUnAsKnR66Xg8TlsH/zYIW3WDJK/B+d21jVnlRnbdQKDylRYsWxMfHk5ycDMCSJUvo0qVLlTIVYYq3bt1aQ8hXDlOckpJCSkoKL7zwAtOmTavxrOphis8Gh8PBzz//zPbt213P/e233+qcTTQWXinodTqB2ddQU6OvcLGsZTFGUQ+EgDZD4a4Zml9+bG/4/R/wQQ9Y/ZHyx1c0GB999BF33HEH3bt3Z+vWrbz44ose160tTHFlgTt8+HC6detG//79SUhIqOKCWWGjr3h9+OGHrrzu3bu7ZhzVbf7Lly8nNja2ytm0Q4YMYffu3aQ3gUOI14UpruB/L64irkMoI+45NfqX7tpFyo03EfvRhwRdfvnZNlNRnWPrNVPOoaXgHwVDnoW+96r4OucxKkxx86S+YYq9UqMHMJr0WC32KmmmCo0+VWn0jUJ8f/i/mXDvAs0Hf/6z8MlA2DtXuWUqFE2IR4JeCDFKCJEshDgghJjoJv8OIcR252u1EKJHtXy9EGKLEGJO9bqNhcGkx2ZxVEnTBQejCwjAmpp6rppxYdLqIrhnDtz2o3Zk4rTb4eurtbDKCoXinFOnoBdC6IFJwGigC3CbEKJLtWKHgaFSyu7Aq8CUavlPAHvOvrmeYzDpqoRAAC2SpTEuTtnozwVCQMdR8NAauOodyNoLnw2H6fdrZ+kqFIpzhicafX/ggJTykJTSAkwDxlQuIKVcLaWscBBdC8RV5Akh4oCrgM8bpsmeYTTrsVUz3YC2IGtNUxr9OUNvgH7jtbg6g5/WXDMn9YdVH2px9BUKRaPjiaCPBSqrYKnOtNoYB8yvdP0+8BzgcFvaiRBighBioxBiY1ZWlgfNOj2ajb7mI01xsVjSjtMcF6G9Gp8gGPEyPLoBEofC4r/BlGHaAq5CoWhUPBH07nYWuZWSQojhaIL+eef11UCmlHJTXQ+RUk6RUvaVUvaNjDz72Oiajd69Ri9LSrA30Q61C56QBLhtKtz6PZTmwheXw+wntM8KhaJR8ETQpwLxla7jgBpxBIQQ3dHMM2OklNnO5EuAa4UQKWgmn0uFEN+dVYs9RG/SYbPW1OiNcZpVSS3INiFCaGfgPrIeLnoUNn8LH/WFbT8q7xxFFZKTk6v4sQcFBfH+++/X6x7Dhg2jY8eO9OjRg379+lWJRtm6desaYQ169uxJt27akaMlJSXccccdJCUl0a1bNwYNGkRRkbYpUK/Xu8refPPNrqialdOvueYa8vLyXPfetWsXl156KR06dKB9+/a8+uqrLuvC119/TWRkJD179qRLly589tln9fy2ascTQb8BaC+ESBRCmICxQJUwbEKIBOBX4C4p5b6KdCnlC1LKOClla2e9P6SUdzZY60+D3qDDYXMj6GOdgl4tyDY95gAY+bq2yza0FcyYAD/cAvnqt1FodOzY0bXrddOmTfj5+dXYAOUJ33//Pdu2bePhhx/m2WefrZJXWFjIsWOadXrPnqo+Ix988AHR0dHs2LGDnTt38sUXX2A0avtCfH192bp1Kzt37sRkMjF58uQa6WFhYUyaNAmA0tJSrr32WiZOnMi+ffvYtm0bq1ev5pNPPnE979Zbb2Xr1q0sW7aMF198kYyMjHr31R11CnoppQ14FFiI5jnzk5RylxDiQSHEg85iLwPhwCdCiK1CiLPb7dQA6A21aPROX3qL0uibDzHdYdxiGPVvSFmp+d5v+lpp94oqLFmyhLZt29KqVaszvsdFF11UI0xxRURL0HbSVo4wmZ6eXmV3a8eOHTGbzTXuO3jwYA4cOHDa5/3www9ccsklXHHFFQD4+fnx8ccfuw3SFhUVRdu2bTly5MgZ9LImHgU1k1LOA+ZVS5tc6fN44LSReqSUy4Bl9W7hGWIw6rDbHDUCmOkD/NGHhCiNvrmh08PAB6HDFTDrcc1uv2sGXPOhpu0rmpx/r/83e3P2Nug9O4V14vn+z3tUdtq0aWcd5nfBggVcd911VdJuuukm7rnnHp555hlmz57N999/z7fffgvAfffdxxVXXMEvv/zCiBEjuPvuu2sEQ7PZbMyfP59Ro0ZVSbfb7SxZssQVS3/Xrl2u4GsVtG3blqKiIgqqxd86dOgQhw4dol27dmfV3wq8MnolgN4gQILDIdHrq64nG2Nj1e7Y5kpYGy1Y2qavYPHL8N+L4YrXoM89mm1fcUFisViYNWsW//rXv86o/h133EFxcTF2u53Nm6tu3AsLCyM0NJRp06bRuXNn/Pz8XHk9e/bk0KFDLFq0iN9//51+/fqxZs0aOnfuTGlpqStW/eDBg10CvSI9JSWFPn36cLkz3MrpouZWpP/444+sXLkSs9nMp59+SlhY2Bn1tzpeK+h1Bs0qZbc60OurWqiMcXGUO6PhKZohOh30GwftL9fOr53zJOyZDWM+hqCWTd26CxZPNe/GYP78+fTu3Zvo6OgaeXWFKQbNRt+jRw8mTpzII488wq+//lol/9Zbb+WRRx7h66+/rlE3ICCAG264gRtuuAGdTse8efPo3LmzyxZfnYr0/Px8rr76aiZNmsTjjz9O165dWb58eZWyhw4dIiAggMDAQFc7Pv74Y0+/Fo/x2lg3eqegd9hq2nmNcbFYjx9HOk7r2q9oakIS4K7ftANPjq7RbPfbpinb/QVIddt5ZU4XprgyRqOR1157jbVr19ZYdL3++ut57rnnGDlyZJX0VatWuQ4LsVgs7N692+M1guDgYD788EPefvttrFYrd9xxBytXruT3338HNM3/8ccf57nnnvPofmeD1wt6u1vPm1ikxYIt6+S5bpaivuh02qEmD66EyE4w4wH48U4oymzqlinOESUlJSxevJgbbrjhrO/l6+vL008/zdtvv10lPTAwkOeffx6TyVQl/eDBgwwdOpSkpCR69epF3759ufHGGz1+Xq9evejRowfTpk3D19eX3377jddee42OHTuSlJREv379ePTRR8+6X3XhtWGK96xO549v9nDnqxcRHOlbJa9o+XKOTXiAVj/8gF/vXmf1HMU5xGGHNZPgj1e106yufh+6XNvUrfJqVJji5okKU+zEYDy9Rg+omDfnGzo9XPI4PLAcguPgp7tgxkNQdnZHvikU3o7XCvq6TDegdseet0R1hnG/awebbJ8G/70EDq9o6lYpFM0WrxX0OoPmruRO0Ot8fNBHRmBRvvTnLwYTXPoS3LdIO8Hqf9fAwr+CtaypW6ZQNDu8VtDrjRVeN+49a0wtlS+9VxDfT1uo7XsfrPlYi3mfvr2pW6VQNCu8V9C7/OjdLzarA0i8CJM/XP0u3PELlGTDZ5fCine0xVuFQuH9gt5Wi0ZvjI3Fmp6OtCth4DW0vxweXgudroIl/4SvRkP2waZulULR5HitoHd53bgJbAbapilsNmwNFB1O0UzwC4Obv4YbPtOOL/zvJbBuCqjNcect7733Hl27dqVbt27cdtttlJXVfx0mKysLo9HIp59+WiW9devWJCUlkZSURJcuXXjppZcoLy+vUuaJJ54gNjYWR7W/oe+++47u3bvTtWtXevTowfjx410hiU8XGrm2e1aEKe7Vqxft27dn5MiRrF69ut59dYfXCvrTed2AimLp1QgB3W/RtPvWl8D8Z+HbMZB3tKlbpqgnaWlpfPjhh2zcuJGdO3dit9uZNm1ave/z888/M3DgQKZOnVojb+nSpezYsYP169dz6NAhJkyY4MpzOBzMmDGD+Pj4KuELFixYwHvvvcf8+fPZtWsXmzdv5uKLL64SVri20Mi13RO0EAhbtmxh//79TJw4kRtuuKHGLt4zwWsF/em8bgBMrgNIlJ3eawlqqdntr/kA0jbDJxdrh5w0w02Citqx2WyUlpZis9koKSmhZcv6xzuaOnUq77zzDqmpqTXCFFcQEBDA5MmTmTlzJjk5OYA2CHTr1o2HHnqoyiDx+uuv8/bbb7tCGOv1eu677z46duxY477VQyPXds/qDB8+nAkTJjBlypR697c6XhvU7FSsm1o0+pgYEEItyHo7QmiRL9sMg5mPwKxHtQBp134IgS2aunXnFSfeeIPyPQ0bptjcuRMtXnyx1vzY2FieeeYZEhIS8PX15YorrnDFc/eUY8eOceLECfr37++KPf/UU0+5LRsUFERiYiL79+9nwIABrhg7Y8aM4cUXX8RqtWI0Gtm1axe9e/f26PnVQyPXdk939O7du4a56UzwWo3+lOnGvfYmTCYM0dFq09SFQmhruHs2jHoTDv8JkwbAjl+Udt/Myc3N5bfffuPw4cMcP36c4uJivvuufqeRTps2jVtuuQWAsWPHnlaLBlxH+1ksFubNm8d1111HUFAQAwYMYNGiRTXK79ixg549e9K2bVvXASaghUaOi4vj3//+N4899li97lm9LWeL92r0zsVYm7V2rxpjXKzS6C8kdDoY+BC0uwxmPAjTx2mHm1z5NgTFNHXrmj2n07wbi99//53ExEQiIyMBuOGGG1i9ejV33nnqRNK6whRPnTqVjIwMvv/+ewCOHz/O/v37axwgAtqxgikpKXTo0IEFCxaQn59PUlISoAVX8/Pz46qrrqJr165s3ryZ4cOHk5SUxNatW3n00UcpLS113ctdaOTT3dMdW7ZsaZBYQx5p9EKIUUKIZCHEASHERDf5dwghtjtfq4UQPZzpPkKI9UKIbUKIXUKIV866xR5Sl0YPYIqNVbtjL0Qi2sN9C+Gyf8CB32FSf9j4lfLMaYYkJCSwdu1aSkpKkFKyZMmSGoLvdGGKk5OTKS4uJi0tjZSUFFJSUnjhhRfcLugWFRXx8MMPc9111xEaGsrUqVP5/PPPXfUOHz7MokWLKCkp4YUXXuCZZ54htZJFoLKQr6B6aOTT3bM6f/75J1OmTOH+++8/06/PRZ2CXgihByYBo4EuwG1CiC7Vih0GhkopuwOvAhWrB+XApVLKHkBPYJQQYuBZt9oDdDqBTidqXYwF7aBw24kTOCyWc9EkRXNCb4BBf4GHVkNMD+1wk/9dDSf3N3XLFJUYMGAAN910E7179yYpKQmHw1HFK6Yupk6dWuMw8RtvvLGK+Wb48OF069aN/v37k5CQwKeffkpJSQkLFy6somn7+/szaNAgZs+ezZVXXsnjjz/O6NGj6dKlCxdffDF6vb5GPHs4FRr5rbfeOu09QTthqmfPnnTo0IE33niD6dOnN4hGX2eYYiHERcA/pJQjndcvAEgp3Z7pJYQIBXZKKWOrpfsBK4GHpJTrTvfMhghTDPDpE3/SdXBLBt1Uc4oGkD97NseffY42s2dhdjONU1wgSAlbvoNFzlg5Q5+DS57QYuhc4Kgwxc2TxghTHAscq3Sd6kyrjXHA/EoP1wshtgKZwOLahLwQYoIQYqMQYmNWVpYHzaobvUHgqGXDFIC5bVsAyg8eapDnKc5ThIDed8EjG6DjaC3e/ZRhkLapqVumUDQIngh6d6fZup0GCCGGowl61+GSUkq7lLInEAf0F0J0c1dXSjlFStlXStm3YuHlbNEbdLWGQAAwJSaCEJQfPNAgz1Oc5wRGwy3/g7E/aDFzPr8M5j0LpXlN3TKF4qzwRNCnAvGVruOA49ULCSG6A58DY6SU2dXzpZR5wDJg1Jk09EzQG3SntdHrfH0xtmyJRWn0isp0ugoeWQd9x8GGz+HjvrB1qnLFVJy3eCLoNwDthRCJQggTMBaYVbmAECIB+BW4S0q5r1J6pBAixPnZF7gMaNgdF6fBYNTVGr2yAlO7tpQfUoJeUQ2fYLjqbbh/qeaDP/NBLUhaxq6mbplCUW/qFPRSShvwKLAQ2AP8JKXcJYR4UAjxoLPYy0A48IkQYqsQomIlNQZYKoTYjjZgLJZSzmnwXtSCrg6NHsDcpi2WQ4dUFEuFe1r21A43ufYjyEqGyYNh/vNQrA6WV5w/eLRhSko5D5hXLW1ypc/jgfFu6m0Hmuz0bb1BV2sIhArMbdsgLRasaWmYEhLOUcsU5xU6HfT+P+h0tbZQu34KbPkeLn4MLnoEzAFN3UKF4rR4bQgE0Lxu6tTo27UDoHzfvtOWUyjwC4Or34OH10HbYbDsDfiwpxYG2ab2YjQWH3zwAd26daNr1668//779a4/Z84cevXqRY8ePejSpUuV2DGehBru3r07nTp14tFHH3XlnW94uaDXYTuNeyWAuWNH0Oko2737HLVKcd4T2QFu/Q7GL4HITloY5En9tNg5andtg7Jz504+++wz1q9fz7Zt25gzZw7793u+qc1qtTJhwgRmz57Ntm3b2LJlC8OGDQM8DzW8fft2tm/fjtlsZsyYMQ3dxXOCdwt6Y902ep2vL+a2bSndpRbZFPUkrq8WKO2O6WAK1GLnTBmqhVVQHjoNwp49exg4cCB+fn4YDAaGDh3KjBkzPK5fWFiIzWYjPDwcALPZ7AolXJ9QwyaTibfeeoujR4+ybdu2BujZucVrg5oBGAy608a6qcCnSxeKVq1CSokQ7rYNKBS1IAS0vwzaXgo7p2s2/O9uhNaDYdhEaHWJVsYLWPHTPk4eK2rQe0bEBzD4lg615nfr1o2//vWvZGdn4+vry7x58+jb1+3mT7eEhYVx7bXX0qpVK0aMGMHVV1/Nbbfdhk6nq1eoYdAGgh49erB371569Ojhcb3mgFdr9J543QD4dO2K/eRJbJkNsyNXcQGi00H3m+HRjTD6P5qHztdXwZcjIXmB0vDPkM6dO/P8889z+eWXM2rUKHr06IHBUD/99PPPP2fJkiX079+ft99+m/vuu69GmdpCDVenocIGn2u8WqPXG+v2ugHw6dYVgLJduzBGRzV2sxTejMEEAyZoIRW2fAerPoSpt0J0Ny1+TpfrtDLnIafTvBuTcePGMW7cOABefPFF4pynw1VQV5hiwHUu7F133UViYiJff/21R6GGqz9nx44d52XsH6/W6OvaGVuBj3NBtnT7+Wd7UzRTjL7Q/354fDNcNxnsFvj1fng/Cf78j/LDrweZmZkAHD16lF9//ZXbbrutSv7pwhQXFRWxbNky1/XWrVtp1aoVgMehhkFb1H3hhReIj4+ne/fuDdGtc4p3a/QGUafXDYDO3x+frl0paYCImQpFFfRG6HkbdL8VDi6Btf+Fpa/B8v9A0s0w4AGIOf8Ex7nkxhtvJDs7G6PRyKRJkwgNDfW4rpSSt956iwceeABfX1/8/f35+uuvAbjyyivJyspi9OjR2O12QkJC6NatW5VQw3fccQdms5ny8nIuu+wyfvvtt4bu3jnBywW9Zxo9gF//fuR+8y2O0lJ0vr6N3DLFBYdOB+0v115Zydqmq60/wNbvoGVv6HM3dLsRzIFN3dJmx4oVK864bmBgIPPmzas1/+677+buu+92m1d5JnC+492mG6MOh016tIDi378/0mql9Dx0nVKcZ0R2hKvegad2w6h/g60MZj8Bb3eE3x6F1I1q8VbRoHi3oHceJ+jwwMXSt08f0OkoWb++sZulUGj4hsLAB7VTrsb9Dl2v11w0Px+hHV6+4h3IO9rUrVR4AReEoPfEfKMPCMCnWzeKV69p7GYpFFURAuL7wXWT4OlkLcyCbygs+ae2ePvVVbD5myaLi3++uhR6K2fyeyhBX4mAwYMp3b4dW25uYzZLoagdnyDoex+MWwiPb4XhL0HRCZj1GLzdAX66G/bOO2exdXx8fMjOzlbCvpkgpSQ7OxsfH5961fPyxVhtR6InnjcAAUOHcHLSJIpXrSb46qvqrqBQNCZhiTD0WRjyDBzfDNt+1Ew7u2eCT4gWTbPr9dBmaKOdbxsXF0dqaioNdbyn4uzx8fGpsZegLrxa0BuM9dPofbp1Qx8WRuHvvytBr2g+CAGxfbTXyNfh4B+wawbsmaV57fiEQOeroUvDC32j0UhiYmKD3U/RNHi1oNfV03QjdDqCRo8m7+efsRcUoA8KaszmKRT1R2+EDiO1l63cKfRnwu5Z2k5c31DtKMRGEPqK8xevFvT18bqpIHjMteR+/z0FCxcSevPNjdU0heLsMZih42jtZS3ThP7umbDrN03o+4RoA0LHK6HdCOWjfwHj0WKsEGKUECJZCHFACDHRTf4dQojtztdqIUQPZ3q8EGKpEGKPEGKXEOKJhu5AZZYcWUJyTrLrWl9P0w2AT1ISptatyZ8xs6Gbp1A0HkYf6HQl3DAFnj0AY6dCh1GwfxH8fDe81UaLqrnhCyhIb+rWKs4xdQp6IYQemASMBroAtwkhulQrdhgYKqXsDrwKTHGm24CnpZSdgYHAI27qNhgvrHyBOYdOHUnr8rrxcDEWQAhByM03U7p5M2V79jR4GxWKRscl9D+FZw7APXOh3/2QfQDmPgXvdoIpw7SYOyd2qs1ZFwCeaPT9gQNSykNSSgswDahyzIqUcrWUssIncS0Q50xPl1Judn4uRDtcPLahGl8dgcAhTwn1CkFvq4dGDxBy040IPz9yvvm2QdunUJxz9AZoPQhGvaG5az68Fka8DEKvxdyZfAm81xV+e0Tz6CnObuoWKxoBT2z0scCxStepwIDTlB8HzK+eKIRojXZQ+Lp6tK9e6ISuiqB3ed3UQ6MH0AcHE3LdGPJ+/oWop5/CEBHRoO1UKJoEISCqs/Ya/DQUnoB9C+DAEtgzW7PrI6BlT+0glbaXQlz/8zassuIUngh6d8fjuJ3rCSGGown6QdXSA4DpwJNSyoJa6k4AJgAkJCR40Cy390BWaprO6UdfHxt9BaF33kXuD1PJnTqNyMcePaP2KBTNmsAW0Oce7WW3QfpWbUH34B+w8n0tBIPRX5sRtBmqvUd3A52+adutqDeeCPpUIL7SdRxwvHohIUR34HNgtJQyu1K6EU3Ify+l/LW2h0gpp+C07fft2/eMjIZlFsnBrELX9Smvm/oLenObRAIuvZScb78l7O7/U66WCu9Gb9DOwI3rC0Ofg7ICSFkBB5dqgn//Qq2cT7B2PGLrQUrwn0d4Iug3AO2FEIlAGjAWuL1yASFEAvArcJeUcl+ldAF8AeyRUr7bYK2uBYtdkl1U5ro+FQLhzBabIh9/jMPXXU/2l18S9eSTDdFEheL8wCdI88fv5Nw4WHAcUlZBynJIWQnJztC/PiFuBL9XR1Y5L6lT0EspbUKIR4GFgB74Ukq5SwjxoDN/MvAyEA584jxc2yal7AtcAtwF7BBCbHXe8kUpZe0Bos8GKXBU8iCob6yb6vh06kTg6FHkfPMtYXfeqWz1iguXoJbambjdnXtL8tPgyCpN609ZCclztXQl+JslHm2YcgrmedXSJlf6PB4Y76beStzb+BsFgUBSyevGuRjraawbd0Q+/jiFvy8h8+13aPnmv866jQqFVxAcC91v0V4A+alOjb8WwZ8wQFvYbdlTO2ZRcU7xsp2xVTV6w1lq9ADmxETC77mb7M8+J+SWW/Dr3eusW6lQeB3BcdDjVu0FTsG/0in4V50S/DojtEiC+AFaaOa4/lpdcc70wQsSrxP0lTX6s/G6qUzEgw+SP3sOJ159lcRffkbo1eKTQnFaguOgx1jtBVCUBanr4dh6SN0Am76Gdf/V8gJbnhL68f0hpocW3kHRYHiZoNdViZsthEBnEGfkdVPlrv7+RE98nrQn/0LOV18RPr6GlUqhUJyOgMiqi7t2K2TshGMb4Ng6bRDY7Tx4W2+CmJ6a0I/rp70HtWyypnsDXiboBQ6qCnW9QYfdevZbvANHjiTw8svJ/OBD/C++GJ8ujRbJQaHwfvRGaNlLew2YoKUVZpzS+o+th/WfwZqPtbzAGO0Q9dhe2nvLXuAX1nTtP8/wKkEvEEjpRtCfpUYP2uygxT9foXTMdaQ9+xyJ039BV89TXhQKxWkIjIbO12gv0E7ROrFDM/Uc3wxpm0/Z+gHC2jiFf2/tPaYHmPyapu3NHK8S9CBqHHmmN+jqHeumNgyhocT86w2OjRtPxptvEvOPfzTIfRUKhRsMJojro70qKM3TdvCmbYa0TXB0Dez8RcsTei28Q8teTuHfC6K6KHs/Xijoa5hujLp6x7o5HQGXXELYuPvI+eJLfDp1JnTsrQ12b4VCUQe+IdBmmPaqoPCEJvgrtP49s2GLMyChzqAJ/5iemsYf0xOiu15wmr9XCXrNj76mRn+2i7HViXrqKcr37efEa69hat0K/4EDG/T+CoWiHgS20MIyd7pSu5YScg9D+rZTr71zTwl/oYOIjppPf0wP7dUiyasPZvEqQQ+iRmxtvUE0iI2+ylP0emLffYeU224j9eFHSPj6K3y7d2/QZygUijNECM1+H9ZGOzwdNLmQn1pV+B9cCtumVlSC8LaVNH+n8PeSBV+vEvQCHQ43Gn1DC3oAfWAgCV98wZE77+Lo+Ptp9c3/8OnUqcGfo1AoGgAhICRee3W++lR64QlI367Z/dO3aa6eFTZ/gKA4TeC36Ka9R3eD0MTzLqyDVwl6avW6aZwTdIzR0SR89RVH7ryTo/eNo9V332Ju06ZRnqVQKBqBwBbaq8MVp9KKszXBn7FT8/o5sVM7klHatXxTgGbnj3YK/xZJ2qJvM7b7e5+gr67RG3WUl9ga7YmmuFgSvvySI3fdxZG7/o+Ezz/Dp3PnRnueQqFoZPzDtcPU2404lWYthcw9TuHvHAB2/Awbv9DyhQ7C2p7S/qOTILoLBMU2i/AOXiXoqwc1g8Yz3VTG3CaRVt9+y9Fx4zhy1/8RP/m/+PXt26jPVCgU5xCjr+ayGdv7VJqUkHfklODP2AlpG2FXpWM3fII1bT+qiyb4o7pq7z7B57T53ifo3fjRN7TXjTvMbRJp/cP3HL1vHEfHjSf2/fcIHD680Z+rUCiaCCEgtLX2qmz3L82DzN2Qscv5vtup/Vc6XC8ozin4u2hmoKguENGh0Y5t9CpBD7qaGr2x4b1uasMYE0Or77/j2P0TSH3kUaJfeIGwu+48J89WKBTNBN8QaHWx9qqgwuun+gBwcCk4rFoZnUGz+09Y1uDmHq8S9LX50Tfkhqm6MISF0erbb0h79jkyXn8dS0oK0S9MRBi86qtWKBT1obLXT4eRp9LtVsg+cEr4W4obxabvVdKnNtNNQ4VA8BSdnx9xH35A5tvvkPPVV1iOHSX23XfRBwSc03YoFIpmjt6o7dyNalwHjvPLGbRO3JhuGtG98nQIvZ7o55+jxSuvULxqNUduu43ygwfPeTsUCoXCI0EvhBglhEgWQhwQQkx0k3+HEGK787VaCNGjUt6XQohMIcTOhmx4Le10617pOIemm+qE3noLCZ9/hi07h8M33UzejJlN1haFQnFhUqegF0LogUnAaKALcJsQonow9sPAUClld+BVYEqlvK+BUQ3S2jpx717pcEik49xr9RX4X3QRiTNm4JuURPoLL3D8+Yk4ioubrD0KheLCwhONvj9wQEp5SEppAaYBYyoXkFKullLmOi/XAnGV8pYDOQ3U3tMi0LmNdQNnf5zg2WKMjiLhqy+JeOQR8mfN4vBNN1O6bVuTtkmhUFwYeCLoY4Fjla5TnWm1MQ6YX9+GCCEmCCE2CiE2ZmVl1be6do9avG6g6QU9aHb7yMceJeGrL3GUlpIy9jYy/vUvHCUlTd00hULhxXgi6N35+ri1gwghhqMJ+ufr2xAp5RQpZV8pZd/IyMj6VteeX4vpBsDWhHb66vgPHEibObMJGXsrOf/7hkPXXEvx6tVN3SyFQuGleCLoU4H4StdxwPHqhYQQ3YHPgTFSyuyGaV79EELndjEWmodGXxl9QAAxf/87rb77FmE0cvS+cRx/fiLWzMymbppCofAyPBH0G4D2QohEIYQJGAvMqlxACJEA/ArcJaXc1/DN9BR38ei1LjqawMXSE/z69iXxt5mEP/gABfPmcWjUaLK/+AJpsTR10xQKhZdQp6CXUtqAR4GFwB7gJynlLiHEg0KIB53FXgbCgU+EEFuFEBsr6gshpgJrgI5CiFQhxLgG74UTXS1+9ND8NPrK6Mxmop58kjazZ+HXvz+Z/3mbQ9dcS/6cuUhH8223QqE4P/BoZ6yUch4wr1ra5EqfxwPja6l729k0sF4INztjm6npxh2m1q2Jn/xfilasIPOt/3D8mWfI/nQyEY8+RuDllyHOs8MOFApF88CrJIdAUH2d2OVe2YwWY+siYPBgEn+bSey77yDtDtKeeILDN9xI4R9/1BjIFAqFoi68TNC7WYyt8Lo5DzT6ygidjqArr6TN7Fm0fOvfOEpLSH34EVJuvIn8WbOUDV+hUHiMdwl6IaA2G/15pNFXRuj1BF97LW3nziXm9ddxlJVx/Lnn2T9iBCf/+19sOedkL5pCoTiP8S5BX8tRgtB8vW48RRgMhNx4A23mzCb+s8/w6dSZrA8+5MCw4Rx/6SXKkpvQ2UmhUDRrvC5McXUbvdGkB8BqsTdBixoeodMRMHgQAYMHUX7wIDnffkv+zN/I/2U6fhcNJPS22wgcPhxhNDZ1UxUKRTPBqzR6ndDXcK80+miC3lLaeAeENxXmtm2J+cc/aL9sKZFPP4XlcAppjz/B/uGXkvnOO1iOHGnqJioUimaAVwl6gR5JVc3d7KtNWixl3ifoK9CHhBBx//20+30xcZ98gm9SEtlffMnBkaM4fOut5Hzzjdpxq1BcwHiV6UYn9NRYjDXq0OkFllLvMN2cDmEwEHjpcAIvHY41I4P832ZRMHcuGW/8i4w3/41f//4EXXUlQVdcgT743J5Cr1Aomg6v0uj1wlBDoxdCYPIxeKXp5nQYo6OJmHA/bX6bSZs5swl/YALW48c58beX2TdoMMceepj8OXNV5EyF4gLAqzR6g66m6QbA5Kv3atNNXZjbtSPqiSeIfPxxynbupGDOXArmz6do6VKEry+Bw4cTdPXVBAy6BGEyNXVzFQpFA+NVgt6oM4Co6S9v8r3wNHp3CCHwTUrCNymJqOeepWTjJgrmzaNwwQIK5s1DFxioefQMH47/oEEYQkObuskKhaIB8CpB7850A2immzLvt9HXB6HX4z+gP/4D+tPipb9SvHo1BQsXUfTnnxTMmw86Hb69exE4bBgBw4ZhatvWuSFNoVCcb3iVoDfo9LVq9IU5ZU3QovMDYTQSMHQoAUOHIh0OynbsoHDZMoqW/Unm2++Q+fY7GOPjCRg2jMDhw/Dr21eZeBSK8wivEvRGvQEh7NjtDvT6U+vMJl891gvYRl8fhE6Hb48e+PboQdQTT2BNT6fozz8pXLqUvB9/JPfbb9H5+eHXrx9+Fw3E/6KLMXdor7R9haIZ412CXqd1p8xmw19/SuM0+xgoL1GC/kwwxsQQOnYsoWPH4igpoXjtOoqW/0nJmrUU/fknAPrwcPwHDsT/ooH4X3QRxtjTHSmsUCjONV4m6LVt/yVWK/7mU4LeJ8BIeakNh92BTu9VHqXnFJ2fn8tPH8B6/DjFa9ZSvHYtxWvWUDB3LgDGhARN8F98EX59+2KIiGjKZisUFzzeJej1FRq9BfB3pfsGmkBCaZEV/2BzE7XO+zC2bEnIjTcQcuMNSCmxHDhA8Zo1FK9ZS8HcueT99BOgHaji26c3fn364tenN8aEBGXqUSjOIR4JeiHEKOADQA98LqV8s1r+HcDzzssi4CEp5TZP6jYkJqegL7Vaq6T7BWnafWmhRQn6RkIIgbl9e8zt2xP2f/+HtNko3bGD0s2bKdm4icLfl5A//VcA9JER+PXug1+f3vj26YNPx44Ig1fpHApFs6LO/y4hhB6YBFwOpAIbhBCzpJS7KxU7DAyVUuYKIUYDU4ABHtZtMCps9KXVDuXwDXQK+gJrjTqKxkEYDPj16oVfr16EjxuHdDiwHDxIyabNlGzeROnGTRQuXAiAzt8f3x7d8Unqjm/3JHySkjBGRTVxDxQK78ETNao/cEBKeQhACDENGAO4hLWUcnWl8muBOE/rNiQmg2ajL7O51+hLCtWpTE2F0OlcGn/o2FsBsKanU7J5M6WbNlG6dRvZX3wBNm3R3NCiBb5JmtD37Z6ET7du6AMCmrILCsV5iyeCPhY4Vuk6FRhwmvLjgPn1rSuEmABMAEhISPCgWTVxafS26hq9c5G2QAn65oQxJobgq64i+KqrAHCUlVG2Zw9lO3ZQun0HpTu2U7h4sVZYCExt2jiFfzd8u3fH3LEjOuXPr1DUiSeC3t2qmdvjmoQQw9EE/aD61pVSTkEz+dC3b98zOg7K7NLoq7pSmnwN6A06SpWgb9bofHxc5p4K7Hl5lO7YSdlOTfgXrVhB/syZWqZej7lNIub2HTB37Ii5Ywd8OnbE0KKFWuxVKCrhiaBPBeIrXccBx6sXEkJ0Bz4HRksps+tTt6Ew6zVBX2otr942AkLNFOaq3bHnG/qQENeJWgBSSmzp6ZRu30HZ3j2UJ++jdOtWCubNc9XRBQXh06Gq8De3b4/Oz6+puqFQNCmeCPoNQHshRCKQBowFbq9cQAiRAPwK3CWl3Fefug2Jn9EXgGJLaY28wHAfCk4qQX++I4TA2LIlxpYtCRo10pVuLyykfN8+ypKTKU/eR3lyMvkzZpwKwywExoR4fDp0PDUAdOqEMTYWoVN7KxTeTZ2CXkppE0I8CixEc5H8Ukq5SwjxoDN/MvAyEA584pwy26SUfWur20h9IcCkaWzF1pqCPijCl8Pbshrr0YomRh8YiF+fPvj16eNKkw4H1rQ0ypOTqwwAhb//DlKzDur8/DBX1v47dMDcoQP6oKCm6opC0eB45LwspZwHzKuWNrnS5/HAeE/rNhb+Rk3Ql1iLa+QFhvtQWmjFWm7HaNafi+Yomhih02GKj8cUH0/gZZe50h0lJZQfOFBF+BcsWIDjxx9dZQwtYzTtv307TK1aYWrVCmNCKwxRkcr+rzjv8KpdKhUafYmtpkYfHKGZdfKzSomIU256FzI6Pz98u3fHt3t3V5qUEltGRg3zT9HKlS6XTwDh64spIUF7tUrA2KoVpoRWmFolYIiKUmYgRbPEqwR9oEkLe+BO0Ie11PKy04qUoFfUQAiBsUULjC1aEDBkiCtd2mxY09OxHDmK5egRrEeOYDlylPKDBylatgxZaRe28PHBFB+PsVWCNgtwDgCmVq0wREerQUDRZHiVoA8yaxp9qbXmOaghLfzQGQQnU4voeLpdAApFJYTB4DL/wCVV8qTdjjX9BNajR7A4BwDL0aNYDqdQ/OfyqoOAyYQxIR5Tq9au2YA2GCRo7qB6ZU5UNB5eJug1Tb3UjUav1+sIi/EnO7XwXDdL4aUIvR5TXCymuFj8L764Sp6027FlZFQdAI4cwXr0CMUrVyLLT7kAC6MRY3w8xrhYjLGxmGK1d2PLlhhjY9GHh6t1AcVZ4V2C3kezw5fZ3btRRsQFcGRntts8haIhEXq9yw3U/6KLquRJh8M5CGjmIG0AOIolLY3Sbdtx5OdXvZfZ7LqXsWUMhpgYjDEtMcbEaNctWqgdworT4lWC3t9kRDqMlNpqmm4AIuIC2bvmBEW55QSEqiiWiqZB6HSakI6JwX9gTTuivagIa9pxrMfTtPe0NKzHtfey5GTsJ0/WqKOPiHDd0xgTgyGmhTYYtIjGEB2NISJCRQi9gPGqX14IgXCY3ZpuAGLaBQOQfjCP9n2jz2XTFAqP0QcEoO/YAZ+OHdzmO8rLsZ04gTU9XVsjSD+OLT0d6/F0yg8coGjFCmRptf8BIdBHhGOMcgr+qEiM0dEYoqIwREVjiI7CGBWFLjhYmYm8EK8S9AACM2W1CPqIuACMZj3H9ytBrzh/0ZnNLt9+d0gpceTna7OAjAxsGZnYMjOwZmZiy8jEmpZG6ebN2PPyatQVZrMm/KOjtEEhKgpDdDTG6CjXZ0NUFDqzmhGfT3idoNdjotzhXtDr9DrCWvqTl+HetKNQeANCCPQhIehDQvDp0qXWco7ycmxZWdgyMrBlZlYaFDKxZWRQunMntoyMKgvHFeiDg11C3xAddWp2EBmJITwcfUQkhohwdD4+jdlVhYd4n6AXPlgctce08QsykZ/lfiBQKC4kdGYzprg4THFxtZaRUuIoKHAOBNoAYMtyDgqZ2iBRnpyMLTsbHI6azwgIwBARgT4iHENEJIaICAwR4VpaeEVaOIbwcIRaUG40vE7QG4UP1lo0egC/YDPpB/NrzVcoFKcQQqAPDkYfHIy5fftay0mbDVt2Nrask9izT2I7eRJb1kkt7WQW9pPZlCcnU7xqFY5C9y7O+uBg9BER2owgPAxD2Kl3Q0Q4+rBwDOFh6MPD0fn7q7WEeuB1gt6sC6DUXrsLZWCYmbIiK2XFVnz8jeewZQqF9yIMBozR0Rij6177cpSXYz/pHAycg4Mt+6SWlnUSW04O5Xv2UpyTg6OgwP1NjEYMTvOUPjRUe4WEoA/V0gyu61N5uoCAC3Zw8DpB76sPJMdeM6hZBdGJmudNxuECWnULP1fNUigUTnRmMzrnprC6kBYLttxc7NnZ2LJzsOdkYzuZjT0vD3teLva8PGy5uZQfPIA9N09bYLbb3d/MYHAOAiHog0MqDQ5VBwpDyKk8XWCgV4Su8DpB728IQtpKcEgHOlHzB4puHYTQCdIP5ClBr1A0c4TJ5PFMAbTNaI6iIuy5pwaBigGgIs2em4s9NxdLymFsFYNDtVPpXOj1roXtGrOFkJozCX1wMPqgoGa3Z6F5taYBCDAGQ7mkoLyAEJ+QGvlGs57IhECO78875227kCiyFBFgavrgcQtTFhJiDmFAjApwdCEgdDr0QUHaeQK1uJ9WR0qpDQ6VBgHXIJGXV2WgsB45Stm27djy8qBSLKPq6Pz80IUEow/SBL8+OAhdUJB2HRxc7ToIXWCglh4Q0CiL0l4n6MN9oqEIjuSnuRX0AHEdQ9m6+CiWMhsmH6/7CpqcdenrGL9oPJ9d8RkDYwY2aVue+fMZAHbcvaPJ2vDDnh/oEt6FnlE9m6wNitoRQqAPDEQfGAjx8XVXwDk4FJdo5qPKM4X8AuwF+TgKCpyftWtLSorrWpbV7hWoDwmhw9o1DdU1F14n5dqFtmLRSViXuo8e0V3dlonrGMrmhUc4cTCfhK7KfNPQrEtfB8DWzK1NLuibA/9a/y+gaQcbRcMihEAf4I8+wB9O457qDofFgiM/XxsEnO+OggLsBY0XcNHrBP3Qtm34ZD/szUyvtUyLdsHo9ILU5Fwl6BsBm9TsnQZd4/x55ZTloBd6gs3BjXJ/haIx0ZlM6CIjMURGnrtnelJICDFKCJEshDgghJjoJr+TEGKNEKJcCPFMtbwnhBA7hRC7hBBPNlC7a6V1qPbl5ZTm1VrGaNITnRjEkZ3ZSOfZoYqGw2rXbJdGXeO4rw79cSiDpg2qkmaxWyi0qBDUCoU76hT0Qgg9MAkYDXQBbhNCVN9XnQM8DrxdrW434H6gP9ADuFoIUfuuiwbAz2QGh5m88tNviup0UQw5x4tJ3ZvbmM25ILE5NI3+XA2iDumgz3d9uHjqxXUXPsecD4pEub2cTRmbAMgozuCfa/5Jub1m2IPzFauj9kXTCwVPNPr+wAEp5SEppQWYBoypXEBKmSml3ABU/0Y7A2ullCVSShvwJ3B9A7T7tOilP5nFOact07F/C/yCTGxZdKSxm3PBUbEppaSWcNENzdxDc8+4bom1hMnbJjeaMKgY9BqSBYcXUGytfa9IfXlz/Zvcs+Aebpx1I5f9chk/7/uZRSmLzuhecw/NZUXqCtd1ck4yx4uO11p+5C8j+WTrJ2f0LIAJiya4FtzdsSVzC72/7e0ayC5UPBH0scCxStepzjRP2AkMEUKECyH8gCsBt8vaQogJQoiNQoiNWVlZHt7ePaE+YeSWn6SovPZ/Mr1RR48R8Rzbk8vxA3ln9TxFVewObcNKQwojd1RonQWWWnZPesDXu75m0tZJzNg/o6GaVYWGHkAO5B7g2eXP8rdVfzuj+jaHjfxqs93knGQA9uXuc6WdKD5xRvefuGIiDy952HV90+ybGDl9pNuyDungePFx/rvtv2f0LIA16WtYmLKw1vy16WsBWJW26oyf4Q14Iujd7Rn2aD4qpdwD/BtYDCwAtgFupa+UcoqUsq+Usm/kWS5SxAckoDOdZMqfB09bruuQWIIifJg/eQdFubW7PCnqR8VibGNP/8tsNX+zyqYST8wmFYI4t6xxTHgNLegrvtuUgpR617197u30+rYXg6YNqqJ1Czf/4nnleTXSUgtTeWrZUw02gJ9Oyz5WeMylMJwNeqGdxeuQNQOuXUh4IuhTqaqFxwG1z8WqIaX8QkrZW0o5BM2Wv79+Taw/XaPaIoz5fLh0D8dyajcfmH0NXP1oD2xWB/Mn78BafvZ/WIpTi7GNbRt1d8BM5cHFE7OJj96nxr325uzlqWVPNUj7G/o7qBi8Kr5jTzlZepIdJ0+5d1bWut2pchklGeSX5/Puxnex2C0AfLHzCxYfWcysg7PqfF71gTOn7JQpdeaBmby94W3uW3ifK2156nIO5R8iuzSbXdm7uPLXK/kx+UdPu1crFRq9EvR1swFoL4RIFEKYgLFA3b+0EyFElPM9AbgBmHomDa0PSVHtEEKiM2Xz44Zjp9XsQlv4c8W4rmQdLWTGO5spL1ELN3VhdVh5b9N7HMo/xLHCYxRYCvh026ekFaW58qH+wqi+VKwBVNZIKwv6vTl767yHXqdpfJU12BdWvMDiI4v59/p/szlj8xm3r9xeziurX3Fdf7rt0zO+V+V7Vn6vYMD3A3hn4ztklmS61YQ/2/6Z63P10CDuNPrUwlTe3/w+X+36iiVHlwAQbNLcWX878BtvrHujSnmHdPDyqpdd15O2TqqSX6G955Xl8bdVf+N/u/9XJf/pZU8zZuYYrplxDbMPzgbgSIHn62dWu5VD+YeqzPI2nNjAhhMbALDLC1uJq1PQOxdRHwUWAnuAn6SUu4QQDwohHgQQQrQQQqQCTwEvCSFShRBBzltMF0LsBmYDj0gpG93NpVNYJwBiWibz8dIDPPrDFj7+Yz+FZe4FT2L3CEY9kER2WhHTXl3PvvVnZp/0Jr7a+RVJ/0uq4kFTMWD+e/2/+XLnl4yZOYYrf72Sexfcy8dbP2bsnLEUWApcgt7isLjuZ3VYuWfBPWw8sbHGszJLMmsILpvDxhc7vqhhJqhsO674p64ckbDyfW6fd3ud/SyxaoPF9P3TeWrZU2SWZLqm+z8m/8jdC+6u8x618duB31iWusx1/fHWj8/4XhVUHHxf0c8vd37J93u+p8RWwte7vmbEzyOYfWh2jXo7s3cC8MfNf3BfN02TLrIUAVUF/ZO9n+SKVldwMO8g6UXaXpQKN9kTJdp3vyt7F1P3TqXEWoLNYePjLR9zMO8gMw6cWuew2C1VtOhVaatYc3wNb6yvOkAMix/Gwz0edvWr0FrI93u+d/VxW9Y2pJQcyj/E2vS1HC04yuIji3lxxYtVFInHlj7GmJlj+GDzB6609OJTe2ncmfkuJDzyo5dSzpNSdpBStpVSvu5MmyylnOz8fEJKGSelDJJShjg/FzjzBkspu0gpe0gplzReV07RJqQNI1uPxOK/DEQ5c3ek8/aiffT852J+3HDUfZ2ekYx5shd+wWYWf7mbme9u5uDmzHPR3GZJhSdEhUC5aOpF3DX/LoAaU+qKRby88jw2pG84JejtpwR9WmEamzI2uV1EHPHzCJ5Y+gT7cvfR65teHMo/xMKUhby/+X0mb5tcpezlv1zu+vzv9f8GqKLBltvcrwtsPLGR5anLXYIdNI3vsx2nNN3FRxYz4ucRJOcmV6m7O3s3r6x5BZvDxr7cfWzL2ub2GaANiMtTl2N1WDlZWvMQ77Olon9Wu5Xlqct5b9N7vLn+zSplFhxewKjpo1yDYn55PtuztgMQ6ReJWa8dA/joH48C4OCUQG7h34KLW15Mmb3M9T28uf5Ncstyayx65pbnsjJtJZ9u/5QbZt1QJU8imbr31OR9+v7pTFg8gfmH51cp99KAl+gR2cNtX6fvn86d8+7k9XWvM2bmGO5fdD9XzbiKp5Y9xexDs8ktP6UzViy2Vv5tKu+rKLAUkFqYStL/kth5cmeV55TZyrzetON1O2MruKXDLSxMWcgT1+XzwYwoAOwOyfPTd3BrvwS3dVq2D+HGZ3uzeeFRNi08QtoU7Q/CL9hEvytb02VwLDrdhRXPutxejr/Rn2JrMduytp12IU4ndOzJ2ePStCo0+inbp7i0xuq7ZQ/kHgC0f9Rwn3Bs0saa42tc96jQxKwOK9mlVc8Z2Jy5mdVpq/luz3eutDJ7Gck5yTUEyr0L73V9HpEwgqzSLJfwq4tb59wKwC/7fnGlPdzjYT7Z9gm/XfcbbYLbuNLXpq/lkSWP8GCPB2t4t9TGv9b9ixEJI+gf079G3v7c/RRbi11xcio03yJrEY8secTt/VYd14Te5b9czv1J91exzQOuAWhTxiYeW/JYle+hX4t+HMo/VKVcRkkGQ34cAsCDPR50Db4PLn6w1kXhmQdm1tVtAKL9o8kuq/38CKipWFQw4ucRNdJ2nNzB4388ztJjS6uk783Zy5+pfwJw29zbuKH9DWSVZPFYr8e4Zc4tjE8azxO9n/CozbUhpWTOoTmMSBiBn9HvrO7V0IjmuKGjb9++cuPGmlP8+mC1W7lyxpWcKD7B+E4TmbMqjv2Z2lQ15c2r6qxvtznYvfI4G+elUFJwSjP18TfS7+rWtGwfSkRcANIhEV4o/Pt+15dyezmLb1pMC/8WJP0vCYBBsYNYmbbSbZ12Ie2I8Y+h1FbKxoyNGHVGHuv1GO9uetdVpm1wW2ZeN5MSawklthKG/zS8xn2ifKNAaCadwbGDuTThUl5Z80qNcg3FG4PeQCL568q/1rvu032e5rp21/H1rq/ZlLEJndCxOXMzl7e6nBPFJ2oI2QExA1iXvo6PL/2Y2IBYtp/czt9X/x2AZ/o+w/LU5eSX53Nnlzv5ce+PLpPLO0PfYdmxZQxsObBKO006k2tAffWSV1meupzFRxbXaGeQKYi3hrzFJbGXkFaUxqjpo6rkj0gYwfvD3we0792dEAXYcMcGBk8b7Bpw6kOgKZBCSyEGYXB5D+24ewcnik9Umak1FonBiRzOP1xrvrtYRMk5ycQHxmPSm7BLO0ad0W34c4AdWTu4fd7tjGk7htcGvdZg7fYUIcQmKWVft3neKuhBm7JWaHK/Xvsr7y7ex4dL9pP82ijMBr1H95BSUlJg4fC2kxzaksmxPVWXGPRGHT0ujSMiLhCH3UHHgTFn3e7mQIWgn3P9HFoFtXIJ+jCfsCoeFC8NeInX1ml/1Ld1uo2fk38mJiCGY4XH3N4XYPq103nmz2c4VnDM9Q9fH/RCz6UJl7I7ezeFlkIKLAW0C2nHgbwDrjJdw7ti0pt4rNdjdAjtwPas7SxIWUBicCKfbP2ENwa/wYz9Mzicf5iFNy5ECMH/dv2Ptzdqm7uX3rKUOQfnUG4v56KWF2Fz2Phy55f8mfont3a81WOPkLbBbTmYf3o337Phl2t+wSEdbMrYxJ1d7qTEWsKsg7N4fd3rgDYwP9vvWRKDEqusZZTaStmRtYNnlz/L4NjB/POSf1YRYBtPbGRBygKCTEF0De9KTEAMncM6u+6x7NgyXljxAkXWoirtmTlmJnGBcXyx4wtWpa1i+8ntDI4dTHpxOqNaj+LjrR+TEJjA032fxqAzMCRuCA7poMc37s03njA8fjhLjy11zTwr0zuqNw7pYGvW1jrv89KAlxjTbgz3LbyPv/T5C90iutH/+/5c3PJijhYcJbUolXYh7Xiy95P8sPcHRrYeSe+o3vgZ/Zi8bTJ2aefX/b/SM7In3175LWW2Mow6I5syNpFRksHClIU81usxOoZ1BOCLHV9gcVh4oPsDFJQX8MXOLxjXbVytUXfr4oIV9KB5Ony89WPW37GeWVuyeH76DlY+P5y40DObWtltDjbOTyE/o4TcjBJOHqv6h27y0dOyg6btOxySnpfFY/I1oNefX6fUVAj66ddOp11Iuyr/iA/1eMi1yeWfF/+TQFMgweZgrA4rDyx+4Iye56P3qaIltg5qTZvgNvxx7A8ARrcezcjEkTy59Mka02y7w45O6Jh7eC49I3sSF1i/aIKVKbOVUW4vrzVgmtVuxaAzkFqYypUzrqzzfv+97L/sz91fZVbTUIxOHM1bQ95q8PvWh0P5h9ChzWK6hHdxOUJATVOGlJIvd35Jt4huNc4H+Pvqv2PSmci35DP/8Hye6P0EBZYCvtr5Fa2DWtM+tD0vDniRPdl7WH9iPV/v+hqA2dfNpsRWwtJjS7m6zdW0CmrF9H3TeXXtq/SI7MGkEZPQCR1/XflXfj/6OwBjO45lWvI017Nv6nAT0/dNR1baHhTtF8193e5zRR5tSL4a+RW+Bl/Gzh0LwAPdH2Bn9k5Wpa3i9UGvc23ba8/ovhe0oJ++bzr/WPMPFt+0mD2pOu79agPTH7qIPq3CGuT+AMX55RzemkVJgYXMI4VkpxVRlFt1UdA3yIReL/ALMmH0MQCSAde2JbSFH2ZfQ7Mz/1QI+qlXTaVNcBsG/HDqH3Ni/4n4G/1ZkbqCNwe/iVGveWW4Mwl4yr3d7uWPo38wJG4IYzuOJSFIW0c5UXyCUJ9Q1wJifnk+AcYAl1tkU3Lz7JvZm7OXSSMmkVGixYipzLD4YXx06Ueua7vDztS9UxmVOIpVaasYEjeEj7d8zE/7fgLgxQEvcmn8pVz2y2U1nnVt22vZm7OXfbn76Brelaf7Pk2vqF6NFiG0uXCy9CQRvhE10vfn7qddSLt6nQG7KWMTAcYAOoZ1ZHnqctcax5rb1pBVmsW1M08vYJ/p+4xrxtdY+Bv9WXv72jOqe0EL+t+P/M5flv2FX675BVtZC676ULMvz39iMJ1jguqofeYUnCzlyM5sCk6WsmvlcXz8jRRmn96uGREfwMljRfgEGEFCx4Et0OkENpuDhC5htEgM1vIaEZvDxqq0VTy17CksDgtfjfyKxOBEhv00zFWmNq1DSkn3b7rXSB/XbRyhPqFc0/Yahv441JUe5RtFZqnm2fTFFV+4XYxszpTaSrE5bASaAgFtULLarcQGxmJ32F0DoCcczj9MfGA8Bp2B3LJcgs3BzD00l5yyHG7vfHujRQK9kDlRfILD+Ye5qOVFrrTv93xfw4sJ4IneTzA+aTxzD81l4oqJVWa1AJe3upy/9P4LybnJ/GXZXwDoE92H3LJcSm2l3N31bjqGdqTIWsRjfzzmqndH5ztYfXy1a+0gNiCW+TfMP6NDzE8n6L1bHQDXFPyPo39wb9cJrvTHp25h8VNDa6t21gRF+JI0TDMhXHKTFrDTbnNgLbdTVmSlILuU3PQSCrJLsVkdZKYUoDdo5p2yIs3jZNuSU3buHUtTETpBq65hdLo4hrAYf4rzyontENqgs4Efk3+s8ofuLvxvgNH9EYFCCN4f9j5PLnuSYfHDiPaLJi4gjqvbXu3Syvq16OfaxBLuG05maSbD44efd0IewNfgW+W6hX8L12ddPU11icGJrs+hPqEAXNP2mrNonaIuWvi3qPKbgSZ4t2VtY3vWdr4e9XWN/KvaXMVVbTRnjrGdxmK1Wwk0BWLUGzHqjMQFxvHB8A8YHDu41oF+YMxAymxlTLpsEkGmIMrt5RzMO0iX8OpBgRsOr9fojxYc5aoZ2g+z/f+2k11soe9rv9My2IfVL7j3LGhKHHYH5SU29m/MoMslLclOK8YnwEDq3lwObMp0G1bZYNShN2qCJTw2ALvNgZTgH2zC6KPHx9+IpcxOfkYJAaFmErqGExThg8MBQeE+2KwOQqL9kHbJ5B2TmbJtClo4I8Fbw95i+8ltfLP7G9fzJl82mUtiLzmj/pVYS8gsySQ2MJbMkkw2Z2xWAk2haAAuaNMNaH7KP+z9wWUe+HDJft5dvI/IQDOBZgOLnxqKvpnZyGtjy+Z9LP19MwM79MHH10RJgQVLqY2c9GKy04oIi/HHZnVQkKXNFOqLFNoOWIewoZN6dGi28NTgZPQOIzGFms94RHwAMW2CycsqxWaxY7dJ/INNmH0NhLb0R6cT+AaaMJr1ZKYUENU6iLJiK3arg4AwH5CS0BZaW3U6QWC4D3arA0u5DR8/I1JKhBAIvUA6JDqdwGDSY7Pa0elEFY25Iq3gZBk2q53w2ADKi22NbuZSKJoTF7TpBuDhng8z48AMxi0ax3vD3qN3Qk8AsgrLySosJ6/EQniAuUqdb9ek8LffdrHvtdGYDM3HY+aznPdZEb2Ci/pPoXcl22J1tJAFIAQ4bJKTqUW8t/JDzMKHG2NvJed4MaEt/LHbHBTllWO3OvAJMLLi0Cr2FO/E3xpMoCmA8IxEfK0BxFnaois34nB6Jpw8VlTD46ixMfkasJQ6jyk06ohsFUhZkZXcE6ePex8Y7kNhThlIzR3WbnUQHOVLfmYpAWFmwmICOLorm5h2wQSEmDmZWoTDLjGY9fgGaGsrfsEm7FYHYS39CQj14ejuHCITAslJKyL/ZClJQ2PRGXSkH8jHYNQhBASE+uCQEgH4h5gx+xlx2B0U5ZZTnFdOZEIg5SVW8rNKiYgLxFJmQ+gEvgFGHHaJwyGxltnwDTRRXmIjIMyMXq9D6ARGs57yEhvlJVbsNgeJPSIpybeg0wtsFjtGHwMFJ0sxmvRYy+2YfPWY/YzoDALpgJL8coxmPVGJQeedR5ii/lwQgj7YHMxz/Z7jlTWv8Jdlf+HXa3/lq3v68euWNGZvO05uibWGoH917h4AispthBlMTdFst1Qs0riL3Fi9XMV6jt4oiGjlz9zlmu/384Mexs94KiCpxW5hf+5+zHoDhwJWU1SazbMXv0LnsM5VnglQVmxFb9BRUmDB7GugvNTKiUMFlBVZCQzzITDCB71BR1FOGXvXniCuYygOh0Rv0GE068nPKsE30ERpoYWC7DL0OkFAuA85x4vJOV5MSYGF4jzNY6nL4JaYzHpMvgasZXYKsssoK7YSGGrGZnNQkm/BYNJj8tFjtTiQDm0QCggzY7c6KCu2IR3StQgudAK7c5Zjc0YqLcoppyhHe15GSgHpNvcz3Pws7fvOPHJqvSIz5VQc/HWzat+IUxt7Vlc+1/js4iut+PHsgsKGxviTm675oBtM2m9VWmjFP8RMQKgZvUGHdEgyUgponRTBydRCSgosOByS9n2jMftp5sWAEDO+gSZsVgcmHz1FeeWUF1vx8TeiM+goLbTgH2KmvMRGcIQPJQUWSoushMcF4BdkIjTaj8KcMkKi/fALNGEps2O3OSgvsRIeG0BwpC/lJTZMvgZtQNUL7BYHRrMeoRMU55djNOnRm3SuAcxbNzXWhwtC0IPmK1uxu/KGWTfw5cgvubF3K2ZvO05+qaVGeYtNEwglFhth/o0n6Hdk7SDMN4zYAM/OcqlwM9yYsZFLEy51pZfZyph9aDYfbf6IATED+M/Q/1SpN3HFqaN+b5h1A2PaaoeEPdTzIe6cdyd7crSBrV1IO2IDYmtdGPLx18whwZHaQqRPgJHgyJp7EsJi/JvNwetSSpCaoJdS4rBL18I3oGn7QGCYDwUnNZNXWIw/pUUWjCY9EjAYdDjskrISK2XFVsy+RvyDTeSfLEU6JNKhzTgyUwqITgxC6ARlxVanO62e7NQipANyM4rxDTAR1tIfa5md4oJySvIthLbQvsOyIit+wWYKc8rITisiMMyHkGg/TD56HHbJ0V05GH302Cx2AkJ9SNl+kqBIX0zOtZi0fbmExvjjH2xG6MDHz0hpkRWjWU92WhEl+RYObM6kfZ8oIuID2fFnKoXZZRScPKU4OByS0kLNIaA4T5t9GIw6lynw0NaqBwPtW5/hGmRzjjsHC7M2AAshXAN3ddL3CxzOehmHz+zwGL1Bh935v2ow6bBZ3JgrBcR3DuPYbm2jX2SC5iVVoVREtQrEUmYnOMqXo7ty8A004htgJCe9hIi4AEKitL91vxCzSxmJbh2E3qCjILsU/2AzfsEm8k6UcHR3Dj4BRlp1Cycvo4SYtsEIAaVFVoLCfbW/QYdEbxBkpRZhtzgIivTFP9jkyus62NNznTzngrDRV5BTllPFva9f5FD+WD6Kd27uyY19qm6yaT1RO55u8V+G0D46sEHbkV+ej6/BF5Pe5NpxuvWurS7f8OzSbOYdnseGExtoH9qeGP8YCiwF/Hfrf7E6rK6Qq/8Z8h/6x/Qn1BzKdb9d54pRUpnh8cO5teOtPPj7g27bcl+3+/hy55dV0m7teCsvDXypIbusaObY7Q7sFgcGk861/lGRZnQKbLvNgU4vNOGdX45er0MiMfkatEGwyIpfsEmbTYJLi5YO6Yp5X5KvzQJ0OoF/iKa0FJwsxSfAyKpfDuCwOYiI18xYoHmvHdmZTc7xYvyCjPgEmMg6WkhClzBsFjt6ox6dTlBabKG00MrJ1CJKnSFLwmP9ycsoxW5z4BtodA1eFXta7HbpKnsmGMx618ywofAJMHLPm5dUUUQ85YJfjK3OieITPLf8ObZkbnGlfXvFDMpLQxnQRtNCKwT9b49cQo/4kAZ9foVwnzRiUq2BqZqSJTcvIcovqqmboVA0KHarA6Gr6vpqKbNpszbn4n9JoQUfPyN6o46so4UEhvloZiCDDoddMxeWFlmJiA9Ar9eRujeH0Bh/hBCumZtfkAmDSU/KjpOuGbDDLgmJ1mYGFUK8KK8cs6+BoHBfCrJL0ekFwZF+GM1nthlQCXo3uAukZM3rzX9GvMg13To6Bb1k6v0XcVHbcIrKbfib9B5vZFh9fDUJgQnEBcZxpOAIOWU5LEpZVCXS4plya8dbWX9ifa0Bmt4d9i5/XfnXOu34teEuuJNCcSYUldt4bc5uXriyM8G+yguqMVGCvhZyynKYuX8m721+r0q6ozwCYSgEnZWXe3xHiTjIK7/m8fZ1lxIVdYTYgFjahLSp5a6ndogadUY237XZpcHXRvVgTD9d/RNpRWkMjBnIt7u/ZWTrkfx28DfKbGWM7TSWuMA4UgtT2Z29m7SiND7a8hGDYwfzSK9H6BreFYCM4gzyyvPoGNYRq93K7pzdGIQBf6M/x4uOkxSZxPGi45j0JqSUrElfw+aMzYztNJZ+LfqdxbeqUJxiyvKDvDFvLw8Na8vzozrVXUFxxihBXwfH8nK5ceorlPpp56JIhwGhO31UxWjfWAb4vUBw1EbmHZ5Nq6BWTOg+gUtiL6HIUsRFUzXXx5s73MzP+34G4Pl+z7MzeydzD83lkthLuLnDzYxIOLVpq8xWRnZZtscLsxVYHVa1RV7RLPl8xSFem7uHey9pzd+v6epRnRKLjdumrOXv13ald0JoI7fQezhrQS+EGAV8AOiBz6WUb1bL7wR8BfQG/iqlfLtS3l+A8WhbLXcA90opTxv05VwL+gpWHt3Kur1mdIYi+nWwMu7nr9H5pKP3OYbQnd2iy1tD3mJ04miPylrtDozKt/mCosxq52BWEV1buo+aeb7yzZoUXv5tF3cMSOD1608/s61gR2o+13y8klbhfvz5bM3zChTuOasNU0IIPTAJuBxIBTYIIWZJKXdXKpYDPA5cV61urDO9i5SyVAjxE9rh4l+fQT8anUEJPRlU6fCpdQ/05YZPVnPoSDEIC+bI37EWJKEzn8ActQCdofbTlgD8RAwlMp2/DfwbV7S6os7nV2xyGvTvP+jXOoyPb+99tl1SNHP2nijgUFYxny4/xLZjeez4xxUE+njP7MzkVFis9vrv0j6SffqNcArP8cSPvj9wQEp5CEAIMQ0YA7gEvZQyE8gUQrg7uskA+AohrIAfcPysW32OCPEzseRpzR0zJbuElQd6M7R9JB/9sZ+fN/XDELALhy0Ynekk9uL2mKPmUZZxFUgjwlBAoTUYnU865h6XUG6TvDpnO1PXa4HKJo7uxHU9Y2kR7ENOsYVX5+xmxpY017PnbE/no9vkGUWxU5w/3DZlLbklpw653p9Z5FXmioqZacW+FE8os52aPVd4wyjODk8EfSxQ+bigVGBALWWrIKVME0K8DRwFSoFFUspF7soKISYAEwASEtyf6doUVPyRJUb4kxjhD8B/bu7Ba9d3w6C7kg9+38eHf2gnG5Wl38zg9hGs2H8SadXcNB1l8TwxbWuN+745fy9vzt972md/sGQ/Dw5ti4+x6WOvKxoHf7OhiqC/4ZPVvH1zD1oG+zCgTfh5E4OpNuzODVFWu+drgWXWyoe9O9TffwPgiSHY3V+aR7+aECIUTftPBFoC/kKIO92VlVJOkVL2lVL2jYyM9OT2TYrZoEevEzx1RUdS3ryKXx68iJXPD+fbcQPY++ooFv9lCE9f3oFW4ad2jbaJ9Oe5UR1Jiq1ph728SzT9W1c9DOX93/cz8F9LcLeOsjMtn2M5tU9tC8usfLLsADbnlFlKybuLkjmUdW7j0yhOT3SQD/1ah/L9+AGMG6SFKn7m523c/vk63pi3p4lbd/ZYnH9/5fXQ6EstlQT9GQTmU9TEE40+FYivdB2H5+aXy4DDUsosACHEr8DFwNk7kzcz+lYS0j5GPe2jA2kfHchjI9pTUGYls6CcdlFaHPeHh7WjuNyGn0lPdrGFUD+TS3NbsPMEm4/mknyikD/3ZZFXYmXF/pMM6RBJcbkNf7MBm93B1R+tJMTPyNaXT9n+Syw2/tibyVVJMXzw+34+X3mY+FA/runRkoNZRXz4xwEW7DrBor80Xhz+6jgckl82p3Jtj5b11szyS628t3gfz47siL/Zs2gddofky5WHGds//rywdeeWWOjcIohL2kVwSbsI7hrYij/3ZfH63D1sOlIzJPX5RoXJxlIPG31ZpUGhzGYnmOb/OzZ3PPnv2QC0F0IkAmloi6m3e3j/o8BAIYQfmulmBHDu3WmamCAfI0HVhE6F4IqoFkxtVLcWjOrWgnKbnWM5JVz27nJ+2ZSKQSe4/fN1fP5/fWkZou2wy6s05Z+7PZ1HftgMwK5hBeSUaFu7s4vK2XYsjzGTVgGQnn/6U67qy7LkTJbuzWTi6M74mmoK8j/3ZfHcL9tJPlHI367W4ucUl9sosdiJDDTXKF+Z/y47yNerU0iM8Ofui1t71J41B7N5fd4ekjMKefvmHhSX20jPL6VdVMOGsWgocosthPid+ttoHeFP6wh/dh3PZ1ly1mlqnhuOZpcQFWQ+Y/NJxSKsxVbVa23rsTwE0CM+BIdD8u3aIwxsE07HFoFVTDeVtXvFmVOnoJdS2oQQjwIL0dwrv5RS7hJCPOjMnyyEaIEmwIMAhxDiSTRPm3VCiF+AzYAN2AJMaZyueBdmg552UYFclRTDrG3HmbVNm0SN/2Yj/VqfWqxrPXEuMcE+VQT4f5cddH3+x+zKzlGahvXH3gx0QjCso/swBza7A71O1FgEk1Jy79cb8DcZmHRHb9LySrnnK+20qP+tOVLjeEa7Q/LMz9sA2HQkl3KbHbNBz71fb2D94RwOvnFlrTbotLxSJv+p9cNqd1BmtXP3l+sxGXR8O+7UEtHJovIqM6J9GYWu9z/2ZjBl+SHWHsph9qODmLUtjaev6FhvobXqwElsDkmXmKA6Byd33Dx5NRtSchmQGMbzozuRVVjOZZ2jsdod5JZYaRHkU6NOyxBfMgvLWbw7g4vbhns8o2lILDYHQ/6zlJFdo/n0Lrdee27JLirHz2TA16R3afTVbfTXORWPlDevYtHuE/x91i6CfAxsffkKyisJ+rJqA8Se9ALaRPpjNii7fX3w6K9HSjkPmFctbXKlzyfQTDru6v4d+PtZtPGCpldCCHN3pFdJ25CiTekjA81kFZZ7pKVf2imKkV2jeX76Du77WptURQSYeeP6bhzPK6VFsC9/7svigSFtGPHun9gdkpev7sJ9gxL5+A8tBO7Xq1M4WaTNFP5eUMYlb/5R5RmvzN7FXy7rQP9EzYx1MKuI7GKt/NZjeXR8aUGV8t3/sZCXr+lC++hA9mcUckvfeNfg8sKvp8IwfLHyMFPXH+VglubO+v7v+yi12Dl8sphFuzNIig3mmh4x5JZYXYPc9tR8Vz8BrvlYOyv4sxWHGdohEr1OcHmXaNdzRnSKIqOwjECzkb9f24X0vDLaRgYwc2sa7y7e57rP7n+OdK3PVDD+fxs4kFnE/UPasPt4Ad+vO8o/rumCzSG5c2Ar1++17nAON3yyusZvEx3sRtAHa7O2+7/R+vDtuP4Mbl/72pWUkpd/28XO4/l8dU8/QvxqRlzNKbawMy2fIR2q3uelmTtYlpxFam4pP9w/gIvbRpCeX0rKSW0NaOGuDArLrB6bwvq89jtdWwYx9/HBLo0+u6iccpuddxfv44EhbV1lk08UurzNCsps7E4voLiSFl9WyUZfVG5j9Acr6Nc6lJ8fvNjtdyAl6M5wATs9v5SYYF+3eZkFZaTnlzV43KtzhdoZ28wpKrcx8r3lpOWVsumly3hp5k7m7zzBxW3D+X78AE4UlPFnchbJGYVYbA5GdI6if2I4/5i1i182pQKaK+dt/RIoLLcy+K2l1OcnN+l1ddpXP/u/vjz6w+YaC24vXtmJN+btxdeop9Ra9xS8b6tQvhnXHz+TgUd/2Myc7ek8O7Ij/1mYDED7qABSsovr5cHR0EQEmDhZZKFTi0BGdI5iwc4TrgGoLh67tB0ni8pJzS1lxf6TrvR5jw+mS8uqB9X/tjWthrfWu7f0IDrIhy9XHqbEYqdPq1BySixc0SWaA5lFvOY8Q+HWvvHcNyiRB7/bRFyor2bOur4bHy89wLGcUsYPSiQswMT+jCIE8Gslt97Tseefo/A16Skut3Hjf1ez90Qh858YTNvIAArLtDMdpJQkvqDphG/f3IPdxwv4cpUWk+mvV3bm9VoWmNtFBXAgs4hXx3Tli5WHSXH60H83bgCD2kfw9E/b2HU8n70ntBlbyps1PbknTt/Oot0Z/PLgRbSJrHmu8UdL9vPduiOsfWFEjdnq9tQ8rv14Ff+5qTs3942vUXfke8tJzihsdgcRVUaFQDjPkVJSZnW4tYGfjlKLHYeUVab9mYVl+Br1BPoY+WnDMb5YeRh/s57NR/OYOLpTnS6fAGaDziXUxw9KZOLoTvxnYTKfLq8ZJhm0UM92KQn3N5OaW8L6wzncc0lrZm09zrO/bK9S1qATXNuzJb9uTiM+zJcVz13K0r2ZtIsKID7Mj7wSC5uP5tIiyJf4MF8k8O2aIyzYeYLB7SOwOyTPjuxIUbmNQB8jM7ek0SshhElLD9I5JpAtR/N47bpuSODwyWKig8wE+hgxG3T8vieDlJPFbD6ah9mgY/5O7TAQX6OeXgkh7EjNp9Rqx+ao+T/zyPC2fLUqhRKLndHdWpBTbGHd4RxX/vSHLqZPq1MmN7tDYrU7MBt0bv3Ey6x2/rMwmQeHtuWdRclM23CsRhl3XNw2nNUHsz0qW5nKv2kFrcP9XAIXNHv6pR2j2HU8n0W7M2o8c//rozl8spgr3lvu8XP7tgrFZNDx4pWdGTNplcsdsy6iAs1IoHdCCOEBZp4Y0Z4Bb2ghTJ4f1YmHhp2aNexMy+dgVpFr4Nz00mVVDhqy2R3M3ZHOE9O2MqprCybf1afG8yqi2f768MUe7XOw2R1Y7bLe/7NngxL0ijopsdjwMxn4Yd1RurYMIi7UlykrDmGzS4Z0iOTDJfvZnprHvMcHY7Vri2dPjGhPC6fZweGQFJRZKSi1kVtiYe2hbH5Yf5TcYgtrXxyBn6mmlVBKybrDOaTmliKlZMHOEyzZm+nKNxl07HvNs7ARjUGJxYZRr6sSjqJiA8+f+7LYk16Av9lAj7hguseFVMkHSM0tQUoI9qu5GF9fVh88SbnNQXaRhTnbj3Moq9jltZUQ5kd2UTm39ktgwpA2vOc0NQ3rGMl7v+8jxM/E9T1jWbw7gyEdIsksLGPF/pNsPprrWtBf8dxwAsyaXb3yGkZWYTkD3vid6vLX3Swt1M9YZU/A4PYRmPQ6hnaMZMX+kyzenUGnFoF8MLYX2UXl9GkdWsXWfs9X610L0B2iA+gZH8JPG7VZ6ZVJLUjLK2PbsTyPvq8gHwNRQT5c1Cacb9ceqZI39/FBtI8K5Eh2MVmF5dz++TpGdIpiyd5Mgn2NzH9isMvhIaOgDKNeR+9XFwMwqmsL3ru1J/szC3nul+0cOlnM5V2ief/Wnhj1OtYdysbmkDw2dQs5xRZmPzqI9tEB52QvgBL0irPGaneQU2wh2s3C4emoOGTCU07klxHoY+DdxfvoEB3Arf2az+a5CxUpJRkF5aw9lI2PUU+Qr4EecSGYDTrGf7PRrXdQ9YV5qPtvwe6QnCgo42BmEW0i/YkK9GFfRiFdYoJc9aSU/LIplQGJ4Tik5N3F+1yOCi2DfeiXGMZvW2t6f0cGmnnmig48P30HRr2o0/wX5GOgoOz0gQ2rs/ufI+ny8kK3eYPbR/Dx7b3xNerZn1nIm/P3MmFIm9Ouu9QXJegVCkWjUWKx4WPQs3hPBoeyirmxdyxR9VQIzpaCMismvQ69TnAiv4xQfxNZhdrglJJdzMRRnXBIuOuLdew6XoCPUUdGgXbE4aPD26HTCVJzSwg0G1h3OMe1FlBBQpgf/3dRK2ZvT68yq/j49l48+sMWqhNoNlBuc9S5vvXJHb3JLCgjLa+UtpEBDOkQ6ZpN1Bcl6BUKhaIaZVY7dod067pqtTuw2SU+xqprKFJKCkptBPsZOVlUToRzAfrh7zczf+cJbh+QwHU9Y0mKDcbXpMfukBw+WURqbilvLUimZYgvoX5GfnY6Srhj1ysjz8idVgl6hUKhaETKrHaWJWcxsmu0R0HYNh/NpW1EAH/uz2JXWj77M4vYk17AnQNb8cjwdmfUBiXoFQqFwss5naBvng6hCoVCoWgwlKBXKBQKL0cJeoVCofBylKBXKBQKL0cJeoVCofBylKBXKBQKL0cJeoVCofBylKBXKBQKL6dZbpgSQmQBR+os6J4I4GSdpbwL1ecLA9Vn7+ds+ttKSuk2SlqzFPRngxBiY227w7wV1ecLA9Vn76ex+qtMNwqFQuHlKEGvUCgUXo43CvopTd2AJkD1+cJA9dn7aZT+ep2NXqFQKBRV8UaNXqFQKBSVUIJeoVAovByvEfRCiFFCiGQhxAEhxMSmbk9DIYSIF0IsFULsEULsEkI84UwPE0IsFkLsd76HVqrzgvN7SBZCjGy61p8dQgi9EGKLEGKO89qr+yyECBFC/CKE2Ov8vS+6APr8F+ff9U4hxFQhhI+39VkI8aUQIlMIsbNSWr37KIToI4TY4cz7UHhylFUFUsrz/gXogYNAG8AEbAO6NHW7GqhvMUBv5+dAYB/QBXgLmOhMnwj82/m5i7P/ZiDR+b3om7ofZ9j3p4AfgDnOa6/uM/A/YLzzswkI8eY+A7HAYcDXef0TcI+39RkYAvQGdlZKq3cfgfXARYAA5gOjPW2Dt2j0/YEDUspDUkoLMA0Y08RtahCklOlSys3Oz4XAHrR/kDFoggHn+3XOz2OAaVLKcinlYeAA2vdzXiGEiAOuAj6vlOy1fRZCBKEJhC8ApJQWKWUeXtxnJwbAVwhhAPyA43hZn6WUy4Gcasn16qMQIgYIklKukZrU/6ZSnTrxFkEfCxyrdJ3qTPMqhBCtgV7AOiBaSpkO2mAARDmLect38T7wHOColObNfW4DZAFfOc1Vnwsh/PHiPksp04C3gaNAOpAvpVyEF/e5EvXtY6zzc/V0j/AWQe/OVuVVfqNCiABgOvCklLLgdEXdpJ1X34UQ4mogU0q5ydMqbtLOqz6jaba9gf9KKXsBxWhT+to47/vstEuPQTNRtAT8hRB3nq6Km7Tzqs8eUFsfz6rv3iLoU4H4StdxaFNAr0AIYUQT8t9LKX91Jmc4p3M43zOd6d7wXVwCXCuESEEzw10qhPgO7+5zKpAqpVznvP4FTfB7c58vAw5LKbOklFbgV+BivLvPFdS3j6nOz9XTPcJbBP0GoL0QIlEIYQLGArOauE0NgnNl/Qtgj5Ty3UpZs4C7nZ/vBn6rlD5WCGEWQiQC7dEWcc4bpJQvSCnjpJSt0X7LP6SUd+LdfT4BHBNCdHQmjQB248V9RjPZDBRC+Dn/zkegrUF5c58rqFcfneadQiHEQOd39X+V6tRNU69IN+DK9pVoHikHgb82dXsasF+D0KZo24GtzteVQDiwBNjvfA+rVOevzu8hmXqszDfHFzCMU143Xt1noCew0flbzwRCL4A+vwLsBXYC36J5m3hVn4GpaGsQVjTNfNyZ9BHo6/yeDgIf44xs4MlLhUBQKBQKL8dbTDcKhUKhqAUl6BUKhcLLUYJeoVAovBwl6BUKhcLLUYJeoVAovBwl6BUKhcLLUYJeoVAovJz/BythHcctmHwPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Day 14-2 cell [62]\n",
    "plt.plot(fit_model_A20.history[\"loss\"])\n",
    "plt.plot(fit_model_A21.history[\"loss\"])\n",
    "plt.plot(fit_model_A22.history[\"loss\"])\n",
    "plt.plot(fit_model_A23.history[\"loss\"])\n",
    "plt.plot(fit_model_A24.history[\"loss\"])\n",
    "\n",
    "plt.title(\"loss_function - Training\")\n",
    "plt.legend([\"5 - ADAM\",\n",
    "            \"6 - ADELTA\",\n",
    "            \"7 - RMSPROP\",\n",
    "            \"8 - ADAGRAD\",\n",
    "            \"9 - SGD\"\n",
    "           ])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Day 14-2 cell [62]\n",
    "plt.plot(fit_model_A20.history[\"accuracy\"])\n",
    "plt.plot(fit_model_A21.history[\"accuracy\"])\n",
    "plt.plot(fit_model_A22.history[\"accuracy\"])\n",
    "plt.plot(fit_model_A23.history[\"accuracy\"])\n",
    "plt.plot(fit_model_A24.history[\"accuracy\"])\n",
    "\n",
    "plt.title(\"accuracy_function - Training\")\n",
    "plt.legend([\"5 - ADAM\",\n",
    "            \"6 - ADELTA\",\n",
    "            \"7 - RMSPROP\",\n",
    "            \"8 - ADAGRAD\",\n",
    "            \"9 - SGD\"\n",
    "           ])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(fit_model_A20.history[\"loss\"])\n",
    "plt.plot(fit_model_A20.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - Model A20\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(fit_model_A21.history[\"loss\"])\n",
    "plt.plot(fit_model_A21.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - Model A21\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(fit_model_A22.history[\"loss\"])\n",
    "plt.plot(fit_model_A22.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - Model A22\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(fit_model_A23.history[\"loss\"])\n",
    "plt.plot(fit_model_A23.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - Model A23\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train vs test for deep net\n",
    "plt.plot(fit_model_A24.history[\"loss\"])\n",
    "plt.plot(fit_model_A24.history[\"val_loss\"])\n",
    "plt.title(\"loss_function - Training Vs. Validation - Model A24\")\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Save each of your alternative models as an HDF5 file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the fifth alternative model\n",
    "file_path = Path(\"./Resources/Alt_Models/AlphabetSoup_A20.h5\")\n",
    "# Export your model to a HDF5 file\n",
    "nn_A20.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the sixth alternative model\n",
    "file_path = Path(\"./Resources/Alt_Models/AlphabetSoup_A21.h5\")\n",
    "# Export your model to a HDF5 file\n",
    "nn_A21.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the seventh alternative model\n",
    "file_path = Path(\"./Resources/Alt_Models/AlphabetSoup_A22.h5\")\n",
    "# Export your model to a HDF5 file\n",
    "nn_A22.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the eighth alternative model\n",
    "file_path = Path(\"./Resources/Alt_Models/AlphabetSoup_A23.h5\")\n",
    "# Export your model to a HDF5 file\n",
    "nn_A23.save(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the file path for the ninth alternative model\n",
    "file_path = Path(\"./Resources/Alt_Models/AlphabetSoup_A24.h5\")\n",
    "# Export your model to a HDF5 file\n",
    "nn_A24.save(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dev)",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
